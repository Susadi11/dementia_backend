{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3735,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008033741715203857,
      "grad_norm": 1.132008671760559,
      "learning_rate": 0.0001996251673360107,
      "loss": 3.4651,
      "step": 10
    },
    {
      "epoch": 0.016067483430407713,
      "grad_norm": 0.47358328104019165,
      "learning_rate": 0.00019908969210174032,
      "loss": 0.6456,
      "step": 20
    },
    {
      "epoch": 0.02410122514561157,
      "grad_norm": 0.27274540066719055,
      "learning_rate": 0.0001985542168674699,
      "loss": 0.5358,
      "step": 30
    },
    {
      "epoch": 0.03213496686081543,
      "grad_norm": 0.2697281539440155,
      "learning_rate": 0.00019801874163319946,
      "loss": 0.4868,
      "step": 40
    },
    {
      "epoch": 0.04016870857601928,
      "grad_norm": 0.3254106938838959,
      "learning_rate": 0.00019748326639892907,
      "loss": 0.5358,
      "step": 50
    },
    {
      "epoch": 0.04820245029122314,
      "grad_norm": 0.3368348479270935,
      "learning_rate": 0.00019694779116465866,
      "loss": 0.5444,
      "step": 60
    },
    {
      "epoch": 0.056236192006426995,
      "grad_norm": 0.2133895754814148,
      "learning_rate": 0.00019641231593038822,
      "loss": 0.4039,
      "step": 70
    },
    {
      "epoch": 0.06426993372163085,
      "grad_norm": 0.3219776153564453,
      "learning_rate": 0.00019587684069611783,
      "loss": 0.4511,
      "step": 80
    },
    {
      "epoch": 0.0723036754368347,
      "grad_norm": 0.30520257353782654,
      "learning_rate": 0.00019534136546184742,
      "loss": 0.4859,
      "step": 90
    },
    {
      "epoch": 0.08033741715203856,
      "grad_norm": 0.28878071904182434,
      "learning_rate": 0.00019480589022757697,
      "loss": 0.4267,
      "step": 100
    },
    {
      "epoch": 0.08837115886724242,
      "grad_norm": 0.2603961229324341,
      "learning_rate": 0.00019427041499330656,
      "loss": 0.4352,
      "step": 110
    },
    {
      "epoch": 0.09640490058244627,
      "grad_norm": 0.2261233627796173,
      "learning_rate": 0.00019373493975903617,
      "loss": 0.4654,
      "step": 120
    },
    {
      "epoch": 0.10443864229765012,
      "grad_norm": 0.2439500093460083,
      "learning_rate": 0.00019319946452476573,
      "loss": 0.4454,
      "step": 130
    },
    {
      "epoch": 0.11247238401285399,
      "grad_norm": 0.24835407733917236,
      "learning_rate": 0.00019266398929049532,
      "loss": 0.4423,
      "step": 140
    },
    {
      "epoch": 0.12050612572805784,
      "grad_norm": 0.2820044159889221,
      "learning_rate": 0.00019212851405622493,
      "loss": 0.5221,
      "step": 150
    },
    {
      "epoch": 0.1285398674432617,
      "grad_norm": 0.2305702269077301,
      "learning_rate": 0.0001915930388219545,
      "loss": 0.4302,
      "step": 160
    },
    {
      "epoch": 0.13657360915846556,
      "grad_norm": 0.21414883434772491,
      "learning_rate": 0.00019105756358768407,
      "loss": 0.4498,
      "step": 170
    },
    {
      "epoch": 0.1446073508736694,
      "grad_norm": 0.22551341354846954,
      "learning_rate": 0.00019052208835341369,
      "loss": 0.4543,
      "step": 180
    },
    {
      "epoch": 0.15264109258887326,
      "grad_norm": 0.22646573185920715,
      "learning_rate": 0.00018998661311914324,
      "loss": 0.4838,
      "step": 190
    },
    {
      "epoch": 0.1606748343040771,
      "grad_norm": 0.22690428793430328,
      "learning_rate": 0.00018945113788487283,
      "loss": 0.4376,
      "step": 200
    },
    {
      "epoch": 0.168708576019281,
      "grad_norm": 0.2163514792919159,
      "learning_rate": 0.00018891566265060242,
      "loss": 0.4391,
      "step": 210
    },
    {
      "epoch": 0.17674231773448484,
      "grad_norm": 0.23566676676273346,
      "learning_rate": 0.000188380187416332,
      "loss": 0.4775,
      "step": 220
    },
    {
      "epoch": 0.1847760594496887,
      "grad_norm": 0.21516543626785278,
      "learning_rate": 0.0001878447121820616,
      "loss": 0.4381,
      "step": 230
    },
    {
      "epoch": 0.19280980116489255,
      "grad_norm": 0.24172808229923248,
      "learning_rate": 0.00018730923694779117,
      "loss": 0.4331,
      "step": 240
    },
    {
      "epoch": 0.2008435428800964,
      "grad_norm": 0.26499494910240173,
      "learning_rate": 0.00018677376171352076,
      "loss": 0.4032,
      "step": 250
    },
    {
      "epoch": 0.20887728459530025,
      "grad_norm": 0.23649801313877106,
      "learning_rate": 0.00018623828647925034,
      "loss": 0.4158,
      "step": 260
    },
    {
      "epoch": 0.21691102631050413,
      "grad_norm": 0.20637226104736328,
      "learning_rate": 0.00018570281124497993,
      "loss": 0.4153,
      "step": 270
    },
    {
      "epoch": 0.22494476802570798,
      "grad_norm": 0.22066718339920044,
      "learning_rate": 0.00018516733601070952,
      "loss": 0.4103,
      "step": 280
    },
    {
      "epoch": 0.23297850974091183,
      "grad_norm": 0.1991472840309143,
      "learning_rate": 0.0001846318607764391,
      "loss": 0.4392,
      "step": 290
    },
    {
      "epoch": 0.24101225145611568,
      "grad_norm": 0.2619296908378601,
      "learning_rate": 0.0001840963855421687,
      "loss": 0.4674,
      "step": 300
    },
    {
      "epoch": 0.24904599317131954,
      "grad_norm": 0.2240721583366394,
      "learning_rate": 0.00018356091030789827,
      "loss": 0.4833,
      "step": 310
    },
    {
      "epoch": 0.2570797348865234,
      "grad_norm": 0.20903994143009186,
      "learning_rate": 0.00018302543507362786,
      "loss": 0.4732,
      "step": 320
    },
    {
      "epoch": 0.26511347660172724,
      "grad_norm": 0.16380032896995544,
      "learning_rate": 0.00018248995983935744,
      "loss": 0.4103,
      "step": 330
    },
    {
      "epoch": 0.2731472183169311,
      "grad_norm": 0.20191846787929535,
      "learning_rate": 0.00018195448460508703,
      "loss": 0.4657,
      "step": 340
    },
    {
      "epoch": 0.28118096003213494,
      "grad_norm": 0.2295970320701599,
      "learning_rate": 0.00018141900937081661,
      "loss": 0.4196,
      "step": 350
    },
    {
      "epoch": 0.2892147017473388,
      "grad_norm": 0.20007199048995972,
      "learning_rate": 0.0001808835341365462,
      "loss": 0.4883,
      "step": 360
    },
    {
      "epoch": 0.2972484434625427,
      "grad_norm": 0.17337796092033386,
      "learning_rate": 0.00018034805890227579,
      "loss": 0.4095,
      "step": 370
    },
    {
      "epoch": 0.3052821851777465,
      "grad_norm": 0.20329415798187256,
      "learning_rate": 0.00017981258366800537,
      "loss": 0.4449,
      "step": 380
    },
    {
      "epoch": 0.3133159268929504,
      "grad_norm": 0.16563549637794495,
      "learning_rate": 0.00017927710843373496,
      "loss": 0.4468,
      "step": 390
    },
    {
      "epoch": 0.3213496686081542,
      "grad_norm": 0.23716925084590912,
      "learning_rate": 0.00017874163319946454,
      "loss": 0.4099,
      "step": 400
    },
    {
      "epoch": 0.3293834103233581,
      "grad_norm": 0.20661552250385284,
      "learning_rate": 0.0001782061579651941,
      "loss": 0.409,
      "step": 410
    },
    {
      "epoch": 0.337417152038562,
      "grad_norm": 0.1957511156797409,
      "learning_rate": 0.00017767068273092371,
      "loss": 0.3842,
      "step": 420
    },
    {
      "epoch": 0.3454508937537658,
      "grad_norm": 0.1871669888496399,
      "learning_rate": 0.0001771352074966533,
      "loss": 0.456,
      "step": 430
    },
    {
      "epoch": 0.3534846354689697,
      "grad_norm": 0.1884123980998993,
      "learning_rate": 0.00017659973226238286,
      "loss": 0.4141,
      "step": 440
    },
    {
      "epoch": 0.3615183771841735,
      "grad_norm": 0.20582698285579681,
      "learning_rate": 0.00017606425702811247,
      "loss": 0.4629,
      "step": 450
    },
    {
      "epoch": 0.3695521188993774,
      "grad_norm": 0.24805234372615814,
      "learning_rate": 0.00017552878179384206,
      "loss": 0.4226,
      "step": 460
    },
    {
      "epoch": 0.3775858606145812,
      "grad_norm": 0.20405986905097961,
      "learning_rate": 0.00017499330655957162,
      "loss": 0.3968,
      "step": 470
    },
    {
      "epoch": 0.3856196023297851,
      "grad_norm": 0.20246562361717224,
      "learning_rate": 0.00017445783132530123,
      "loss": 0.4368,
      "step": 480
    },
    {
      "epoch": 0.393653344044989,
      "grad_norm": 0.2127695381641388,
      "learning_rate": 0.00017392235609103081,
      "loss": 0.4763,
      "step": 490
    },
    {
      "epoch": 0.4016870857601928,
      "grad_norm": 0.17338618636131287,
      "learning_rate": 0.00017338688085676037,
      "loss": 0.507,
      "step": 500
    },
    {
      "epoch": 0.4097208274753967,
      "grad_norm": 0.22318929433822632,
      "learning_rate": 0.00017285140562248996,
      "loss": 0.4136,
      "step": 510
    },
    {
      "epoch": 0.4177545691906005,
      "grad_norm": 0.21907584369182587,
      "learning_rate": 0.00017231593038821957,
      "loss": 0.4341,
      "step": 520
    },
    {
      "epoch": 0.4257883109058044,
      "grad_norm": 0.21428196132183075,
      "learning_rate": 0.00017178045515394913,
      "loss": 0.4283,
      "step": 530
    },
    {
      "epoch": 0.43382205262100826,
      "grad_norm": 0.22335073351860046,
      "learning_rate": 0.00017124497991967871,
      "loss": 0.4515,
      "step": 540
    },
    {
      "epoch": 0.4418557943362121,
      "grad_norm": 0.18083858489990234,
      "learning_rate": 0.00017070950468540833,
      "loss": 0.5201,
      "step": 550
    },
    {
      "epoch": 0.44988953605141596,
      "grad_norm": 0.2371758222579956,
      "learning_rate": 0.00017017402945113789,
      "loss": 0.4027,
      "step": 560
    },
    {
      "epoch": 0.4579232777666198,
      "grad_norm": 0.20005950331687927,
      "learning_rate": 0.00016963855421686747,
      "loss": 0.4316,
      "step": 570
    },
    {
      "epoch": 0.46595701948182366,
      "grad_norm": 0.25928258895874023,
      "learning_rate": 0.00016910307898259708,
      "loss": 0.4413,
      "step": 580
    },
    {
      "epoch": 0.4739907611970275,
      "grad_norm": 0.17014247179031372,
      "learning_rate": 0.00016856760374832664,
      "loss": 0.4388,
      "step": 590
    },
    {
      "epoch": 0.48202450291223137,
      "grad_norm": 0.26768606901168823,
      "learning_rate": 0.00016803212851405623,
      "loss": 0.4119,
      "step": 600
    },
    {
      "epoch": 0.49005824462743525,
      "grad_norm": 0.2324385643005371,
      "learning_rate": 0.00016749665327978581,
      "loss": 0.4288,
      "step": 610
    },
    {
      "epoch": 0.49809198634263907,
      "grad_norm": 0.19439704716205597,
      "learning_rate": 0.0001669611780455154,
      "loss": 0.456,
      "step": 620
    },
    {
      "epoch": 0.506125728057843,
      "grad_norm": 0.24154482781887054,
      "learning_rate": 0.00016642570281124499,
      "loss": 0.3855,
      "step": 630
    },
    {
      "epoch": 0.5141594697730468,
      "grad_norm": 0.21832583844661713,
      "learning_rate": 0.00016589022757697457,
      "loss": 0.4704,
      "step": 640
    },
    {
      "epoch": 0.5221932114882507,
      "grad_norm": 0.23757041990756989,
      "learning_rate": 0.00016535475234270416,
      "loss": 0.4725,
      "step": 650
    },
    {
      "epoch": 0.5302269532034545,
      "grad_norm": 0.21809662878513336,
      "learning_rate": 0.00016481927710843374,
      "loss": 0.4362,
      "step": 660
    },
    {
      "epoch": 0.5382606949186584,
      "grad_norm": 0.2550409138202667,
      "learning_rate": 0.00016428380187416333,
      "loss": 0.4175,
      "step": 670
    },
    {
      "epoch": 0.5462944366338622,
      "grad_norm": 0.1967543065547943,
      "learning_rate": 0.00016374832663989291,
      "loss": 0.4142,
      "step": 680
    },
    {
      "epoch": 0.5543281783490661,
      "grad_norm": 0.22716736793518066,
      "learning_rate": 0.0001632128514056225,
      "loss": 0.3668,
      "step": 690
    },
    {
      "epoch": 0.5623619200642699,
      "grad_norm": 0.21152514219284058,
      "learning_rate": 0.00016267737617135208,
      "loss": 0.4084,
      "step": 700
    },
    {
      "epoch": 0.5703956617794738,
      "grad_norm": 0.17286980152130127,
      "learning_rate": 0.00016214190093708167,
      "loss": 0.4107,
      "step": 710
    },
    {
      "epoch": 0.5784294034946776,
      "grad_norm": 0.34120073914527893,
      "learning_rate": 0.00016160642570281126,
      "loss": 0.4208,
      "step": 720
    },
    {
      "epoch": 0.5864631452098815,
      "grad_norm": 0.23264890909194946,
      "learning_rate": 0.00016107095046854084,
      "loss": 0.4348,
      "step": 730
    },
    {
      "epoch": 0.5944968869250854,
      "grad_norm": 0.22570852935314178,
      "learning_rate": 0.00016053547523427043,
      "loss": 0.3815,
      "step": 740
    },
    {
      "epoch": 0.6025306286402892,
      "grad_norm": 0.21916428208351135,
      "learning_rate": 0.00016,
      "loss": 0.3505,
      "step": 750
    },
    {
      "epoch": 0.610564370355493,
      "grad_norm": 0.2203734964132309,
      "learning_rate": 0.0001594645247657296,
      "loss": 0.3929,
      "step": 760
    },
    {
      "epoch": 0.6185981120706969,
      "grad_norm": 0.17801420390605927,
      "learning_rate": 0.00015892904953145918,
      "loss": 0.3903,
      "step": 770
    },
    {
      "epoch": 0.6266318537859008,
      "grad_norm": 0.19534707069396973,
      "learning_rate": 0.00015839357429718874,
      "loss": 0.3176,
      "step": 780
    },
    {
      "epoch": 0.6346655955011047,
      "grad_norm": 0.2451646625995636,
      "learning_rate": 0.00015785809906291836,
      "loss": 0.4348,
      "step": 790
    },
    {
      "epoch": 0.6426993372163085,
      "grad_norm": 0.22583137452602386,
      "learning_rate": 0.00015732262382864794,
      "loss": 0.3547,
      "step": 800
    },
    {
      "epoch": 0.6507330789315123,
      "grad_norm": 0.1758325695991516,
      "learning_rate": 0.0001567871485943775,
      "loss": 0.338,
      "step": 810
    },
    {
      "epoch": 0.6587668206467162,
      "grad_norm": 0.20006053149700165,
      "learning_rate": 0.0001562516733601071,
      "loss": 0.3391,
      "step": 820
    },
    {
      "epoch": 0.6668005623619201,
      "grad_norm": 0.2508776783943176,
      "learning_rate": 0.0001557161981258367,
      "loss": 0.4166,
      "step": 830
    },
    {
      "epoch": 0.674834304077124,
      "grad_norm": 0.27153199911117554,
      "learning_rate": 0.00015518072289156626,
      "loss": 0.4386,
      "step": 840
    },
    {
      "epoch": 0.6828680457923277,
      "grad_norm": 0.2080046832561493,
      "learning_rate": 0.00015464524765729587,
      "loss": 0.374,
      "step": 850
    },
    {
      "epoch": 0.6909017875075316,
      "grad_norm": 0.17246730625629425,
      "learning_rate": 0.00015410977242302546,
      "loss": 0.3244,
      "step": 860
    },
    {
      "epoch": 0.6989355292227355,
      "grad_norm": 0.2656323313713074,
      "learning_rate": 0.00015357429718875501,
      "loss": 0.4165,
      "step": 870
    },
    {
      "epoch": 0.7069692709379394,
      "grad_norm": 0.2481265813112259,
      "learning_rate": 0.0001530388219544846,
      "loss": 0.3908,
      "step": 880
    },
    {
      "epoch": 0.7150030126531433,
      "grad_norm": 0.22763706743717194,
      "learning_rate": 0.0001525033467202142,
      "loss": 0.3541,
      "step": 890
    },
    {
      "epoch": 0.723036754368347,
      "grad_norm": 0.19910573959350586,
      "learning_rate": 0.00015196787148594377,
      "loss": 0.3795,
      "step": 900
    },
    {
      "epoch": 0.7310704960835509,
      "grad_norm": 0.2121638059616089,
      "learning_rate": 0.00015143239625167336,
      "loss": 0.3562,
      "step": 910
    },
    {
      "epoch": 0.7391042377987548,
      "grad_norm": 0.18302994966506958,
      "learning_rate": 0.00015089692101740297,
      "loss": 0.3453,
      "step": 920
    },
    {
      "epoch": 0.7471379795139587,
      "grad_norm": 0.18843090534210205,
      "learning_rate": 0.00015036144578313253,
      "loss": 0.3854,
      "step": 930
    },
    {
      "epoch": 0.7551717212291624,
      "grad_norm": 0.2186533808708191,
      "learning_rate": 0.0001498259705488621,
      "loss": 0.3722,
      "step": 940
    },
    {
      "epoch": 0.7632054629443663,
      "grad_norm": 0.21920454502105713,
      "learning_rate": 0.00014929049531459173,
      "loss": 0.3959,
      "step": 950
    },
    {
      "epoch": 0.7712392046595702,
      "grad_norm": 0.1929076462984085,
      "learning_rate": 0.00014875502008032128,
      "loss": 0.3837,
      "step": 960
    },
    {
      "epoch": 0.7792729463747741,
      "grad_norm": 0.17810696363449097,
      "learning_rate": 0.00014821954484605087,
      "loss": 0.3452,
      "step": 970
    },
    {
      "epoch": 0.787306688089978,
      "grad_norm": 0.2561005651950836,
      "learning_rate": 0.00014768406961178046,
      "loss": 0.3767,
      "step": 980
    },
    {
      "epoch": 0.7953404298051817,
      "grad_norm": 0.30869072675704956,
      "learning_rate": 0.00014714859437751004,
      "loss": 0.4368,
      "step": 990
    },
    {
      "epoch": 0.8033741715203856,
      "grad_norm": 0.20675168931484222,
      "learning_rate": 0.00014661311914323963,
      "loss": 0.3202,
      "step": 1000
    },
    {
      "epoch": 0.8114079132355895,
      "grad_norm": 0.19101428985595703,
      "learning_rate": 0.0001460776439089692,
      "loss": 0.3756,
      "step": 1010
    },
    {
      "epoch": 0.8194416549507934,
      "grad_norm": 0.2381686121225357,
      "learning_rate": 0.0001455421686746988,
      "loss": 0.3994,
      "step": 1020
    },
    {
      "epoch": 0.8274753966659972,
      "grad_norm": 0.2507588565349579,
      "learning_rate": 0.00014500669344042838,
      "loss": 0.4189,
      "step": 1030
    },
    {
      "epoch": 0.835509138381201,
      "grad_norm": 0.30224180221557617,
      "learning_rate": 0.00014447121820615797,
      "loss": 0.4142,
      "step": 1040
    },
    {
      "epoch": 0.8435428800964049,
      "grad_norm": 0.20850928127765656,
      "learning_rate": 0.00014393574297188756,
      "loss": 0.366,
      "step": 1050
    },
    {
      "epoch": 0.8515766218116088,
      "grad_norm": 0.18256916105747223,
      "learning_rate": 0.00014340026773761714,
      "loss": 0.3213,
      "step": 1060
    },
    {
      "epoch": 0.8596103635268126,
      "grad_norm": 0.18299731612205505,
      "learning_rate": 0.00014286479250334673,
      "loss": 0.3581,
      "step": 1070
    },
    {
      "epoch": 0.8676441052420165,
      "grad_norm": 0.15771929919719696,
      "learning_rate": 0.0001423293172690763,
      "loss": 0.393,
      "step": 1080
    },
    {
      "epoch": 0.8756778469572203,
      "grad_norm": 0.21335934102535248,
      "learning_rate": 0.0001417938420348059,
      "loss": 0.401,
      "step": 1090
    },
    {
      "epoch": 0.8837115886724242,
      "grad_norm": 0.23628227412700653,
      "learning_rate": 0.00014125836680053548,
      "loss": 0.402,
      "step": 1100
    },
    {
      "epoch": 0.891745330387628,
      "grad_norm": 0.28371793031692505,
      "learning_rate": 0.00014072289156626507,
      "loss": 0.3997,
      "step": 1110
    },
    {
      "epoch": 0.8997790721028319,
      "grad_norm": 0.2388913333415985,
      "learning_rate": 0.00014018741633199465,
      "loss": 0.3734,
      "step": 1120
    },
    {
      "epoch": 0.9078128138180358,
      "grad_norm": 0.2081468105316162,
      "learning_rate": 0.00013965194109772424,
      "loss": 0.3668,
      "step": 1130
    },
    {
      "epoch": 0.9158465555332396,
      "grad_norm": 0.2579735517501831,
      "learning_rate": 0.00013911646586345383,
      "loss": 0.3427,
      "step": 1140
    },
    {
      "epoch": 0.9238802972484434,
      "grad_norm": 0.19921037554740906,
      "learning_rate": 0.0001385809906291834,
      "loss": 0.3426,
      "step": 1150
    },
    {
      "epoch": 0.9319140389636473,
      "grad_norm": 0.19951798021793365,
      "learning_rate": 0.000138045515394913,
      "loss": 0.3877,
      "step": 1160
    },
    {
      "epoch": 0.9399477806788512,
      "grad_norm": 0.20289741456508636,
      "learning_rate": 0.00013751004016064258,
      "loss": 0.399,
      "step": 1170
    },
    {
      "epoch": 0.947981522394055,
      "grad_norm": 0.2422320395708084,
      "learning_rate": 0.00013697456492637214,
      "loss": 0.4071,
      "step": 1180
    },
    {
      "epoch": 0.9560152641092589,
      "grad_norm": 0.17441679537296295,
      "learning_rate": 0.00013643908969210175,
      "loss": 0.354,
      "step": 1190
    },
    {
      "epoch": 0.9640490058244627,
      "grad_norm": 0.17903202772140503,
      "learning_rate": 0.00013590361445783134,
      "loss": 0.4123,
      "step": 1200
    },
    {
      "epoch": 0.9720827475396666,
      "grad_norm": 0.17970091104507446,
      "learning_rate": 0.0001353681392235609,
      "loss": 0.3548,
      "step": 1210
    },
    {
      "epoch": 0.9801164892548705,
      "grad_norm": 0.34728384017944336,
      "learning_rate": 0.0001348326639892905,
      "loss": 0.4056,
      "step": 1220
    },
    {
      "epoch": 0.9881502309700743,
      "grad_norm": 0.20289669930934906,
      "learning_rate": 0.0001342971887550201,
      "loss": 0.3378,
      "step": 1230
    },
    {
      "epoch": 0.9961839726852781,
      "grad_norm": 0.22148609161376953,
      "learning_rate": 0.00013376171352074965,
      "loss": 0.3503,
      "step": 1240
    },
    {
      "epoch": 1.0040168708576018,
      "grad_norm": 0.21025404334068298,
      "learning_rate": 0.00013322623828647927,
      "loss": 0.4153,
      "step": 1250
    },
    {
      "epoch": 1.0120506125728057,
      "grad_norm": 0.2411973476409912,
      "learning_rate": 0.00013269076305220885,
      "loss": 0.3553,
      "step": 1260
    },
    {
      "epoch": 1.0200843542880096,
      "grad_norm": 0.21799862384796143,
      "learning_rate": 0.0001321552878179384,
      "loss": 0.4613,
      "step": 1270
    },
    {
      "epoch": 1.0281180960032135,
      "grad_norm": 0.246332585811615,
      "learning_rate": 0.000131619812583668,
      "loss": 0.3224,
      "step": 1280
    },
    {
      "epoch": 1.0361518377184173,
      "grad_norm": 0.2858455777168274,
      "learning_rate": 0.0001310843373493976,
      "loss": 0.3304,
      "step": 1290
    },
    {
      "epoch": 1.0441855794336212,
      "grad_norm": 0.24395707249641418,
      "learning_rate": 0.00013054886211512717,
      "loss": 0.3921,
      "step": 1300
    },
    {
      "epoch": 1.052219321148825,
      "grad_norm": 0.23404213786125183,
      "learning_rate": 0.00013001338688085675,
      "loss": 0.3547,
      "step": 1310
    },
    {
      "epoch": 1.060253062864029,
      "grad_norm": 0.2077709138393402,
      "learning_rate": 0.00012947791164658637,
      "loss": 0.3528,
      "step": 1320
    },
    {
      "epoch": 1.0682868045792329,
      "grad_norm": 0.2238084375858307,
      "learning_rate": 0.00012894243641231593,
      "loss": 0.3443,
      "step": 1330
    },
    {
      "epoch": 1.0763205462944367,
      "grad_norm": 0.20972716808319092,
      "learning_rate": 0.0001284069611780455,
      "loss": 0.36,
      "step": 1340
    },
    {
      "epoch": 1.0843542880096404,
      "grad_norm": 0.2123727649450302,
      "learning_rate": 0.00012787148594377512,
      "loss": 0.3648,
      "step": 1350
    },
    {
      "epoch": 1.0923880297248443,
      "grad_norm": 0.17604078352451324,
      "learning_rate": 0.00012733601070950468,
      "loss": 0.3589,
      "step": 1360
    },
    {
      "epoch": 1.1004217714400482,
      "grad_norm": 0.23872920870780945,
      "learning_rate": 0.00012680053547523427,
      "loss": 0.4228,
      "step": 1370
    },
    {
      "epoch": 1.108455513155252,
      "grad_norm": 0.27258363366127014,
      "learning_rate": 0.00012626506024096385,
      "loss": 0.4359,
      "step": 1380
    },
    {
      "epoch": 1.116489254870456,
      "grad_norm": 0.19572122395038605,
      "learning_rate": 0.00012572958500669344,
      "loss": 0.3864,
      "step": 1390
    },
    {
      "epoch": 1.1245229965856598,
      "grad_norm": 0.2099531590938568,
      "learning_rate": 0.00012519410977242303,
      "loss": 0.3648,
      "step": 1400
    },
    {
      "epoch": 1.1325567383008637,
      "grad_norm": 0.20813390612602234,
      "learning_rate": 0.0001246586345381526,
      "loss": 0.4238,
      "step": 1410
    },
    {
      "epoch": 1.1405904800160676,
      "grad_norm": 0.2050723284482956,
      "learning_rate": 0.0001241231593038822,
      "loss": 0.4057,
      "step": 1420
    },
    {
      "epoch": 1.1486242217312714,
      "grad_norm": 0.21433116495609283,
      "learning_rate": 0.00012358768406961178,
      "loss": 0.3699,
      "step": 1430
    },
    {
      "epoch": 1.156657963446475,
      "grad_norm": 0.20369383692741394,
      "learning_rate": 0.00012305220883534137,
      "loss": 0.3622,
      "step": 1440
    },
    {
      "epoch": 1.164691705161679,
      "grad_norm": 0.22480599582195282,
      "learning_rate": 0.00012251673360107095,
      "loss": 0.3709,
      "step": 1450
    },
    {
      "epoch": 1.1727254468768828,
      "grad_norm": 0.24358583986759186,
      "learning_rate": 0.00012198125836680054,
      "loss": 0.3541,
      "step": 1460
    },
    {
      "epoch": 1.1807591885920867,
      "grad_norm": 0.19848763942718506,
      "learning_rate": 0.00012144578313253012,
      "loss": 0.3797,
      "step": 1470
    },
    {
      "epoch": 1.1887929303072906,
      "grad_norm": 0.19707661867141724,
      "learning_rate": 0.0001209103078982597,
      "loss": 0.3842,
      "step": 1480
    },
    {
      "epoch": 1.1968266720224945,
      "grad_norm": 0.21157968044281006,
      "learning_rate": 0.0001203748326639893,
      "loss": 0.3875,
      "step": 1490
    },
    {
      "epoch": 1.2048604137376984,
      "grad_norm": 0.22039122879505157,
      "learning_rate": 0.00011983935742971888,
      "loss": 0.342,
      "step": 1500
    },
    {
      "epoch": 1.2128941554529022,
      "grad_norm": 0.21861785650253296,
      "learning_rate": 0.00011930388219544845,
      "loss": 0.3512,
      "step": 1510
    },
    {
      "epoch": 1.2209278971681061,
      "grad_norm": 0.277175635099411,
      "learning_rate": 0.00011876840696117805,
      "loss": 0.3327,
      "step": 1520
    },
    {
      "epoch": 1.2289616388833098,
      "grad_norm": 0.31667569279670715,
      "learning_rate": 0.00011823293172690764,
      "loss": 0.3824,
      "step": 1530
    },
    {
      "epoch": 1.2369953805985137,
      "grad_norm": 0.28321242332458496,
      "learning_rate": 0.00011769745649263721,
      "loss": 0.3765,
      "step": 1540
    },
    {
      "epoch": 1.2450291223137175,
      "grad_norm": 0.20964811742305756,
      "learning_rate": 0.00011716198125836681,
      "loss": 0.3762,
      "step": 1550
    },
    {
      "epoch": 1.2530628640289214,
      "grad_norm": 0.21235890686511993,
      "learning_rate": 0.0001166265060240964,
      "loss": 0.4174,
      "step": 1560
    },
    {
      "epoch": 1.2610966057441253,
      "grad_norm": 0.18887633085250854,
      "learning_rate": 0.00011609103078982597,
      "loss": 0.3541,
      "step": 1570
    },
    {
      "epoch": 1.2691303474593292,
      "grad_norm": 0.28848013281822205,
      "learning_rate": 0.00011555555555555555,
      "loss": 0.3831,
      "step": 1580
    },
    {
      "epoch": 1.277164089174533,
      "grad_norm": 0.2641180157661438,
      "learning_rate": 0.00011502008032128515,
      "loss": 0.3338,
      "step": 1590
    },
    {
      "epoch": 1.285197830889737,
      "grad_norm": 0.19582973420619965,
      "learning_rate": 0.00011448460508701472,
      "loss": 0.3248,
      "step": 1600
    },
    {
      "epoch": 1.2932315726049408,
      "grad_norm": 0.2550804615020752,
      "learning_rate": 0.00011394912985274431,
      "loss": 0.3856,
      "step": 1610
    },
    {
      "epoch": 1.3012653143201445,
      "grad_norm": 0.19659313559532166,
      "learning_rate": 0.00011341365461847391,
      "loss": 0.38,
      "step": 1620
    },
    {
      "epoch": 1.3092990560353486,
      "grad_norm": 0.2583557963371277,
      "learning_rate": 0.00011287817938420348,
      "loss": 0.3662,
      "step": 1630
    },
    {
      "epoch": 1.3173327977505522,
      "grad_norm": 0.22443416714668274,
      "learning_rate": 0.00011234270414993307,
      "loss": 0.3633,
      "step": 1640
    },
    {
      "epoch": 1.325366539465756,
      "grad_norm": 0.22605152428150177,
      "learning_rate": 0.00011180722891566267,
      "loss": 0.3494,
      "step": 1650
    },
    {
      "epoch": 1.33340028118096,
      "grad_norm": 0.22392763197422028,
      "learning_rate": 0.00011127175368139224,
      "loss": 0.3389,
      "step": 1660
    },
    {
      "epoch": 1.3414340228961639,
      "grad_norm": 0.2192889302968979,
      "learning_rate": 0.00011073627844712182,
      "loss": 0.3472,
      "step": 1670
    },
    {
      "epoch": 1.3494677646113677,
      "grad_norm": 0.20917446911334991,
      "learning_rate": 0.0001102008032128514,
      "loss": 0.3544,
      "step": 1680
    },
    {
      "epoch": 1.3575015063265716,
      "grad_norm": 0.2761863172054291,
      "learning_rate": 0.000109665327978581,
      "loss": 0.3811,
      "step": 1690
    },
    {
      "epoch": 1.3655352480417755,
      "grad_norm": 0.19150669872760773,
      "learning_rate": 0.00010912985274431058,
      "loss": 0.3246,
      "step": 1700
    },
    {
      "epoch": 1.3735689897569794,
      "grad_norm": 0.22120584547519684,
      "learning_rate": 0.00010859437751004015,
      "loss": 0.3329,
      "step": 1710
    },
    {
      "epoch": 1.3816027314721833,
      "grad_norm": 0.23309999704360962,
      "learning_rate": 0.00010805890227576975,
      "loss": 0.3741,
      "step": 1720
    },
    {
      "epoch": 1.389636473187387,
      "grad_norm": 0.2623259127140045,
      "learning_rate": 0.00010752342704149934,
      "loss": 0.4315,
      "step": 1730
    },
    {
      "epoch": 1.3976702149025908,
      "grad_norm": 0.235374316573143,
      "learning_rate": 0.00010698795180722891,
      "loss": 0.3168,
      "step": 1740
    },
    {
      "epoch": 1.4057039566177947,
      "grad_norm": 0.23128081858158112,
      "learning_rate": 0.00010645247657295851,
      "loss": 0.3814,
      "step": 1750
    },
    {
      "epoch": 1.4137376983329986,
      "grad_norm": 0.2060771882534027,
      "learning_rate": 0.0001059170013386881,
      "loss": 0.3694,
      "step": 1760
    },
    {
      "epoch": 1.4217714400482024,
      "grad_norm": 0.2314344197511673,
      "learning_rate": 0.00010538152610441767,
      "loss": 0.3971,
      "step": 1770
    },
    {
      "epoch": 1.4298051817634063,
      "grad_norm": 0.3063316345214844,
      "learning_rate": 0.00010484605087014725,
      "loss": 0.3518,
      "step": 1780
    },
    {
      "epoch": 1.4378389234786102,
      "grad_norm": 0.25503385066986084,
      "learning_rate": 0.00010431057563587685,
      "loss": 0.3999,
      "step": 1790
    },
    {
      "epoch": 1.445872665193814,
      "grad_norm": 0.24630536139011383,
      "learning_rate": 0.00010377510040160642,
      "loss": 0.356,
      "step": 1800
    },
    {
      "epoch": 1.453906406909018,
      "grad_norm": 0.26521536707878113,
      "learning_rate": 0.00010323962516733601,
      "loss": 0.3626,
      "step": 1810
    },
    {
      "epoch": 1.4619401486242216,
      "grad_norm": 0.2676689624786377,
      "learning_rate": 0.00010270414993306561,
      "loss": 0.3422,
      "step": 1820
    },
    {
      "epoch": 1.4699738903394257,
      "grad_norm": 0.24699358642101288,
      "learning_rate": 0.00010216867469879518,
      "loss": 0.3604,
      "step": 1830
    },
    {
      "epoch": 1.4780076320546294,
      "grad_norm": 0.17629535496234894,
      "learning_rate": 0.00010163319946452477,
      "loss": 0.2943,
      "step": 1840
    },
    {
      "epoch": 1.4860413737698333,
      "grad_norm": 0.21683256328105927,
      "learning_rate": 0.00010109772423025437,
      "loss": 0.37,
      "step": 1850
    },
    {
      "epoch": 1.4940751154850371,
      "grad_norm": 0.26659059524536133,
      "learning_rate": 0.00010056224899598394,
      "loss": 0.361,
      "step": 1860
    },
    {
      "epoch": 1.502108857200241,
      "grad_norm": 0.25621628761291504,
      "learning_rate": 0.00010002677376171352,
      "loss": 0.3924,
      "step": 1870
    },
    {
      "epoch": 1.510142598915445,
      "grad_norm": 0.2238258421421051,
      "learning_rate": 9.949129852744311e-05,
      "loss": 0.3396,
      "step": 1880
    },
    {
      "epoch": 1.5181763406306488,
      "grad_norm": 0.23072418570518494,
      "learning_rate": 9.89558232931727e-05,
      "loss": 0.3965,
      "step": 1890
    },
    {
      "epoch": 1.5262100823458526,
      "grad_norm": 0.24812249839305878,
      "learning_rate": 9.842034805890228e-05,
      "loss": 0.3959,
      "step": 1900
    },
    {
      "epoch": 1.5342438240610563,
      "grad_norm": 0.21507136523723602,
      "learning_rate": 9.788487282463187e-05,
      "loss": 0.3535,
      "step": 1910
    },
    {
      "epoch": 1.5422775657762604,
      "grad_norm": 0.2743983268737793,
      "learning_rate": 9.734939759036145e-05,
      "loss": 0.3994,
      "step": 1920
    },
    {
      "epoch": 1.550311307491464,
      "grad_norm": 0.27434444427490234,
      "learning_rate": 9.681392235609104e-05,
      "loss": 0.375,
      "step": 1930
    },
    {
      "epoch": 1.5583450492066682,
      "grad_norm": 0.2638346552848816,
      "learning_rate": 9.627844712182062e-05,
      "loss": 0.3438,
      "step": 1940
    },
    {
      "epoch": 1.5663787909218718,
      "grad_norm": 0.2071731835603714,
      "learning_rate": 9.574297188755021e-05,
      "loss": 0.344,
      "step": 1950
    },
    {
      "epoch": 1.5744125326370757,
      "grad_norm": 0.22280021011829376,
      "learning_rate": 9.52074966532798e-05,
      "loss": 0.3769,
      "step": 1960
    },
    {
      "epoch": 1.5824462743522796,
      "grad_norm": 0.22103025019168854,
      "learning_rate": 9.467202141900937e-05,
      "loss": 0.406,
      "step": 1970
    },
    {
      "epoch": 1.5904800160674835,
      "grad_norm": 0.22083590924739838,
      "learning_rate": 9.413654618473896e-05,
      "loss": 0.356,
      "step": 1980
    },
    {
      "epoch": 1.5985137577826873,
      "grad_norm": 0.23231397569179535,
      "learning_rate": 9.360107095046855e-05,
      "loss": 0.4066,
      "step": 1990
    },
    {
      "epoch": 1.606547499497891,
      "grad_norm": 0.25895750522613525,
      "learning_rate": 9.306559571619812e-05,
      "loss": 0.3718,
      "step": 2000
    },
    {
      "epoch": 1.614581241213095,
      "grad_norm": 0.2096288651227951,
      "learning_rate": 9.253012048192772e-05,
      "loss": 0.4003,
      "step": 2010
    },
    {
      "epoch": 1.6226149829282988,
      "grad_norm": 0.238925039768219,
      "learning_rate": 9.19946452476573e-05,
      "loss": 0.3564,
      "step": 2020
    },
    {
      "epoch": 1.6306487246435029,
      "grad_norm": 0.30842646956443787,
      "learning_rate": 9.145917001338688e-05,
      "loss": 0.3862,
      "step": 2030
    },
    {
      "epoch": 1.6386824663587065,
      "grad_norm": 0.19030800461769104,
      "learning_rate": 9.092369477911648e-05,
      "loss": 0.337,
      "step": 2040
    },
    {
      "epoch": 1.6467162080739104,
      "grad_norm": 0.3022247850894928,
      "learning_rate": 9.038821954484605e-05,
      "loss": 0.3682,
      "step": 2050
    },
    {
      "epoch": 1.6547499497891143,
      "grad_norm": 0.26470932364463806,
      "learning_rate": 8.985274431057564e-05,
      "loss": 0.3741,
      "step": 2060
    },
    {
      "epoch": 1.6627836915043182,
      "grad_norm": 0.22066441178321838,
      "learning_rate": 8.931726907630522e-05,
      "loss": 0.3595,
      "step": 2070
    },
    {
      "epoch": 1.670817433219522,
      "grad_norm": 0.21666333079338074,
      "learning_rate": 8.878179384203481e-05,
      "loss": 0.3428,
      "step": 2080
    },
    {
      "epoch": 1.6788511749347257,
      "grad_norm": 0.18693774938583374,
      "learning_rate": 8.824631860776439e-05,
      "loss": 0.3571,
      "step": 2090
    },
    {
      "epoch": 1.6868849166499298,
      "grad_norm": 0.27557119727134705,
      "learning_rate": 8.771084337349398e-05,
      "loss": 0.3137,
      "step": 2100
    },
    {
      "epoch": 1.6949186583651334,
      "grad_norm": 0.24219098687171936,
      "learning_rate": 8.717536813922356e-05,
      "loss": 0.3755,
      "step": 2110
    },
    {
      "epoch": 1.7029524000803375,
      "grad_norm": 0.22057904303073883,
      "learning_rate": 8.663989290495315e-05,
      "loss": 0.3169,
      "step": 2120
    },
    {
      "epoch": 1.7109861417955412,
      "grad_norm": 0.3494814336299896,
      "learning_rate": 8.610441767068274e-05,
      "loss": 0.4038,
      "step": 2130
    },
    {
      "epoch": 1.719019883510745,
      "grad_norm": 0.19113487005233765,
      "learning_rate": 8.556894243641232e-05,
      "loss": 0.3087,
      "step": 2140
    },
    {
      "epoch": 1.727053625225949,
      "grad_norm": 0.2614189684391022,
      "learning_rate": 8.503346720214191e-05,
      "loss": 0.355,
      "step": 2150
    },
    {
      "epoch": 1.7350873669411528,
      "grad_norm": 0.19660761952400208,
      "learning_rate": 8.449799196787149e-05,
      "loss": 0.3892,
      "step": 2160
    },
    {
      "epoch": 1.7431211086563567,
      "grad_norm": 0.21846309304237366,
      "learning_rate": 8.396251673360106e-05,
      "loss": 0.337,
      "step": 2170
    },
    {
      "epoch": 1.7511548503715606,
      "grad_norm": 0.2698502242565155,
      "learning_rate": 8.342704149933066e-05,
      "loss": 0.3334,
      "step": 2180
    },
    {
      "epoch": 1.7591885920867645,
      "grad_norm": 0.28796523809432983,
      "learning_rate": 8.289156626506025e-05,
      "loss": 0.4511,
      "step": 2190
    },
    {
      "epoch": 1.7672223338019681,
      "grad_norm": 0.3226747214794159,
      "learning_rate": 8.235609103078982e-05,
      "loss": 0.3582,
      "step": 2200
    },
    {
      "epoch": 1.7752560755171722,
      "grad_norm": 0.24429668486118317,
      "learning_rate": 8.182061579651942e-05,
      "loss": 0.3969,
      "step": 2210
    },
    {
      "epoch": 1.783289817232376,
      "grad_norm": 0.21187929809093475,
      "learning_rate": 8.128514056224899e-05,
      "loss": 0.3585,
      "step": 2220
    },
    {
      "epoch": 1.79132355894758,
      "grad_norm": 0.2742381989955902,
      "learning_rate": 8.074966532797858e-05,
      "loss": 0.3725,
      "step": 2230
    },
    {
      "epoch": 1.7993573006627837,
      "grad_norm": 0.19131051003932953,
      "learning_rate": 8.021419009370818e-05,
      "loss": 0.322,
      "step": 2240
    },
    {
      "epoch": 1.8073910423779875,
      "grad_norm": 0.174168661236763,
      "learning_rate": 7.967871485943775e-05,
      "loss": 0.3103,
      "step": 2250
    },
    {
      "epoch": 1.8154247840931914,
      "grad_norm": 0.21696144342422485,
      "learning_rate": 7.914323962516735e-05,
      "loss": 0.3714,
      "step": 2260
    },
    {
      "epoch": 1.8234585258083953,
      "grad_norm": 0.2576613128185272,
      "learning_rate": 7.860776439089692e-05,
      "loss": 0.3357,
      "step": 2270
    },
    {
      "epoch": 1.8314922675235992,
      "grad_norm": 0.21023418009281158,
      "learning_rate": 7.80722891566265e-05,
      "loss": 0.3237,
      "step": 2280
    },
    {
      "epoch": 1.8395260092388028,
      "grad_norm": 0.22956319153308868,
      "learning_rate": 7.75368139223561e-05,
      "loss": 0.3979,
      "step": 2290
    },
    {
      "epoch": 1.847559750954007,
      "grad_norm": 0.2887933850288391,
      "learning_rate": 7.700133868808568e-05,
      "loss": 0.4164,
      "step": 2300
    },
    {
      "epoch": 1.8555934926692106,
      "grad_norm": 0.28453823924064636,
      "learning_rate": 7.646586345381526e-05,
      "loss": 0.405,
      "step": 2310
    },
    {
      "epoch": 1.8636272343844147,
      "grad_norm": 0.20546390116214752,
      "learning_rate": 7.593038821954485e-05,
      "loss": 0.3605,
      "step": 2320
    },
    {
      "epoch": 1.8716609760996183,
      "grad_norm": 0.23203156888484955,
      "learning_rate": 7.539491298527443e-05,
      "loss": 0.3813,
      "step": 2330
    },
    {
      "epoch": 1.8796947178148222,
      "grad_norm": 0.22656196355819702,
      "learning_rate": 7.485943775100402e-05,
      "loss": 0.3669,
      "step": 2340
    },
    {
      "epoch": 1.887728459530026,
      "grad_norm": 0.21479547023773193,
      "learning_rate": 7.43239625167336e-05,
      "loss": 0.3794,
      "step": 2350
    },
    {
      "epoch": 1.89576220124523,
      "grad_norm": 0.2951812744140625,
      "learning_rate": 7.378848728246319e-05,
      "loss": 0.3353,
      "step": 2360
    },
    {
      "epoch": 1.9037959429604339,
      "grad_norm": 0.25887784361839294,
      "learning_rate": 7.325301204819278e-05,
      "loss": 0.3819,
      "step": 2370
    },
    {
      "epoch": 1.9118296846756375,
      "grad_norm": 0.2884334921836853,
      "learning_rate": 7.271753681392236e-05,
      "loss": 0.4064,
      "step": 2380
    },
    {
      "epoch": 1.9198634263908416,
      "grad_norm": 0.23540639877319336,
      "learning_rate": 7.218206157965195e-05,
      "loss": 0.3044,
      "step": 2390
    },
    {
      "epoch": 1.9278971681060453,
      "grad_norm": 0.22783619165420532,
      "learning_rate": 7.164658634538153e-05,
      "loss": 0.3525,
      "step": 2400
    },
    {
      "epoch": 1.9359309098212494,
      "grad_norm": 0.20055140554904938,
      "learning_rate": 7.111111111111112e-05,
      "loss": 0.3365,
      "step": 2410
    },
    {
      "epoch": 1.943964651536453,
      "grad_norm": 0.264608770608902,
      "learning_rate": 7.057563587684069e-05,
      "loss": 0.3423,
      "step": 2420
    },
    {
      "epoch": 1.951998393251657,
      "grad_norm": 0.22867229580879211,
      "learning_rate": 7.004016064257029e-05,
      "loss": 0.3619,
      "step": 2430
    },
    {
      "epoch": 1.9600321349668608,
      "grad_norm": 0.29081079363822937,
      "learning_rate": 6.950468540829988e-05,
      "loss": 0.4022,
      "step": 2440
    },
    {
      "epoch": 1.9680658766820647,
      "grad_norm": 0.25540319085121155,
      "learning_rate": 6.896921017402945e-05,
      "loss": 0.3174,
      "step": 2450
    },
    {
      "epoch": 1.9760996183972686,
      "grad_norm": 0.2642761170864105,
      "learning_rate": 6.843373493975905e-05,
      "loss": 0.3948,
      "step": 2460
    },
    {
      "epoch": 1.9841333601124724,
      "grad_norm": 0.20571234822273254,
      "learning_rate": 6.789825970548862e-05,
      "loss": 0.2872,
      "step": 2470
    },
    {
      "epoch": 1.9921671018276763,
      "grad_norm": 0.2754462957382202,
      "learning_rate": 6.73627844712182e-05,
      "loss": 0.3432,
      "step": 2480
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.36839279532432556,
      "learning_rate": 6.68273092369478e-05,
      "loss": 0.3764,
      "step": 2490
    },
    {
      "epoch": 2.0080337417152037,
      "grad_norm": 0.262613981962204,
      "learning_rate": 6.629183400267738e-05,
      "loss": 0.3495,
      "step": 2500
    },
    {
      "epoch": 2.0160674834304078,
      "grad_norm": 0.21317771077156067,
      "learning_rate": 6.575635876840696e-05,
      "loss": 0.3286,
      "step": 2510
    },
    {
      "epoch": 2.0241012251456114,
      "grad_norm": 0.21060994267463684,
      "learning_rate": 6.522088353413655e-05,
      "loss": 0.348,
      "step": 2520
    },
    {
      "epoch": 2.0321349668608155,
      "grad_norm": 0.18403205275535583,
      "learning_rate": 6.468540829986613e-05,
      "loss": 0.3804,
      "step": 2530
    },
    {
      "epoch": 2.040168708576019,
      "grad_norm": 0.21018195152282715,
      "learning_rate": 6.414993306559572e-05,
      "loss": 0.3457,
      "step": 2540
    },
    {
      "epoch": 2.0482024502912233,
      "grad_norm": 0.30029571056365967,
      "learning_rate": 6.36144578313253e-05,
      "loss": 0.2827,
      "step": 2550
    },
    {
      "epoch": 2.056236192006427,
      "grad_norm": 0.20262807607650757,
      "learning_rate": 6.307898259705489e-05,
      "loss": 0.2813,
      "step": 2560
    },
    {
      "epoch": 2.064269933721631,
      "grad_norm": 0.3218610882759094,
      "learning_rate": 6.254350736278448e-05,
      "loss": 0.3539,
      "step": 2570
    },
    {
      "epoch": 2.0723036754368347,
      "grad_norm": 0.2582375109195709,
      "learning_rate": 6.200803212851406e-05,
      "loss": 0.3258,
      "step": 2580
    },
    {
      "epoch": 2.0803374171520383,
      "grad_norm": 0.20623479783535004,
      "learning_rate": 6.147255689424365e-05,
      "loss": 0.3034,
      "step": 2590
    },
    {
      "epoch": 2.0883711588672424,
      "grad_norm": 0.26574379205703735,
      "learning_rate": 6.093708165997323e-05,
      "loss": 0.3399,
      "step": 2600
    },
    {
      "epoch": 2.096404900582446,
      "grad_norm": 0.2609272599220276,
      "learning_rate": 6.040160642570282e-05,
      "loss": 0.308,
      "step": 2610
    },
    {
      "epoch": 2.10443864229765,
      "grad_norm": 0.2844827175140381,
      "learning_rate": 5.98661311914324e-05,
      "loss": 0.3217,
      "step": 2620
    },
    {
      "epoch": 2.112472384012854,
      "grad_norm": 0.19114059209823608,
      "learning_rate": 5.9330655957161984e-05,
      "loss": 0.338,
      "step": 2630
    },
    {
      "epoch": 2.120506125728058,
      "grad_norm": 0.2711401879787445,
      "learning_rate": 5.8795180722891576e-05,
      "loss": 0.3256,
      "step": 2640
    },
    {
      "epoch": 2.1285398674432616,
      "grad_norm": 0.276679128408432,
      "learning_rate": 5.8259705488621155e-05,
      "loss": 0.3504,
      "step": 2650
    },
    {
      "epoch": 2.1365736091584657,
      "grad_norm": 0.2749685049057007,
      "learning_rate": 5.772423025435074e-05,
      "loss": 0.3098,
      "step": 2660
    },
    {
      "epoch": 2.1446073508736694,
      "grad_norm": 0.3031058609485626,
      "learning_rate": 5.718875502008032e-05,
      "loss": 0.3657,
      "step": 2670
    },
    {
      "epoch": 2.1526410925888735,
      "grad_norm": 0.32104694843292236,
      "learning_rate": 5.665327978580991e-05,
      "loss": 0.3597,
      "step": 2680
    },
    {
      "epoch": 2.160674834304077,
      "grad_norm": 0.2745492458343506,
      "learning_rate": 5.61178045515395e-05,
      "loss": 0.3712,
      "step": 2690
    },
    {
      "epoch": 2.168708576019281,
      "grad_norm": 0.2663492262363434,
      "learning_rate": 5.5582329317269076e-05,
      "loss": 0.3156,
      "step": 2700
    },
    {
      "epoch": 2.176742317734485,
      "grad_norm": 0.30882886052131653,
      "learning_rate": 5.504685408299867e-05,
      "loss": 0.3882,
      "step": 2710
    },
    {
      "epoch": 2.1847760594496886,
      "grad_norm": 0.29841968417167664,
      "learning_rate": 5.451137884872825e-05,
      "loss": 0.3244,
      "step": 2720
    },
    {
      "epoch": 2.1928098011648927,
      "grad_norm": 0.3082270622253418,
      "learning_rate": 5.397590361445783e-05,
      "loss": 0.3128,
      "step": 2730
    },
    {
      "epoch": 2.2008435428800963,
      "grad_norm": 0.3029526174068451,
      "learning_rate": 5.3440428380187426e-05,
      "loss": 0.3491,
      "step": 2740
    },
    {
      "epoch": 2.2088772845953004,
      "grad_norm": 0.22567908465862274,
      "learning_rate": 5.2904953145917004e-05,
      "loss": 0.3547,
      "step": 2750
    },
    {
      "epoch": 2.216911026310504,
      "grad_norm": 0.2460719347000122,
      "learning_rate": 5.236947791164659e-05,
      "loss": 0.3586,
      "step": 2760
    },
    {
      "epoch": 2.224944768025708,
      "grad_norm": 0.33361807465553284,
      "learning_rate": 5.183400267737617e-05,
      "loss": 0.3515,
      "step": 2770
    },
    {
      "epoch": 2.232978509740912,
      "grad_norm": 0.26383906602859497,
      "learning_rate": 5.129852744310576e-05,
      "loss": 0.318,
      "step": 2780
    },
    {
      "epoch": 2.2410122514561155,
      "grad_norm": 0.2913963496685028,
      "learning_rate": 5.076305220883535e-05,
      "loss": 0.365,
      "step": 2790
    },
    {
      "epoch": 2.2490459931713196,
      "grad_norm": 0.2444242686033249,
      "learning_rate": 5.0227576974564926e-05,
      "loss": 0.2879,
      "step": 2800
    },
    {
      "epoch": 2.2570797348865232,
      "grad_norm": 0.21734434366226196,
      "learning_rate": 4.969210174029451e-05,
      "loss": 0.3595,
      "step": 2810
    },
    {
      "epoch": 2.2651134766017273,
      "grad_norm": 0.3057258129119873,
      "learning_rate": 4.9156626506024104e-05,
      "loss": 0.3673,
      "step": 2820
    },
    {
      "epoch": 2.273147218316931,
      "grad_norm": 0.3189774453639984,
      "learning_rate": 4.862115127175368e-05,
      "loss": 0.2891,
      "step": 2830
    },
    {
      "epoch": 2.281180960032135,
      "grad_norm": 0.2641839385032654,
      "learning_rate": 4.808567603748327e-05,
      "loss": 0.3123,
      "step": 2840
    },
    {
      "epoch": 2.2892147017473388,
      "grad_norm": 0.31812605261802673,
      "learning_rate": 4.7550200803212854e-05,
      "loss": 0.3461,
      "step": 2850
    },
    {
      "epoch": 2.297248443462543,
      "grad_norm": 0.2873534858226776,
      "learning_rate": 4.701472556894243e-05,
      "loss": 0.3482,
      "step": 2860
    },
    {
      "epoch": 2.3052821851777465,
      "grad_norm": 0.30882441997528076,
      "learning_rate": 4.6479250334672025e-05,
      "loss": 0.3552,
      "step": 2870
    },
    {
      "epoch": 2.31331592689295,
      "grad_norm": 0.2887188494205475,
      "learning_rate": 4.594377510040161e-05,
      "loss": 0.3374,
      "step": 2880
    },
    {
      "epoch": 2.3213496686081543,
      "grad_norm": 0.2575450539588928,
      "learning_rate": 4.5408299866131196e-05,
      "loss": 0.3282,
      "step": 2890
    },
    {
      "epoch": 2.329383410323358,
      "grad_norm": 0.3605458736419678,
      "learning_rate": 4.4872824631860775e-05,
      "loss": 0.4022,
      "step": 2900
    },
    {
      "epoch": 2.337417152038562,
      "grad_norm": 0.30894735455513,
      "learning_rate": 4.433734939759036e-05,
      "loss": 0.3177,
      "step": 2910
    },
    {
      "epoch": 2.3454508937537657,
      "grad_norm": 0.2825964093208313,
      "learning_rate": 4.3801874163319953e-05,
      "loss": 0.3831,
      "step": 2920
    },
    {
      "epoch": 2.35348463546897,
      "grad_norm": 0.3611002564430237,
      "learning_rate": 4.326639892904953e-05,
      "loss": 0.3622,
      "step": 2930
    },
    {
      "epoch": 2.3615183771841735,
      "grad_norm": 0.304724782705307,
      "learning_rate": 4.273092369477912e-05,
      "loss": 0.319,
      "step": 2940
    },
    {
      "epoch": 2.3695521188993776,
      "grad_norm": 0.4157257080078125,
      "learning_rate": 4.2195448460508704e-05,
      "loss": 0.3917,
      "step": 2950
    },
    {
      "epoch": 2.377585860614581,
      "grad_norm": 0.2488096058368683,
      "learning_rate": 4.165997322623829e-05,
      "loss": 0.3565,
      "step": 2960
    },
    {
      "epoch": 2.3856196023297853,
      "grad_norm": 0.32500573992729187,
      "learning_rate": 4.1124497991967875e-05,
      "loss": 0.3563,
      "step": 2970
    },
    {
      "epoch": 2.393653344044989,
      "grad_norm": 0.2523650527000427,
      "learning_rate": 4.058902275769746e-05,
      "loss": 0.3735,
      "step": 2980
    },
    {
      "epoch": 2.4016870857601926,
      "grad_norm": 0.30728065967559814,
      "learning_rate": 4.0053547523427046e-05,
      "loss": 0.3346,
      "step": 2990
    },
    {
      "epoch": 2.4097208274753967,
      "grad_norm": 0.3365595042705536,
      "learning_rate": 3.9518072289156625e-05,
      "loss": 0.3252,
      "step": 3000
    },
    {
      "epoch": 2.4177545691906004,
      "grad_norm": 0.38716980814933777,
      "learning_rate": 3.898259705488621e-05,
      "loss": 0.3905,
      "step": 3010
    },
    {
      "epoch": 2.4257883109058045,
      "grad_norm": 0.26728343963623047,
      "learning_rate": 3.84471218206158e-05,
      "loss": 0.3619,
      "step": 3020
    },
    {
      "epoch": 2.433822052621008,
      "grad_norm": 0.2774925231933594,
      "learning_rate": 3.791164658634538e-05,
      "loss": 0.3667,
      "step": 3030
    },
    {
      "epoch": 2.4418557943362122,
      "grad_norm": 0.308668315410614,
      "learning_rate": 3.737617135207497e-05,
      "loss": 0.3108,
      "step": 3040
    },
    {
      "epoch": 2.449889536051416,
      "grad_norm": 0.28095752000808716,
      "learning_rate": 3.684069611780455e-05,
      "loss": 0.3571,
      "step": 3050
    },
    {
      "epoch": 2.4579232777666196,
      "grad_norm": 0.3753568232059479,
      "learning_rate": 3.630522088353414e-05,
      "loss": 0.3746,
      "step": 3060
    },
    {
      "epoch": 2.4659570194818237,
      "grad_norm": 0.3215799629688263,
      "learning_rate": 3.5769745649263724e-05,
      "loss": 0.3725,
      "step": 3070
    },
    {
      "epoch": 2.4739907611970273,
      "grad_norm": 0.3176068961620331,
      "learning_rate": 3.523427041499331e-05,
      "loss": 0.3573,
      "step": 3080
    },
    {
      "epoch": 2.4820245029122314,
      "grad_norm": 0.3010421097278595,
      "learning_rate": 3.4698795180722896e-05,
      "loss": 0.3296,
      "step": 3090
    },
    {
      "epoch": 2.490058244627435,
      "grad_norm": 0.2953355610370636,
      "learning_rate": 3.4163319946452474e-05,
      "loss": 0.3603,
      "step": 3100
    },
    {
      "epoch": 2.498091986342639,
      "grad_norm": 0.27942752838134766,
      "learning_rate": 3.362784471218206e-05,
      "loss": 0.3188,
      "step": 3110
    },
    {
      "epoch": 2.506125728057843,
      "grad_norm": 0.2720414102077484,
      "learning_rate": 3.309236947791165e-05,
      "loss": 0.3523,
      "step": 3120
    },
    {
      "epoch": 2.514159469773047,
      "grad_norm": 0.294866681098938,
      "learning_rate": 3.255689424364123e-05,
      "loss": 0.3125,
      "step": 3130
    },
    {
      "epoch": 2.5221932114882506,
      "grad_norm": 0.33957183361053467,
      "learning_rate": 3.202141900937082e-05,
      "loss": 0.3652,
      "step": 3140
    },
    {
      "epoch": 2.5302269532034547,
      "grad_norm": 0.2840844988822937,
      "learning_rate": 3.14859437751004e-05,
      "loss": 0.3549,
      "step": 3150
    },
    {
      "epoch": 2.5382606949186584,
      "grad_norm": 0.3433597981929779,
      "learning_rate": 3.095046854082999e-05,
      "loss": 0.3472,
      "step": 3160
    },
    {
      "epoch": 2.546294436633862,
      "grad_norm": 0.3363398313522339,
      "learning_rate": 3.0414993306559574e-05,
      "loss": 0.3715,
      "step": 3170
    },
    {
      "epoch": 2.554328178349066,
      "grad_norm": 0.3088454306125641,
      "learning_rate": 2.987951807228916e-05,
      "loss": 0.329,
      "step": 3180
    },
    {
      "epoch": 2.5623619200642698,
      "grad_norm": 0.2682492434978485,
      "learning_rate": 2.9344042838018742e-05,
      "loss": 0.3997,
      "step": 3190
    },
    {
      "epoch": 2.570395661779474,
      "grad_norm": 0.26886656880378723,
      "learning_rate": 2.8808567603748327e-05,
      "loss": 0.3489,
      "step": 3200
    },
    {
      "epoch": 2.5784294034946775,
      "grad_norm": 0.21136347949504852,
      "learning_rate": 2.827309236947791e-05,
      "loss": 0.3274,
      "step": 3210
    },
    {
      "epoch": 2.5864631452098816,
      "grad_norm": 0.2220022976398468,
      "learning_rate": 2.77376171352075e-05,
      "loss": 0.3256,
      "step": 3220
    },
    {
      "epoch": 2.5944968869250853,
      "grad_norm": 0.24567930400371552,
      "learning_rate": 2.7202141900937084e-05,
      "loss": 0.2986,
      "step": 3230
    },
    {
      "epoch": 2.602530628640289,
      "grad_norm": 0.27948325872421265,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.3333,
      "step": 3240
    },
    {
      "epoch": 2.610564370355493,
      "grad_norm": 0.2984091341495514,
      "learning_rate": 2.6131191432396252e-05,
      "loss": 0.3079,
      "step": 3250
    },
    {
      "epoch": 2.618598112070697,
      "grad_norm": 0.2693980634212494,
      "learning_rate": 2.5595716198125834e-05,
      "loss": 0.3458,
      "step": 3260
    },
    {
      "epoch": 2.626631853785901,
      "grad_norm": 0.2741018235683441,
      "learning_rate": 2.5060240963855423e-05,
      "loss": 0.3629,
      "step": 3270
    },
    {
      "epoch": 2.6346655955011045,
      "grad_norm": 0.32621172070503235,
      "learning_rate": 2.452476572958501e-05,
      "loss": 0.3272,
      "step": 3280
    },
    {
      "epoch": 2.6426993372163086,
      "grad_norm": 0.2246417999267578,
      "learning_rate": 2.398929049531459e-05,
      "loss": 0.3663,
      "step": 3290
    },
    {
      "epoch": 2.650733078931512,
      "grad_norm": 0.285453736782074,
      "learning_rate": 2.345381526104418e-05,
      "loss": 0.3242,
      "step": 3300
    },
    {
      "epoch": 2.6587668206467163,
      "grad_norm": 0.28387558460235596,
      "learning_rate": 2.2918340026773763e-05,
      "loss": 0.3437,
      "step": 3310
    },
    {
      "epoch": 2.66680056236192,
      "grad_norm": 0.3075927793979645,
      "learning_rate": 2.2382864792503348e-05,
      "loss": 0.3259,
      "step": 3320
    },
    {
      "epoch": 2.674834304077124,
      "grad_norm": 0.26055908203125,
      "learning_rate": 2.1847389558232934e-05,
      "loss": 0.3492,
      "step": 3330
    },
    {
      "epoch": 2.6828680457923277,
      "grad_norm": 0.2848292291164398,
      "learning_rate": 2.1311914323962516e-05,
      "loss": 0.3445,
      "step": 3340
    },
    {
      "epoch": 2.6909017875075314,
      "grad_norm": 0.2430519014596939,
      "learning_rate": 2.0776439089692105e-05,
      "loss": 0.3424,
      "step": 3350
    },
    {
      "epoch": 2.6989355292227355,
      "grad_norm": 0.26608240604400635,
      "learning_rate": 2.0240963855421687e-05,
      "loss": 0.3619,
      "step": 3360
    },
    {
      "epoch": 2.7069692709379396,
      "grad_norm": 0.3151749074459076,
      "learning_rate": 1.9705488621151273e-05,
      "loss": 0.3627,
      "step": 3370
    },
    {
      "epoch": 2.7150030126531433,
      "grad_norm": 0.3288150727748871,
      "learning_rate": 1.917001338688086e-05,
      "loss": 0.3726,
      "step": 3380
    },
    {
      "epoch": 2.723036754368347,
      "grad_norm": 0.28761106729507446,
      "learning_rate": 1.863453815261044e-05,
      "loss": 0.365,
      "step": 3390
    },
    {
      "epoch": 2.731070496083551,
      "grad_norm": 0.28035968542099,
      "learning_rate": 1.809906291834003e-05,
      "loss": 0.3155,
      "step": 3400
    },
    {
      "epoch": 2.7391042377987547,
      "grad_norm": 0.22472605109214783,
      "learning_rate": 1.7563587684069612e-05,
      "loss": 0.3057,
      "step": 3410
    },
    {
      "epoch": 2.7471379795139588,
      "grad_norm": 0.3331677317619324,
      "learning_rate": 1.7028112449799198e-05,
      "loss": 0.3356,
      "step": 3420
    },
    {
      "epoch": 2.7551717212291624,
      "grad_norm": 0.30853867530822754,
      "learning_rate": 1.6492637215528783e-05,
      "loss": 0.3798,
      "step": 3430
    },
    {
      "epoch": 2.7632054629443665,
      "grad_norm": 0.28440555930137634,
      "learning_rate": 1.5957161981258366e-05,
      "loss": 0.3464,
      "step": 3440
    },
    {
      "epoch": 2.77123920465957,
      "grad_norm": 0.25496265292167664,
      "learning_rate": 1.5421686746987955e-05,
      "loss": 0.3077,
      "step": 3450
    },
    {
      "epoch": 2.779272946374774,
      "grad_norm": 0.2735050916671753,
      "learning_rate": 1.4886211512717537e-05,
      "loss": 0.3377,
      "step": 3460
    },
    {
      "epoch": 2.787306688089978,
      "grad_norm": 0.25729548931121826,
      "learning_rate": 1.4350736278447121e-05,
      "loss": 0.3156,
      "step": 3470
    },
    {
      "epoch": 2.7953404298051816,
      "grad_norm": 0.3114127218723297,
      "learning_rate": 1.3815261044176708e-05,
      "loss": 0.3562,
      "step": 3480
    },
    {
      "epoch": 2.8033741715203857,
      "grad_norm": 0.2583520710468292,
      "learning_rate": 1.3279785809906292e-05,
      "loss": 0.3456,
      "step": 3490
    },
    {
      "epoch": 2.8114079132355894,
      "grad_norm": 0.29257291555404663,
      "learning_rate": 1.274431057563588e-05,
      "loss": 0.3392,
      "step": 3500
    },
    {
      "epoch": 2.8194416549507935,
      "grad_norm": 0.311310350894928,
      "learning_rate": 1.2208835341365463e-05,
      "loss": 0.3374,
      "step": 3510
    },
    {
      "epoch": 2.827475396665997,
      "grad_norm": 0.2399248629808426,
      "learning_rate": 1.1673360107095047e-05,
      "loss": 0.3229,
      "step": 3520
    },
    {
      "epoch": 2.8355091383812008,
      "grad_norm": 0.26998206973075867,
      "learning_rate": 1.1137884872824631e-05,
      "loss": 0.3018,
      "step": 3530
    },
    {
      "epoch": 2.843542880096405,
      "grad_norm": 0.28868138790130615,
      "learning_rate": 1.0602409638554217e-05,
      "loss": 0.3704,
      "step": 3540
    },
    {
      "epoch": 2.851576621811609,
      "grad_norm": 0.2370283156633377,
      "learning_rate": 1.0066934404283803e-05,
      "loss": 0.3849,
      "step": 3550
    },
    {
      "epoch": 2.8596103635268126,
      "grad_norm": 0.23871760070323944,
      "learning_rate": 9.531459170013388e-06,
      "loss": 0.3178,
      "step": 3560
    },
    {
      "epoch": 2.8676441052420163,
      "grad_norm": 0.3892604410648346,
      "learning_rate": 8.995983935742972e-06,
      "loss": 0.4022,
      "step": 3570
    },
    {
      "epoch": 2.8756778469572204,
      "grad_norm": 0.311570942401886,
      "learning_rate": 8.460508701472556e-06,
      "loss": 0.341,
      "step": 3580
    },
    {
      "epoch": 2.883711588672424,
      "grad_norm": 0.32137826085090637,
      "learning_rate": 7.925033467202142e-06,
      "loss": 0.3618,
      "step": 3590
    },
    {
      "epoch": 2.891745330387628,
      "grad_norm": 0.24745935201644897,
      "learning_rate": 7.389558232931727e-06,
      "loss": 0.3954,
      "step": 3600
    },
    {
      "epoch": 2.899779072102832,
      "grad_norm": 0.3074815273284912,
      "learning_rate": 6.854082998661312e-06,
      "loss": 0.3607,
      "step": 3610
    },
    {
      "epoch": 2.907812813818036,
      "grad_norm": 0.235945463180542,
      "learning_rate": 6.318607764390898e-06,
      "loss": 0.3886,
      "step": 3620
    },
    {
      "epoch": 2.9158465555332396,
      "grad_norm": 0.23034200072288513,
      "learning_rate": 5.783132530120483e-06,
      "loss": 0.3568,
      "step": 3630
    },
    {
      "epoch": 2.9238802972484432,
      "grad_norm": 0.32611826062202454,
      "learning_rate": 5.2476572958500665e-06,
      "loss": 0.3637,
      "step": 3640
    },
    {
      "epoch": 2.9319140389636473,
      "grad_norm": 0.2806864380836487,
      "learning_rate": 4.712182061579652e-06,
      "loss": 0.3498,
      "step": 3650
    },
    {
      "epoch": 2.9399477806788514,
      "grad_norm": 0.25423094630241394,
      "learning_rate": 4.176706827309238e-06,
      "loss": 0.3623,
      "step": 3660
    },
    {
      "epoch": 2.947981522394055,
      "grad_norm": 0.31904008984565735,
      "learning_rate": 3.641231593038822e-06,
      "loss": 0.3993,
      "step": 3670
    },
    {
      "epoch": 2.9560152641092587,
      "grad_norm": 0.2579241693019867,
      "learning_rate": 3.105756358768407e-06,
      "loss": 0.3803,
      "step": 3680
    },
    {
      "epoch": 2.964049005824463,
      "grad_norm": 0.29248669743537903,
      "learning_rate": 2.570281124497992e-06,
      "loss": 0.3131,
      "step": 3690
    },
    {
      "epoch": 2.9720827475396665,
      "grad_norm": 0.31283822655677795,
      "learning_rate": 2.034805890227577e-06,
      "loss": 0.3565,
      "step": 3700
    },
    {
      "epoch": 2.9801164892548706,
      "grad_norm": 0.39187976717948914,
      "learning_rate": 1.499330655957162e-06,
      "loss": 0.352,
      "step": 3710
    },
    {
      "epoch": 2.9881502309700743,
      "grad_norm": 0.350029319524765,
      "learning_rate": 9.638554216867472e-07,
      "loss": 0.3484,
      "step": 3720
    },
    {
      "epoch": 2.9961839726852784,
      "grad_norm": 0.3139471411705017,
      "learning_rate": 4.28380187416332e-07,
      "loss": 0.3405,
      "step": 3730
    }
  ],
  "logging_steps": 10,
  "max_steps": 3735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.96122185402286e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2490,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008034548558802852,
      "grad_norm": 1.0373977422714233,
      "learning_rate": 0.0001997322623828648,
      "loss": 6.9154,
      "step": 10
    },
    {
      "epoch": 0.016069097117605704,
      "grad_norm": 0.30423006415367126,
      "learning_rate": 0.0001991967871485944,
      "loss": 0.7186,
      "step": 20
    },
    {
      "epoch": 0.024103645676408558,
      "grad_norm": 0.18798606097698212,
      "learning_rate": 0.00019866131191432397,
      "loss": 0.5324,
      "step": 30
    },
    {
      "epoch": 0.03213819423521141,
      "grad_norm": 0.14447475969791412,
      "learning_rate": 0.00019812583668005356,
      "loss": 0.4699,
      "step": 40
    },
    {
      "epoch": 0.04017274279401426,
      "grad_norm": 0.23008406162261963,
      "learning_rate": 0.00019759036144578314,
      "loss": 0.5084,
      "step": 50
    },
    {
      "epoch": 0.048207291352817115,
      "grad_norm": 0.2064332216978073,
      "learning_rate": 0.00019705488621151273,
      "loss": 0.5097,
      "step": 60
    },
    {
      "epoch": 0.05624183991161997,
      "grad_norm": 0.1356736272573471,
      "learning_rate": 0.00019651941097724232,
      "loss": 0.3803,
      "step": 70
    },
    {
      "epoch": 0.06427638847042282,
      "grad_norm": 0.17006024718284607,
      "learning_rate": 0.0001959839357429719,
      "loss": 0.4234,
      "step": 80
    },
    {
      "epoch": 0.07231093702922567,
      "grad_norm": 0.22150123119354248,
      "learning_rate": 0.0001954484605087015,
      "loss": 0.4537,
      "step": 90
    },
    {
      "epoch": 0.08034548558802852,
      "grad_norm": 0.20373305678367615,
      "learning_rate": 0.00019491298527443107,
      "loss": 0.4047,
      "step": 100
    },
    {
      "epoch": 0.08838003414683138,
      "grad_norm": 0.15008515119552612,
      "learning_rate": 0.00019437751004016066,
      "loss": 0.4052,
      "step": 110
    },
    {
      "epoch": 0.09641458270563423,
      "grad_norm": 0.14398758113384247,
      "learning_rate": 0.00019384203480589022,
      "loss": 0.4351,
      "step": 120
    },
    {
      "epoch": 0.10444913126443708,
      "grad_norm": 0.16062946617603302,
      "learning_rate": 0.00019330655957161983,
      "loss": 0.4175,
      "step": 130
    },
    {
      "epoch": 0.11248367982323994,
      "grad_norm": 0.1657368242740631,
      "learning_rate": 0.00019277108433734942,
      "loss": 0.4161,
      "step": 140
    },
    {
      "epoch": 0.12051822838204278,
      "grad_norm": 0.20168568193912506,
      "learning_rate": 0.00019223560910307897,
      "loss": 0.4906,
      "step": 150
    },
    {
      "epoch": 0.12855277694084563,
      "grad_norm": 0.1492224782705307,
      "learning_rate": 0.0001917001338688086,
      "loss": 0.4015,
      "step": 160
    },
    {
      "epoch": 0.1365873254996485,
      "grad_norm": 0.15185053646564484,
      "learning_rate": 0.00019116465863453817,
      "loss": 0.4199,
      "step": 170
    },
    {
      "epoch": 0.14462187405845134,
      "grad_norm": 0.13899379968643188,
      "learning_rate": 0.00019062918340026773,
      "loss": 0.4268,
      "step": 180
    },
    {
      "epoch": 0.1526564226172542,
      "grad_norm": 0.1545664668083191,
      "learning_rate": 0.00019009370816599734,
      "loss": 0.4512,
      "step": 190
    },
    {
      "epoch": 0.16069097117605705,
      "grad_norm": 0.16737189888954163,
      "learning_rate": 0.00018955823293172693,
      "loss": 0.4082,
      "step": 200
    },
    {
      "epoch": 0.16872551973485989,
      "grad_norm": 0.14347544312477112,
      "learning_rate": 0.0001890227576974565,
      "loss": 0.4093,
      "step": 210
    },
    {
      "epoch": 0.17676006829366275,
      "grad_norm": 0.1646565943956375,
      "learning_rate": 0.00018848728246318607,
      "loss": 0.437,
      "step": 220
    },
    {
      "epoch": 0.1847946168524656,
      "grad_norm": 0.15071415901184082,
      "learning_rate": 0.00018795180722891569,
      "loss": 0.3842,
      "step": 230
    },
    {
      "epoch": 0.19282916541126846,
      "grad_norm": 0.16400277614593506,
      "learning_rate": 0.00018741633199464524,
      "loss": 0.3796,
      "step": 240
    },
    {
      "epoch": 0.2008637139700713,
      "grad_norm": 0.17444612085819244,
      "learning_rate": 0.00018688085676037483,
      "loss": 0.3439,
      "step": 250
    },
    {
      "epoch": 0.20889826252887417,
      "grad_norm": 0.23109838366508484,
      "learning_rate": 0.00018634538152610444,
      "loss": 0.3512,
      "step": 260
    },
    {
      "epoch": 0.216932811087677,
      "grad_norm": 0.15906475484371185,
      "learning_rate": 0.000185809906291834,
      "loss": 0.3493,
      "step": 270
    },
    {
      "epoch": 0.22496735964647988,
      "grad_norm": 0.14465388655662537,
      "learning_rate": 0.0001852744310575636,
      "loss": 0.3436,
      "step": 280
    },
    {
      "epoch": 0.23300190820528272,
      "grad_norm": 0.1642436385154724,
      "learning_rate": 0.0001847389558232932,
      "loss": 0.3703,
      "step": 290
    },
    {
      "epoch": 0.24103645676408555,
      "grad_norm": 0.20387201011180878,
      "learning_rate": 0.00018420348058902276,
      "loss": 0.3959,
      "step": 300
    },
    {
      "epoch": 0.24907100532288842,
      "grad_norm": 0.1556016355752945,
      "learning_rate": 0.00018366800535475234,
      "loss": 0.4068,
      "step": 310
    },
    {
      "epoch": 0.25710555388169126,
      "grad_norm": 0.15081371366977692,
      "learning_rate": 0.00018313253012048193,
      "loss": 0.4,
      "step": 320
    },
    {
      "epoch": 0.26514010244049413,
      "grad_norm": 0.11856018006801605,
      "learning_rate": 0.00018259705488621152,
      "loss": 0.3442,
      "step": 330
    },
    {
      "epoch": 0.273174650999297,
      "grad_norm": 0.14013396203517914,
      "learning_rate": 0.0001820615796519411,
      "loss": 0.3942,
      "step": 340
    },
    {
      "epoch": 0.2812091995580998,
      "grad_norm": 0.14599798619747162,
      "learning_rate": 0.0001815261044176707,
      "loss": 0.3482,
      "step": 350
    },
    {
      "epoch": 0.2892437481169027,
      "grad_norm": 0.13799016177654266,
      "learning_rate": 0.00018099062918340027,
      "loss": 0.4152,
      "step": 360
    },
    {
      "epoch": 0.29727829667570554,
      "grad_norm": 0.1324983835220337,
      "learning_rate": 0.00018045515394912986,
      "loss": 0.3439,
      "step": 370
    },
    {
      "epoch": 0.3053128452345084,
      "grad_norm": 0.140101358294487,
      "learning_rate": 0.00017991967871485944,
      "loss": 0.3737,
      "step": 380
    },
    {
      "epoch": 0.3133473937933112,
      "grad_norm": 0.11805727332830429,
      "learning_rate": 0.00017938420348058903,
      "loss": 0.3761,
      "step": 390
    },
    {
      "epoch": 0.3213819423521141,
      "grad_norm": 0.15552829205989838,
      "learning_rate": 0.00017884872824631862,
      "loss": 0.341,
      "step": 400
    },
    {
      "epoch": 0.32941649091091696,
      "grad_norm": 0.13736817240715027,
      "learning_rate": 0.0001783132530120482,
      "loss": 0.3413,
      "step": 410
    },
    {
      "epoch": 0.33745103946971977,
      "grad_norm": 0.14059296250343323,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.3181,
      "step": 420
    },
    {
      "epoch": 0.34548558802852264,
      "grad_norm": 0.1314832866191864,
      "learning_rate": 0.00017724230254350737,
      "loss": 0.3851,
      "step": 430
    },
    {
      "epoch": 0.3535201365873255,
      "grad_norm": 0.12976747751235962,
      "learning_rate": 0.00017670682730923696,
      "loss": 0.3479,
      "step": 440
    },
    {
      "epoch": 0.3615546851461284,
      "grad_norm": 0.1509714275598526,
      "learning_rate": 0.00017617135207496654,
      "loss": 0.3932,
      "step": 450
    },
    {
      "epoch": 0.3695892337049312,
      "grad_norm": 0.17412757873535156,
      "learning_rate": 0.00017563587684069613,
      "loss": 0.3521,
      "step": 460
    },
    {
      "epoch": 0.37762378226373405,
      "grad_norm": 0.14991441369056702,
      "learning_rate": 0.00017510040160642571,
      "loss": 0.3286,
      "step": 470
    },
    {
      "epoch": 0.3856583308225369,
      "grad_norm": 0.13779541850090027,
      "learning_rate": 0.0001745649263721553,
      "loss": 0.3671,
      "step": 480
    },
    {
      "epoch": 0.3936928793813398,
      "grad_norm": 0.14195816218852997,
      "learning_rate": 0.00017402945113788489,
      "loss": 0.4027,
      "step": 490
    },
    {
      "epoch": 0.4017274279401426,
      "grad_norm": 0.12471170723438263,
      "learning_rate": 0.00017349397590361447,
      "loss": 0.4343,
      "step": 500
    },
    {
      "epoch": 0.40976197649894547,
      "grad_norm": 0.15163148939609528,
      "learning_rate": 0.00017295850066934406,
      "loss": 0.3442,
      "step": 510
    },
    {
      "epoch": 0.41779652505774834,
      "grad_norm": 0.15107619762420654,
      "learning_rate": 0.00017242302543507362,
      "loss": 0.3647,
      "step": 520
    },
    {
      "epoch": 0.42583107361655115,
      "grad_norm": 0.13999304175376892,
      "learning_rate": 0.00017188755020080323,
      "loss": 0.3628,
      "step": 530
    },
    {
      "epoch": 0.433865622175354,
      "grad_norm": 0.1650177240371704,
      "learning_rate": 0.00017135207496653281,
      "loss": 0.3834,
      "step": 540
    },
    {
      "epoch": 0.4419001707341569,
      "grad_norm": 0.126255601644516,
      "learning_rate": 0.00017081659973226237,
      "loss": 0.4465,
      "step": 550
    },
    {
      "epoch": 0.44993471929295975,
      "grad_norm": 0.15670904517173767,
      "learning_rate": 0.00017028112449799199,
      "loss": 0.3325,
      "step": 560
    },
    {
      "epoch": 0.45796926785176256,
      "grad_norm": 0.12534666061401367,
      "learning_rate": 0.00016974564926372157,
      "loss": 0.3643,
      "step": 570
    },
    {
      "epoch": 0.46600381641056543,
      "grad_norm": 0.1701141893863678,
      "learning_rate": 0.00016921017402945113,
      "loss": 0.3708,
      "step": 580
    },
    {
      "epoch": 0.4740383649693683,
      "grad_norm": 0.12662281095981598,
      "learning_rate": 0.00016867469879518074,
      "loss": 0.3711,
      "step": 590
    },
    {
      "epoch": 0.4820729135281711,
      "grad_norm": 0.18864040076732635,
      "learning_rate": 0.00016813922356091033,
      "loss": 0.3458,
      "step": 600
    },
    {
      "epoch": 0.490107462086974,
      "grad_norm": 0.15426218509674072,
      "learning_rate": 0.00016760374832663989,
      "loss": 0.362,
      "step": 610
    },
    {
      "epoch": 0.49814201064577684,
      "grad_norm": 0.13543865084648132,
      "learning_rate": 0.00016706827309236947,
      "loss": 0.3871,
      "step": 620
    },
    {
      "epoch": 0.5061765592045797,
      "grad_norm": 0.18093110620975494,
      "learning_rate": 0.00016653279785809908,
      "loss": 0.3232,
      "step": 630
    },
    {
      "epoch": 0.5142111077633825,
      "grad_norm": 0.15284331142902374,
      "learning_rate": 0.00016599732262382864,
      "loss": 0.4009,
      "step": 640
    },
    {
      "epoch": 0.5222456563221854,
      "grad_norm": 0.15323181450366974,
      "learning_rate": 0.00016546184738955823,
      "loss": 0.4051,
      "step": 650
    },
    {
      "epoch": 0.5302802048809883,
      "grad_norm": 0.14679692685604095,
      "learning_rate": 0.00016492637215528784,
      "loss": 0.372,
      "step": 660
    },
    {
      "epoch": 0.5383147534397911,
      "grad_norm": 0.15374250710010529,
      "learning_rate": 0.0001643908969210174,
      "loss": 0.354,
      "step": 670
    },
    {
      "epoch": 0.546349301998594,
      "grad_norm": 0.13475187122821808,
      "learning_rate": 0.00016385542168674699,
      "loss": 0.3547,
      "step": 680
    },
    {
      "epoch": 0.5543838505573968,
      "grad_norm": 0.13448861241340637,
      "learning_rate": 0.0001633199464524766,
      "loss": 0.3163,
      "step": 690
    },
    {
      "epoch": 0.5624183991161996,
      "grad_norm": 0.1288829743862152,
      "learning_rate": 0.00016278447121820616,
      "loss": 0.3632,
      "step": 700
    },
    {
      "epoch": 0.5704529476750025,
      "grad_norm": 0.11543543636798859,
      "learning_rate": 0.00016224899598393574,
      "loss": 0.3652,
      "step": 710
    },
    {
      "epoch": 0.5784874962338054,
      "grad_norm": 0.12662579119205475,
      "learning_rate": 0.00016171352074966533,
      "loss": 0.3807,
      "step": 720
    },
    {
      "epoch": 0.5865220447926082,
      "grad_norm": 0.14323389530181885,
      "learning_rate": 0.00016117804551539491,
      "loss": 0.4001,
      "step": 730
    },
    {
      "epoch": 0.5945565933514111,
      "grad_norm": 0.13263379037380219,
      "learning_rate": 0.0001606425702811245,
      "loss": 0.3554,
      "step": 740
    },
    {
      "epoch": 0.6025911419102139,
      "grad_norm": 0.14238335192203522,
      "learning_rate": 0.00016010709504685409,
      "loss": 0.3226,
      "step": 750
    },
    {
      "epoch": 0.6106256904690168,
      "grad_norm": 0.13664333522319794,
      "learning_rate": 0.00015957161981258367,
      "loss": 0.3663,
      "step": 760
    },
    {
      "epoch": 0.6186602390278196,
      "grad_norm": 0.13073422014713287,
      "learning_rate": 0.00015903614457831326,
      "loss": 0.3638,
      "step": 770
    },
    {
      "epoch": 0.6266947875866224,
      "grad_norm": 0.1339569240808487,
      "learning_rate": 0.00015850066934404284,
      "loss": 0.2989,
      "step": 780
    },
    {
      "epoch": 0.6347293361454254,
      "grad_norm": 0.1554918736219406,
      "learning_rate": 0.00015796519410977243,
      "loss": 0.4057,
      "step": 790
    },
    {
      "epoch": 0.6427638847042282,
      "grad_norm": 0.13950280845165253,
      "learning_rate": 0.000157429718875502,
      "loss": 0.3319,
      "step": 800
    },
    {
      "epoch": 0.650798433263031,
      "grad_norm": 0.11782950162887573,
      "learning_rate": 0.0001568942436412316,
      "loss": 0.3177,
      "step": 810
    },
    {
      "epoch": 0.6588329818218339,
      "grad_norm": 0.12576988339424133,
      "learning_rate": 0.00015635876840696118,
      "loss": 0.3186,
      "step": 820
    },
    {
      "epoch": 0.6668675303806367,
      "grad_norm": 0.14569640159606934,
      "learning_rate": 0.00015582329317269077,
      "loss": 0.385,
      "step": 830
    },
    {
      "epoch": 0.6749020789394395,
      "grad_norm": 0.1621841937303543,
      "learning_rate": 0.00015528781793842036,
      "loss": 0.4089,
      "step": 840
    },
    {
      "epoch": 0.6829366274982425,
      "grad_norm": 0.13134099543094635,
      "learning_rate": 0.00015475234270414994,
      "loss": 0.3466,
      "step": 850
    },
    {
      "epoch": 0.6909711760570453,
      "grad_norm": 0.11348912119865417,
      "learning_rate": 0.00015421686746987953,
      "loss": 0.3043,
      "step": 860
    },
    {
      "epoch": 0.6990057246158482,
      "grad_norm": 0.19597801566123962,
      "learning_rate": 0.0001536813922356091,
      "loss": 0.3887,
      "step": 870
    },
    {
      "epoch": 0.707040273174651,
      "grad_norm": 0.1569252610206604,
      "learning_rate": 0.0001531459170013387,
      "loss": 0.3651,
      "step": 880
    },
    {
      "epoch": 0.7150748217334538,
      "grad_norm": 0.12994404137134552,
      "learning_rate": 0.00015261044176706828,
      "loss": 0.3334,
      "step": 890
    },
    {
      "epoch": 0.7231093702922567,
      "grad_norm": 0.13774006068706512,
      "learning_rate": 0.00015207496653279787,
      "loss": 0.3561,
      "step": 900
    },
    {
      "epoch": 0.7311439188510596,
      "grad_norm": 0.14080780744552612,
      "learning_rate": 0.00015153949129852746,
      "loss": 0.331,
      "step": 910
    },
    {
      "epoch": 0.7391784674098624,
      "grad_norm": 0.11512520909309387,
      "learning_rate": 0.00015100401606425701,
      "loss": 0.3258,
      "step": 920
    },
    {
      "epoch": 0.7472130159686653,
      "grad_norm": 0.13046146929264069,
      "learning_rate": 0.00015046854082998663,
      "loss": 0.3597,
      "step": 930
    },
    {
      "epoch": 0.7552475645274681,
      "grad_norm": 0.14750921726226807,
      "learning_rate": 0.0001499330655957162,
      "loss": 0.3491,
      "step": 940
    },
    {
      "epoch": 0.7632821130862709,
      "grad_norm": 0.13117294013500214,
      "learning_rate": 0.00014939759036144577,
      "loss": 0.37,
      "step": 950
    },
    {
      "epoch": 0.7713166616450738,
      "grad_norm": 0.12348867952823639,
      "learning_rate": 0.00014886211512717538,
      "loss": 0.3567,
      "step": 960
    },
    {
      "epoch": 0.7793512102038767,
      "grad_norm": 0.11180102080106735,
      "learning_rate": 0.00014832663989290497,
      "loss": 0.3198,
      "step": 970
    },
    {
      "epoch": 0.7873857587626796,
      "grad_norm": 0.14421498775482178,
      "learning_rate": 0.00014779116465863453,
      "loss": 0.3545,
      "step": 980
    },
    {
      "epoch": 0.7954203073214824,
      "grad_norm": 0.1733960658311844,
      "learning_rate": 0.00014725568942436414,
      "loss": 0.4086,
      "step": 990
    },
    {
      "epoch": 0.8034548558802852,
      "grad_norm": 0.1372808814048767,
      "learning_rate": 0.00014672021419009373,
      "loss": 0.2998,
      "step": 1000
    },
    {
      "epoch": 0.8114894044390881,
      "grad_norm": 0.1272394061088562,
      "learning_rate": 0.00014618473895582328,
      "loss": 0.3507,
      "step": 1010
    },
    {
      "epoch": 0.8195239529978909,
      "grad_norm": 0.162174254655838,
      "learning_rate": 0.00014564926372155287,
      "loss": 0.3738,
      "step": 1020
    },
    {
      "epoch": 0.8275585015566937,
      "grad_norm": 0.16035638749599457,
      "learning_rate": 0.00014511378848728248,
      "loss": 0.3921,
      "step": 1030
    },
    {
      "epoch": 0.8355930501154967,
      "grad_norm": 0.1867516189813614,
      "learning_rate": 0.00014457831325301204,
      "loss": 0.3871,
      "step": 1040
    },
    {
      "epoch": 0.8436275986742995,
      "grad_norm": 0.13369876146316528,
      "learning_rate": 0.00014404283801874163,
      "loss": 0.3425,
      "step": 1050
    },
    {
      "epoch": 0.8516621472331023,
      "grad_norm": 0.12167710065841675,
      "learning_rate": 0.00014350736278447124,
      "loss": 0.3009,
      "step": 1060
    },
    {
      "epoch": 0.8596966957919052,
      "grad_norm": 0.12410513311624527,
      "learning_rate": 0.0001429718875502008,
      "loss": 0.3363,
      "step": 1070
    },
    {
      "epoch": 0.867731244350708,
      "grad_norm": 0.09841236472129822,
      "learning_rate": 0.00014243641231593038,
      "loss": 0.3682,
      "step": 1080
    },
    {
      "epoch": 0.8757657929095108,
      "grad_norm": 0.14756140112876892,
      "learning_rate": 0.00014190093708166,
      "loss": 0.374,
      "step": 1090
    },
    {
      "epoch": 0.8838003414683138,
      "grad_norm": 0.15321993827819824,
      "learning_rate": 0.00014136546184738956,
      "loss": 0.374,
      "step": 1100
    },
    {
      "epoch": 0.8918348900271166,
      "grad_norm": 0.17200085520744324,
      "learning_rate": 0.00014082998661311914,
      "loss": 0.3733,
      "step": 1110
    },
    {
      "epoch": 0.8998694385859195,
      "grad_norm": 0.156183660030365,
      "learning_rate": 0.00014029451137884873,
      "loss": 0.3476,
      "step": 1120
    },
    {
      "epoch": 0.9079039871447223,
      "grad_norm": 0.1381406933069229,
      "learning_rate": 0.00013975903614457834,
      "loss": 0.3429,
      "step": 1130
    },
    {
      "epoch": 0.9159385357035251,
      "grad_norm": 0.15278637409210205,
      "learning_rate": 0.0001392235609103079,
      "loss": 0.3226,
      "step": 1140
    },
    {
      "epoch": 0.923973084262328,
      "grad_norm": 0.132486492395401,
      "learning_rate": 0.00013868808567603748,
      "loss": 0.3215,
      "step": 1150
    },
    {
      "epoch": 0.9320076328211309,
      "grad_norm": 0.13444645702838898,
      "learning_rate": 0.0001381526104417671,
      "loss": 0.3593,
      "step": 1160
    },
    {
      "epoch": 0.9400421813799337,
      "grad_norm": 0.13581356406211853,
      "learning_rate": 0.00013761713520749665,
      "loss": 0.3721,
      "step": 1170
    },
    {
      "epoch": 0.9480767299387366,
      "grad_norm": 0.15123571455478668,
      "learning_rate": 0.00013708165997322624,
      "loss": 0.3785,
      "step": 1180
    },
    {
      "epoch": 0.9561112784975394,
      "grad_norm": 0.12052050977945328,
      "learning_rate": 0.00013654618473895585,
      "loss": 0.3309,
      "step": 1190
    },
    {
      "epoch": 0.9641458270563422,
      "grad_norm": 0.1255498230457306,
      "learning_rate": 0.0001360107095046854,
      "loss": 0.3858,
      "step": 1200
    },
    {
      "epoch": 0.9721803756151451,
      "grad_norm": 0.12577643990516663,
      "learning_rate": 0.000135475234270415,
      "loss": 0.3335,
      "step": 1210
    },
    {
      "epoch": 0.980214924173948,
      "grad_norm": 0.1964809000492096,
      "learning_rate": 0.00013493975903614458,
      "loss": 0.378,
      "step": 1220
    },
    {
      "epoch": 0.9882494727327509,
      "grad_norm": 0.14193300902843475,
      "learning_rate": 0.00013440428380187417,
      "loss": 0.3159,
      "step": 1230
    },
    {
      "epoch": 0.9962840212915537,
      "grad_norm": 0.12691381573677063,
      "learning_rate": 0.00013386880856760375,
      "loss": 0.3275,
      "step": 1240
    },
    {
      "epoch": 1.0040172742794014,
      "grad_norm": 0.13694779574871063,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.3866,
      "step": 1250
    },
    {
      "epoch": 1.0120518228382043,
      "grad_norm": 0.15238317847251892,
      "learning_rate": 0.00013279785809906293,
      "loss": 0.3329,
      "step": 1260
    },
    {
      "epoch": 1.0200863713970072,
      "grad_norm": 0.15172436833381653,
      "learning_rate": 0.0001322623828647925,
      "loss": 0.4294,
      "step": 1270
    },
    {
      "epoch": 1.02812091995581,
      "grad_norm": 0.16846007108688354,
      "learning_rate": 0.0001317269076305221,
      "loss": 0.3008,
      "step": 1280
    },
    {
      "epoch": 1.0361554685146128,
      "grad_norm": 0.18917331099510193,
      "learning_rate": 0.00013119143239625168,
      "loss": 0.3076,
      "step": 1290
    },
    {
      "epoch": 1.0441900170734157,
      "grad_norm": 0.176502987742424,
      "learning_rate": 0.00013065595716198127,
      "loss": 0.3642,
      "step": 1300
    },
    {
      "epoch": 1.0522245656322184,
      "grad_norm": 0.16104361414909363,
      "learning_rate": 0.00013012048192771085,
      "loss": 0.332,
      "step": 1310
    },
    {
      "epoch": 1.0602591141910214,
      "grad_norm": 0.14212384819984436,
      "learning_rate": 0.0001295850066934404,
      "loss": 0.3249,
      "step": 1320
    },
    {
      "epoch": 1.0682936627498243,
      "grad_norm": 0.16038547456264496,
      "learning_rate": 0.00012904953145917002,
      "loss": 0.3163,
      "step": 1330
    },
    {
      "epoch": 1.0763282113086272,
      "grad_norm": 0.15652818977832794,
      "learning_rate": 0.0001285140562248996,
      "loss": 0.3336,
      "step": 1340
    },
    {
      "epoch": 1.08436275986743,
      "grad_norm": 0.15337540209293365,
      "learning_rate": 0.00012797858099062917,
      "loss": 0.3375,
      "step": 1350
    },
    {
      "epoch": 1.0923973084262328,
      "grad_norm": 0.12772820889949799,
      "learning_rate": 0.00012744310575635878,
      "loss": 0.3313,
      "step": 1360
    },
    {
      "epoch": 1.1004318569850358,
      "grad_norm": 0.16377659142017365,
      "learning_rate": 0.00012690763052208837,
      "loss": 0.388,
      "step": 1370
    },
    {
      "epoch": 1.1084664055438385,
      "grad_norm": 0.1798485517501831,
      "learning_rate": 0.00012637215528781793,
      "loss": 0.4039,
      "step": 1380
    },
    {
      "epoch": 1.1165009541026414,
      "grad_norm": 0.13677653670310974,
      "learning_rate": 0.00012583668005354754,
      "loss": 0.3579,
      "step": 1390
    },
    {
      "epoch": 1.1245355026614443,
      "grad_norm": 0.14919322729110718,
      "learning_rate": 0.00012530120481927712,
      "loss": 0.337,
      "step": 1400
    },
    {
      "epoch": 1.132570051220247,
      "grad_norm": 0.14551948010921478,
      "learning_rate": 0.0001247657295850067,
      "loss": 0.3908,
      "step": 1410
    },
    {
      "epoch": 1.14060459977905,
      "grad_norm": 0.1429954171180725,
      "learning_rate": 0.00012423025435073627,
      "loss": 0.3774,
      "step": 1420
    },
    {
      "epoch": 1.1486391483378529,
      "grad_norm": 0.14960871636867523,
      "learning_rate": 0.00012369477911646588,
      "loss": 0.3394,
      "step": 1430
    },
    {
      "epoch": 1.1566736968966556,
      "grad_norm": 0.1362229585647583,
      "learning_rate": 0.00012315930388219547,
      "loss": 0.3416,
      "step": 1440
    },
    {
      "epoch": 1.1647082454554585,
      "grad_norm": 0.14940789341926575,
      "learning_rate": 0.00012262382864792503,
      "loss": 0.3444,
      "step": 1450
    },
    {
      "epoch": 1.1727427940142614,
      "grad_norm": 0.17096664011478424,
      "learning_rate": 0.00012208835341365464,
      "loss": 0.327,
      "step": 1460
    },
    {
      "epoch": 1.180777342573064,
      "grad_norm": 0.14427550137043,
      "learning_rate": 0.00012155287817938421,
      "loss": 0.3537,
      "step": 1470
    },
    {
      "epoch": 1.188811891131867,
      "grad_norm": 0.14001642167568207,
      "learning_rate": 0.0001210174029451138,
      "loss": 0.3542,
      "step": 1480
    },
    {
      "epoch": 1.19684643969067,
      "grad_norm": 0.16559037566184998,
      "learning_rate": 0.0001204819277108434,
      "loss": 0.3585,
      "step": 1490
    },
    {
      "epoch": 1.2048809882494727,
      "grad_norm": 0.15665845572948456,
      "learning_rate": 0.00011994645247657297,
      "loss": 0.3177,
      "step": 1500
    },
    {
      "epoch": 1.2129155368082756,
      "grad_norm": 0.15587951242923737,
      "learning_rate": 0.00011941097724230255,
      "loss": 0.3245,
      "step": 1510
    },
    {
      "epoch": 1.2209500853670785,
      "grad_norm": 0.19402356445789337,
      "learning_rate": 0.00011887550200803212,
      "loss": 0.3062,
      "step": 1520
    },
    {
      "epoch": 1.2289846339258812,
      "grad_norm": 0.20641301572322845,
      "learning_rate": 0.00011834002677376172,
      "loss": 0.3539,
      "step": 1530
    },
    {
      "epoch": 1.2370191824846841,
      "grad_norm": 0.19700537621974945,
      "learning_rate": 0.00011780455153949131,
      "loss": 0.3515,
      "step": 1540
    },
    {
      "epoch": 1.245053731043487,
      "grad_norm": 0.1574840545654297,
      "learning_rate": 0.00011726907630522088,
      "loss": 0.3492,
      "step": 1550
    },
    {
      "epoch": 1.2530882796022897,
      "grad_norm": 0.15300855040550232,
      "learning_rate": 0.00011673360107095048,
      "loss": 0.3857,
      "step": 1560
    },
    {
      "epoch": 1.2611228281610927,
      "grad_norm": 0.13678747415542603,
      "learning_rate": 0.00011619812583668007,
      "loss": 0.3285,
      "step": 1570
    },
    {
      "epoch": 1.2691573767198956,
      "grad_norm": 0.20398001372814178,
      "learning_rate": 0.00011566265060240964,
      "loss": 0.357,
      "step": 1580
    },
    {
      "epoch": 1.2771919252786983,
      "grad_norm": 0.17522726953029633,
      "learning_rate": 0.00011512717536813924,
      "loss": 0.3106,
      "step": 1590
    },
    {
      "epoch": 1.2852264738375012,
      "grad_norm": 0.14253441989421844,
      "learning_rate": 0.00011459170013386882,
      "loss": 0.3008,
      "step": 1600
    },
    {
      "epoch": 1.2932610223963041,
      "grad_norm": 0.16615858674049377,
      "learning_rate": 0.0001140562248995984,
      "loss": 0.3554,
      "step": 1610
    },
    {
      "epoch": 1.3012955709551068,
      "grad_norm": 0.1400468498468399,
      "learning_rate": 0.00011352074966532798,
      "loss": 0.351,
      "step": 1620
    },
    {
      "epoch": 1.3093301195139098,
      "grad_norm": 0.19078408181667328,
      "learning_rate": 0.00011298527443105758,
      "loss": 0.3374,
      "step": 1630
    },
    {
      "epoch": 1.3173646680727127,
      "grad_norm": 0.1636449694633484,
      "learning_rate": 0.00011244979919678715,
      "loss": 0.3355,
      "step": 1640
    },
    {
      "epoch": 1.3253992166315154,
      "grad_norm": 0.16405583918094635,
      "learning_rate": 0.00011191432396251674,
      "loss": 0.3201,
      "step": 1650
    },
    {
      "epoch": 1.3334337651903183,
      "grad_norm": 0.1706804633140564,
      "learning_rate": 0.00011137884872824634,
      "loss": 0.3137,
      "step": 1660
    },
    {
      "epoch": 1.3414683137491212,
      "grad_norm": 0.16107286512851715,
      "learning_rate": 0.00011084337349397591,
      "loss": 0.3227,
      "step": 1670
    },
    {
      "epoch": 1.3495028623079242,
      "grad_norm": 0.14336737990379333,
      "learning_rate": 0.0001103078982597055,
      "loss": 0.3288,
      "step": 1680
    },
    {
      "epoch": 1.3575374108667269,
      "grad_norm": 0.19990164041519165,
      "learning_rate": 0.0001097724230254351,
      "loss": 0.3519,
      "step": 1690
    },
    {
      "epoch": 1.3655719594255298,
      "grad_norm": 0.14925788342952728,
      "learning_rate": 0.00010923694779116467,
      "loss": 0.3042,
      "step": 1700
    },
    {
      "epoch": 1.3736065079843327,
      "grad_norm": 0.15937820076942444,
      "learning_rate": 0.00010870147255689425,
      "loss": 0.3077,
      "step": 1710
    },
    {
      "epoch": 1.3816410565431354,
      "grad_norm": 0.17834344506263733,
      "learning_rate": 0.00010816599732262382,
      "loss": 0.3498,
      "step": 1720
    },
    {
      "epoch": 1.3896756051019383,
      "grad_norm": 0.19108012318611145,
      "learning_rate": 0.00010763052208835342,
      "loss": 0.395,
      "step": 1730
    },
    {
      "epoch": 1.3977101536607413,
      "grad_norm": 0.16483886539936066,
      "learning_rate": 0.00010709504685408301,
      "loss": 0.2952,
      "step": 1740
    },
    {
      "epoch": 1.4057447022195442,
      "grad_norm": 0.16408847272396088,
      "learning_rate": 0.00010655957161981258,
      "loss": 0.3537,
      "step": 1750
    },
    {
      "epoch": 1.4137792507783469,
      "grad_norm": 0.14878350496292114,
      "learning_rate": 0.00010602409638554218,
      "loss": 0.3389,
      "step": 1760
    },
    {
      "epoch": 1.4218137993371498,
      "grad_norm": 0.17166608572006226,
      "learning_rate": 0.00010548862115127177,
      "loss": 0.3656,
      "step": 1770
    },
    {
      "epoch": 1.4298483478959527,
      "grad_norm": 0.2218882441520691,
      "learning_rate": 0.00010495314591700134,
      "loss": 0.3288,
      "step": 1780
    },
    {
      "epoch": 1.4378828964547554,
      "grad_norm": 0.1747017502784729,
      "learning_rate": 0.00010441767068273094,
      "loss": 0.3708,
      "step": 1790
    },
    {
      "epoch": 1.4459174450135583,
      "grad_norm": 0.1780448704957962,
      "learning_rate": 0.00010388219544846052,
      "loss": 0.3326,
      "step": 1800
    },
    {
      "epoch": 1.4539519935723613,
      "grad_norm": 0.19661261141300201,
      "learning_rate": 0.0001033467202141901,
      "loss": 0.3329,
      "step": 1810
    },
    {
      "epoch": 1.461986542131164,
      "grad_norm": 0.1957409530878067,
      "learning_rate": 0.00010281124497991968,
      "loss": 0.3162,
      "step": 1820
    },
    {
      "epoch": 1.470021090689967,
      "grad_norm": 0.15493151545524597,
      "learning_rate": 0.00010227576974564928,
      "loss": 0.3323,
      "step": 1830
    },
    {
      "epoch": 1.4780556392487698,
      "grad_norm": 0.13516178727149963,
      "learning_rate": 0.00010174029451137885,
      "loss": 0.2726,
      "step": 1840
    },
    {
      "epoch": 1.4860901878075725,
      "grad_norm": 0.16861329972743988,
      "learning_rate": 0.00010120481927710844,
      "loss": 0.3422,
      "step": 1850
    },
    {
      "epoch": 1.4941247363663754,
      "grad_norm": 0.19754251837730408,
      "learning_rate": 0.00010066934404283804,
      "loss": 0.3355,
      "step": 1860
    },
    {
      "epoch": 1.5021592849251784,
      "grad_norm": 0.1706671416759491,
      "learning_rate": 0.00010013386880856761,
      "loss": 0.3647,
      "step": 1870
    },
    {
      "epoch": 1.510193833483981,
      "grad_norm": 0.17678290605545044,
      "learning_rate": 9.95983935742972e-05,
      "loss": 0.3139,
      "step": 1880
    },
    {
      "epoch": 1.518228382042784,
      "grad_norm": 0.16498659551143646,
      "learning_rate": 9.906291834002678e-05,
      "loss": 0.3653,
      "step": 1890
    },
    {
      "epoch": 1.526262930601587,
      "grad_norm": 0.17449072003364563,
      "learning_rate": 9.852744310575637e-05,
      "loss": 0.3661,
      "step": 1900
    },
    {
      "epoch": 1.5342974791603896,
      "grad_norm": 0.1523478925228119,
      "learning_rate": 9.799196787148595e-05,
      "loss": 0.3297,
      "step": 1910
    },
    {
      "epoch": 1.5423320277191925,
      "grad_norm": 0.18997275829315186,
      "learning_rate": 9.745649263721554e-05,
      "loss": 0.3683,
      "step": 1920
    },
    {
      "epoch": 1.5503665762779955,
      "grad_norm": 0.20248588919639587,
      "learning_rate": 9.692101740294511e-05,
      "loss": 0.3456,
      "step": 1930
    },
    {
      "epoch": 1.5584011248367982,
      "grad_norm": 0.20365449786186218,
      "learning_rate": 9.638554216867471e-05,
      "loss": 0.3166,
      "step": 1940
    },
    {
      "epoch": 1.566435673395601,
      "grad_norm": 0.15396857261657715,
      "learning_rate": 9.58500669344043e-05,
      "loss": 0.319,
      "step": 1950
    },
    {
      "epoch": 1.574470221954404,
      "grad_norm": 0.1500796675682068,
      "learning_rate": 9.531459170013387e-05,
      "loss": 0.3468,
      "step": 1960
    },
    {
      "epoch": 1.5825047705132067,
      "grad_norm": 0.15949440002441406,
      "learning_rate": 9.477911646586346e-05,
      "loss": 0.3745,
      "step": 1970
    },
    {
      "epoch": 1.5905393190720096,
      "grad_norm": 0.154740110039711,
      "learning_rate": 9.424364123159304e-05,
      "loss": 0.3271,
      "step": 1980
    },
    {
      "epoch": 1.5985738676308126,
      "grad_norm": 0.16771291196346283,
      "learning_rate": 9.370816599732262e-05,
      "loss": 0.3719,
      "step": 1990
    },
    {
      "epoch": 1.6066084161896153,
      "grad_norm": 0.1865275353193283,
      "learning_rate": 9.317269076305222e-05,
      "loss": 0.3456,
      "step": 2000
    },
    {
      "epoch": 1.6146429647484182,
      "grad_norm": 0.15655753016471863,
      "learning_rate": 9.26372155287818e-05,
      "loss": 0.3712,
      "step": 2010
    },
    {
      "epoch": 1.622677513307221,
      "grad_norm": 0.1686265915632248,
      "learning_rate": 9.210174029451138e-05,
      "loss": 0.3268,
      "step": 2020
    },
    {
      "epoch": 1.6307120618660238,
      "grad_norm": 0.22577300667762756,
      "learning_rate": 9.156626506024096e-05,
      "loss": 0.3575,
      "step": 2030
    },
    {
      "epoch": 1.6387466104248267,
      "grad_norm": 0.14020811021327972,
      "learning_rate": 9.103078982597055e-05,
      "loss": 0.3102,
      "step": 2040
    },
    {
      "epoch": 1.6467811589836296,
      "grad_norm": 0.22589918971061707,
      "learning_rate": 9.049531459170014e-05,
      "loss": 0.3384,
      "step": 2050
    },
    {
      "epoch": 1.6548157075424323,
      "grad_norm": 0.18966691195964813,
      "learning_rate": 8.995983935742972e-05,
      "loss": 0.3462,
      "step": 2060
    },
    {
      "epoch": 1.6628502561012353,
      "grad_norm": 0.15841029584407806,
      "learning_rate": 8.942436412315931e-05,
      "loss": 0.3316,
      "step": 2070
    },
    {
      "epoch": 1.6708848046600382,
      "grad_norm": 0.15385453402996063,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.3172,
      "step": 2080
    },
    {
      "epoch": 1.678919353218841,
      "grad_norm": 0.14544592797756195,
      "learning_rate": 8.835341365461848e-05,
      "loss": 0.3276,
      "step": 2090
    },
    {
      "epoch": 1.6869539017776438,
      "grad_norm": 0.20856612920761108,
      "learning_rate": 8.781793842034806e-05,
      "loss": 0.2926,
      "step": 2100
    },
    {
      "epoch": 1.6949884503364467,
      "grad_norm": 0.1715317815542221,
      "learning_rate": 8.728246318607765e-05,
      "loss": 0.3469,
      "step": 2110
    },
    {
      "epoch": 1.7030229988952494,
      "grad_norm": 0.16499429941177368,
      "learning_rate": 8.674698795180724e-05,
      "loss": 0.292,
      "step": 2120
    },
    {
      "epoch": 1.7110575474540526,
      "grad_norm": 0.2532300353050232,
      "learning_rate": 8.621151271753681e-05,
      "loss": 0.3736,
      "step": 2130
    },
    {
      "epoch": 1.7190920960128553,
      "grad_norm": 0.1251787692308426,
      "learning_rate": 8.567603748326641e-05,
      "loss": 0.2852,
      "step": 2140
    },
    {
      "epoch": 1.727126644571658,
      "grad_norm": 0.18928152322769165,
      "learning_rate": 8.514056224899599e-05,
      "loss": 0.3231,
      "step": 2150
    },
    {
      "epoch": 1.7351611931304611,
      "grad_norm": 0.14734186232089996,
      "learning_rate": 8.460508701472556e-05,
      "loss": 0.363,
      "step": 2160
    },
    {
      "epoch": 1.7431957416892638,
      "grad_norm": 0.15701110661029816,
      "learning_rate": 8.406961178045516e-05,
      "loss": 0.3122,
      "step": 2170
    },
    {
      "epoch": 1.7512302902480665,
      "grad_norm": 0.18573546409606934,
      "learning_rate": 8.353413654618474e-05,
      "loss": 0.307,
      "step": 2180
    },
    {
      "epoch": 1.7592648388068697,
      "grad_norm": 0.20189446210861206,
      "learning_rate": 8.299866131191432e-05,
      "loss": 0.4122,
      "step": 2190
    },
    {
      "epoch": 1.7672993873656724,
      "grad_norm": 0.22428077459335327,
      "learning_rate": 8.246318607764392e-05,
      "loss": 0.3294,
      "step": 2200
    },
    {
      "epoch": 1.775333935924475,
      "grad_norm": 0.17604409158229828,
      "learning_rate": 8.192771084337349e-05,
      "loss": 0.3641,
      "step": 2210
    },
    {
      "epoch": 1.7833684844832782,
      "grad_norm": 0.16948018968105316,
      "learning_rate": 8.139223560910308e-05,
      "loss": 0.3272,
      "step": 2220
    },
    {
      "epoch": 1.791403033042081,
      "grad_norm": 0.21291087567806244,
      "learning_rate": 8.085676037483266e-05,
      "loss": 0.3433,
      "step": 2230
    },
    {
      "epoch": 1.7994375816008839,
      "grad_norm": 0.14422519505023956,
      "learning_rate": 8.032128514056225e-05,
      "loss": 0.3001,
      "step": 2240
    },
    {
      "epoch": 1.8074721301596868,
      "grad_norm": 0.12600508332252502,
      "learning_rate": 7.978580990629184e-05,
      "loss": 0.2859,
      "step": 2250
    },
    {
      "epoch": 1.8155066787184895,
      "grad_norm": 0.15116073191165924,
      "learning_rate": 7.925033467202142e-05,
      "loss": 0.3402,
      "step": 2260
    },
    {
      "epoch": 1.8235412272772924,
      "grad_norm": 0.19475248456001282,
      "learning_rate": 7.8714859437751e-05,
      "loss": 0.3083,
      "step": 2270
    },
    {
      "epoch": 1.8315757758360953,
      "grad_norm": 0.1495218127965927,
      "learning_rate": 7.817938420348059e-05,
      "loss": 0.3039,
      "step": 2280
    },
    {
      "epoch": 1.839610324394898,
      "grad_norm": 0.16861306130886078,
      "learning_rate": 7.764390896921018e-05,
      "loss": 0.3649,
      "step": 2290
    },
    {
      "epoch": 1.847644872953701,
      "grad_norm": 0.21987183392047882,
      "learning_rate": 7.710843373493976e-05,
      "loss": 0.387,
      "step": 2300
    },
    {
      "epoch": 1.8556794215125039,
      "grad_norm": 0.22238938510417938,
      "learning_rate": 7.657295850066935e-05,
      "loss": 0.3719,
      "step": 2310
    },
    {
      "epoch": 1.8637139700713066,
      "grad_norm": 0.15708258748054504,
      "learning_rate": 7.603748326639893e-05,
      "loss": 0.3309,
      "step": 2320
    },
    {
      "epoch": 1.8717485186301095,
      "grad_norm": 0.16936315596103668,
      "learning_rate": 7.550200803212851e-05,
      "loss": 0.3547,
      "step": 2330
    },
    {
      "epoch": 1.8797830671889124,
      "grad_norm": 0.15975479781627655,
      "learning_rate": 7.49665327978581e-05,
      "loss": 0.3383,
      "step": 2340
    },
    {
      "epoch": 1.8878176157477151,
      "grad_norm": 0.1639396846294403,
      "learning_rate": 7.443105756358769e-05,
      "loss": 0.3491,
      "step": 2350
    },
    {
      "epoch": 1.895852164306518,
      "grad_norm": 0.22418995201587677,
      "learning_rate": 7.389558232931726e-05,
      "loss": 0.3093,
      "step": 2360
    },
    {
      "epoch": 1.903886712865321,
      "grad_norm": 0.21015426516532898,
      "learning_rate": 7.336010709504686e-05,
      "loss": 0.3503,
      "step": 2370
    },
    {
      "epoch": 1.9119212614241237,
      "grad_norm": 0.20779730379581451,
      "learning_rate": 7.282463186077644e-05,
      "loss": 0.3749,
      "step": 2380
    },
    {
      "epoch": 1.9199558099829266,
      "grad_norm": 0.1784157156944275,
      "learning_rate": 7.228915662650602e-05,
      "loss": 0.2793,
      "step": 2390
    },
    {
      "epoch": 1.9279903585417295,
      "grad_norm": 0.16708694398403168,
      "learning_rate": 7.175368139223562e-05,
      "loss": 0.328,
      "step": 2400
    },
    {
      "epoch": 1.9360249071005322,
      "grad_norm": 0.14262846112251282,
      "learning_rate": 7.121820615796519e-05,
      "loss": 0.3105,
      "step": 2410
    },
    {
      "epoch": 1.9440594556593351,
      "grad_norm": 0.20004786550998688,
      "learning_rate": 7.068273092369478e-05,
      "loss": 0.3139,
      "step": 2420
    },
    {
      "epoch": 1.952094004218138,
      "grad_norm": 0.1803560107946396,
      "learning_rate": 7.014725568942436e-05,
      "loss": 0.3337,
      "step": 2430
    },
    {
      "epoch": 1.9601285527769408,
      "grad_norm": 0.22359366714954376,
      "learning_rate": 6.961178045515395e-05,
      "loss": 0.3683,
      "step": 2440
    },
    {
      "epoch": 1.9681631013357437,
      "grad_norm": 0.1992710381746292,
      "learning_rate": 6.907630522088355e-05,
      "loss": 0.2918,
      "step": 2450
    },
    {
      "epoch": 1.9761976498945466,
      "grad_norm": 0.1988743096590042,
      "learning_rate": 6.854082998661312e-05,
      "loss": 0.3662,
      "step": 2460
    },
    {
      "epoch": 1.9842321984533493,
      "grad_norm": 0.14978069067001343,
      "learning_rate": 6.80053547523427e-05,
      "loss": 0.2675,
      "step": 2470
    },
    {
      "epoch": 1.9922667470121522,
      "grad_norm": 0.20524154603481293,
      "learning_rate": 6.746987951807229e-05,
      "loss": 0.3181,
      "step": 2480
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2979680895805359,
      "learning_rate": 6.693440428380188e-05,
      "loss": 0.3473,
      "step": 2490
    }
  ],
  "logging_steps": 10,
  "max_steps": 3735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7300043973892506e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

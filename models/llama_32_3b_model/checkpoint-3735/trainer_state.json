{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3735,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008034548558802852,
      "grad_norm": 1.0373977422714233,
      "learning_rate": 0.0001997322623828648,
      "loss": 6.9154,
      "step": 10
    },
    {
      "epoch": 0.016069097117605704,
      "grad_norm": 0.30423006415367126,
      "learning_rate": 0.0001991967871485944,
      "loss": 0.7186,
      "step": 20
    },
    {
      "epoch": 0.024103645676408558,
      "grad_norm": 0.18798606097698212,
      "learning_rate": 0.00019866131191432397,
      "loss": 0.5324,
      "step": 30
    },
    {
      "epoch": 0.03213819423521141,
      "grad_norm": 0.14447475969791412,
      "learning_rate": 0.00019812583668005356,
      "loss": 0.4699,
      "step": 40
    },
    {
      "epoch": 0.04017274279401426,
      "grad_norm": 0.23008406162261963,
      "learning_rate": 0.00019759036144578314,
      "loss": 0.5084,
      "step": 50
    },
    {
      "epoch": 0.048207291352817115,
      "grad_norm": 0.2064332216978073,
      "learning_rate": 0.00019705488621151273,
      "loss": 0.5097,
      "step": 60
    },
    {
      "epoch": 0.05624183991161997,
      "grad_norm": 0.1356736272573471,
      "learning_rate": 0.00019651941097724232,
      "loss": 0.3803,
      "step": 70
    },
    {
      "epoch": 0.06427638847042282,
      "grad_norm": 0.17006024718284607,
      "learning_rate": 0.0001959839357429719,
      "loss": 0.4234,
      "step": 80
    },
    {
      "epoch": 0.07231093702922567,
      "grad_norm": 0.22150123119354248,
      "learning_rate": 0.0001954484605087015,
      "loss": 0.4537,
      "step": 90
    },
    {
      "epoch": 0.08034548558802852,
      "grad_norm": 0.20373305678367615,
      "learning_rate": 0.00019491298527443107,
      "loss": 0.4047,
      "step": 100
    },
    {
      "epoch": 0.08838003414683138,
      "grad_norm": 0.15008515119552612,
      "learning_rate": 0.00019437751004016066,
      "loss": 0.4052,
      "step": 110
    },
    {
      "epoch": 0.09641458270563423,
      "grad_norm": 0.14398758113384247,
      "learning_rate": 0.00019384203480589022,
      "loss": 0.4351,
      "step": 120
    },
    {
      "epoch": 0.10444913126443708,
      "grad_norm": 0.16062946617603302,
      "learning_rate": 0.00019330655957161983,
      "loss": 0.4175,
      "step": 130
    },
    {
      "epoch": 0.11248367982323994,
      "grad_norm": 0.1657368242740631,
      "learning_rate": 0.00019277108433734942,
      "loss": 0.4161,
      "step": 140
    },
    {
      "epoch": 0.12051822838204278,
      "grad_norm": 0.20168568193912506,
      "learning_rate": 0.00019223560910307897,
      "loss": 0.4906,
      "step": 150
    },
    {
      "epoch": 0.12855277694084563,
      "grad_norm": 0.1492224782705307,
      "learning_rate": 0.0001917001338688086,
      "loss": 0.4015,
      "step": 160
    },
    {
      "epoch": 0.1365873254996485,
      "grad_norm": 0.15185053646564484,
      "learning_rate": 0.00019116465863453817,
      "loss": 0.4199,
      "step": 170
    },
    {
      "epoch": 0.14462187405845134,
      "grad_norm": 0.13899379968643188,
      "learning_rate": 0.00019062918340026773,
      "loss": 0.4268,
      "step": 180
    },
    {
      "epoch": 0.1526564226172542,
      "grad_norm": 0.1545664668083191,
      "learning_rate": 0.00019009370816599734,
      "loss": 0.4512,
      "step": 190
    },
    {
      "epoch": 0.16069097117605705,
      "grad_norm": 0.16737189888954163,
      "learning_rate": 0.00018955823293172693,
      "loss": 0.4082,
      "step": 200
    },
    {
      "epoch": 0.16872551973485989,
      "grad_norm": 0.14347544312477112,
      "learning_rate": 0.0001890227576974565,
      "loss": 0.4093,
      "step": 210
    },
    {
      "epoch": 0.17676006829366275,
      "grad_norm": 0.1646565943956375,
      "learning_rate": 0.00018848728246318607,
      "loss": 0.437,
      "step": 220
    },
    {
      "epoch": 0.1847946168524656,
      "grad_norm": 0.15071415901184082,
      "learning_rate": 0.00018795180722891569,
      "loss": 0.3842,
      "step": 230
    },
    {
      "epoch": 0.19282916541126846,
      "grad_norm": 0.16400277614593506,
      "learning_rate": 0.00018741633199464524,
      "loss": 0.3796,
      "step": 240
    },
    {
      "epoch": 0.2008637139700713,
      "grad_norm": 0.17444612085819244,
      "learning_rate": 0.00018688085676037483,
      "loss": 0.3439,
      "step": 250
    },
    {
      "epoch": 0.20889826252887417,
      "grad_norm": 0.23109838366508484,
      "learning_rate": 0.00018634538152610444,
      "loss": 0.3512,
      "step": 260
    },
    {
      "epoch": 0.216932811087677,
      "grad_norm": 0.15906475484371185,
      "learning_rate": 0.000185809906291834,
      "loss": 0.3493,
      "step": 270
    },
    {
      "epoch": 0.22496735964647988,
      "grad_norm": 0.14465388655662537,
      "learning_rate": 0.0001852744310575636,
      "loss": 0.3436,
      "step": 280
    },
    {
      "epoch": 0.23300190820528272,
      "grad_norm": 0.1642436385154724,
      "learning_rate": 0.0001847389558232932,
      "loss": 0.3703,
      "step": 290
    },
    {
      "epoch": 0.24103645676408555,
      "grad_norm": 0.20387201011180878,
      "learning_rate": 0.00018420348058902276,
      "loss": 0.3959,
      "step": 300
    },
    {
      "epoch": 0.24907100532288842,
      "grad_norm": 0.1556016355752945,
      "learning_rate": 0.00018366800535475234,
      "loss": 0.4068,
      "step": 310
    },
    {
      "epoch": 0.25710555388169126,
      "grad_norm": 0.15081371366977692,
      "learning_rate": 0.00018313253012048193,
      "loss": 0.4,
      "step": 320
    },
    {
      "epoch": 0.26514010244049413,
      "grad_norm": 0.11856018006801605,
      "learning_rate": 0.00018259705488621152,
      "loss": 0.3442,
      "step": 330
    },
    {
      "epoch": 0.273174650999297,
      "grad_norm": 0.14013396203517914,
      "learning_rate": 0.0001820615796519411,
      "loss": 0.3942,
      "step": 340
    },
    {
      "epoch": 0.2812091995580998,
      "grad_norm": 0.14599798619747162,
      "learning_rate": 0.0001815261044176707,
      "loss": 0.3482,
      "step": 350
    },
    {
      "epoch": 0.2892437481169027,
      "grad_norm": 0.13799016177654266,
      "learning_rate": 0.00018099062918340027,
      "loss": 0.4152,
      "step": 360
    },
    {
      "epoch": 0.29727829667570554,
      "grad_norm": 0.1324983835220337,
      "learning_rate": 0.00018045515394912986,
      "loss": 0.3439,
      "step": 370
    },
    {
      "epoch": 0.3053128452345084,
      "grad_norm": 0.140101358294487,
      "learning_rate": 0.00017991967871485944,
      "loss": 0.3737,
      "step": 380
    },
    {
      "epoch": 0.3133473937933112,
      "grad_norm": 0.11805727332830429,
      "learning_rate": 0.00017938420348058903,
      "loss": 0.3761,
      "step": 390
    },
    {
      "epoch": 0.3213819423521141,
      "grad_norm": 0.15552829205989838,
      "learning_rate": 0.00017884872824631862,
      "loss": 0.341,
      "step": 400
    },
    {
      "epoch": 0.32941649091091696,
      "grad_norm": 0.13736817240715027,
      "learning_rate": 0.0001783132530120482,
      "loss": 0.3413,
      "step": 410
    },
    {
      "epoch": 0.33745103946971977,
      "grad_norm": 0.14059296250343323,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.3181,
      "step": 420
    },
    {
      "epoch": 0.34548558802852264,
      "grad_norm": 0.1314832866191864,
      "learning_rate": 0.00017724230254350737,
      "loss": 0.3851,
      "step": 430
    },
    {
      "epoch": 0.3535201365873255,
      "grad_norm": 0.12976747751235962,
      "learning_rate": 0.00017670682730923696,
      "loss": 0.3479,
      "step": 440
    },
    {
      "epoch": 0.3615546851461284,
      "grad_norm": 0.1509714275598526,
      "learning_rate": 0.00017617135207496654,
      "loss": 0.3932,
      "step": 450
    },
    {
      "epoch": 0.3695892337049312,
      "grad_norm": 0.17412757873535156,
      "learning_rate": 0.00017563587684069613,
      "loss": 0.3521,
      "step": 460
    },
    {
      "epoch": 0.37762378226373405,
      "grad_norm": 0.14991441369056702,
      "learning_rate": 0.00017510040160642571,
      "loss": 0.3286,
      "step": 470
    },
    {
      "epoch": 0.3856583308225369,
      "grad_norm": 0.13779541850090027,
      "learning_rate": 0.0001745649263721553,
      "loss": 0.3671,
      "step": 480
    },
    {
      "epoch": 0.3936928793813398,
      "grad_norm": 0.14195816218852997,
      "learning_rate": 0.00017402945113788489,
      "loss": 0.4027,
      "step": 490
    },
    {
      "epoch": 0.4017274279401426,
      "grad_norm": 0.12471170723438263,
      "learning_rate": 0.00017349397590361447,
      "loss": 0.4343,
      "step": 500
    },
    {
      "epoch": 0.40976197649894547,
      "grad_norm": 0.15163148939609528,
      "learning_rate": 0.00017295850066934406,
      "loss": 0.3442,
      "step": 510
    },
    {
      "epoch": 0.41779652505774834,
      "grad_norm": 0.15107619762420654,
      "learning_rate": 0.00017242302543507362,
      "loss": 0.3647,
      "step": 520
    },
    {
      "epoch": 0.42583107361655115,
      "grad_norm": 0.13999304175376892,
      "learning_rate": 0.00017188755020080323,
      "loss": 0.3628,
      "step": 530
    },
    {
      "epoch": 0.433865622175354,
      "grad_norm": 0.1650177240371704,
      "learning_rate": 0.00017135207496653281,
      "loss": 0.3834,
      "step": 540
    },
    {
      "epoch": 0.4419001707341569,
      "grad_norm": 0.126255601644516,
      "learning_rate": 0.00017081659973226237,
      "loss": 0.4465,
      "step": 550
    },
    {
      "epoch": 0.44993471929295975,
      "grad_norm": 0.15670904517173767,
      "learning_rate": 0.00017028112449799199,
      "loss": 0.3325,
      "step": 560
    },
    {
      "epoch": 0.45796926785176256,
      "grad_norm": 0.12534666061401367,
      "learning_rate": 0.00016974564926372157,
      "loss": 0.3643,
      "step": 570
    },
    {
      "epoch": 0.46600381641056543,
      "grad_norm": 0.1701141893863678,
      "learning_rate": 0.00016921017402945113,
      "loss": 0.3708,
      "step": 580
    },
    {
      "epoch": 0.4740383649693683,
      "grad_norm": 0.12662281095981598,
      "learning_rate": 0.00016867469879518074,
      "loss": 0.3711,
      "step": 590
    },
    {
      "epoch": 0.4820729135281711,
      "grad_norm": 0.18864040076732635,
      "learning_rate": 0.00016813922356091033,
      "loss": 0.3458,
      "step": 600
    },
    {
      "epoch": 0.490107462086974,
      "grad_norm": 0.15426218509674072,
      "learning_rate": 0.00016760374832663989,
      "loss": 0.362,
      "step": 610
    },
    {
      "epoch": 0.49814201064577684,
      "grad_norm": 0.13543865084648132,
      "learning_rate": 0.00016706827309236947,
      "loss": 0.3871,
      "step": 620
    },
    {
      "epoch": 0.5061765592045797,
      "grad_norm": 0.18093110620975494,
      "learning_rate": 0.00016653279785809908,
      "loss": 0.3232,
      "step": 630
    },
    {
      "epoch": 0.5142111077633825,
      "grad_norm": 0.15284331142902374,
      "learning_rate": 0.00016599732262382864,
      "loss": 0.4009,
      "step": 640
    },
    {
      "epoch": 0.5222456563221854,
      "grad_norm": 0.15323181450366974,
      "learning_rate": 0.00016546184738955823,
      "loss": 0.4051,
      "step": 650
    },
    {
      "epoch": 0.5302802048809883,
      "grad_norm": 0.14679692685604095,
      "learning_rate": 0.00016492637215528784,
      "loss": 0.372,
      "step": 660
    },
    {
      "epoch": 0.5383147534397911,
      "grad_norm": 0.15374250710010529,
      "learning_rate": 0.0001643908969210174,
      "loss": 0.354,
      "step": 670
    },
    {
      "epoch": 0.546349301998594,
      "grad_norm": 0.13475187122821808,
      "learning_rate": 0.00016385542168674699,
      "loss": 0.3547,
      "step": 680
    },
    {
      "epoch": 0.5543838505573968,
      "grad_norm": 0.13448861241340637,
      "learning_rate": 0.0001633199464524766,
      "loss": 0.3163,
      "step": 690
    },
    {
      "epoch": 0.5624183991161996,
      "grad_norm": 0.1288829743862152,
      "learning_rate": 0.00016278447121820616,
      "loss": 0.3632,
      "step": 700
    },
    {
      "epoch": 0.5704529476750025,
      "grad_norm": 0.11543543636798859,
      "learning_rate": 0.00016224899598393574,
      "loss": 0.3652,
      "step": 710
    },
    {
      "epoch": 0.5784874962338054,
      "grad_norm": 0.12662579119205475,
      "learning_rate": 0.00016171352074966533,
      "loss": 0.3807,
      "step": 720
    },
    {
      "epoch": 0.5865220447926082,
      "grad_norm": 0.14323389530181885,
      "learning_rate": 0.00016117804551539491,
      "loss": 0.4001,
      "step": 730
    },
    {
      "epoch": 0.5945565933514111,
      "grad_norm": 0.13263379037380219,
      "learning_rate": 0.0001606425702811245,
      "loss": 0.3554,
      "step": 740
    },
    {
      "epoch": 0.6025911419102139,
      "grad_norm": 0.14238335192203522,
      "learning_rate": 0.00016010709504685409,
      "loss": 0.3226,
      "step": 750
    },
    {
      "epoch": 0.6106256904690168,
      "grad_norm": 0.13664333522319794,
      "learning_rate": 0.00015957161981258367,
      "loss": 0.3663,
      "step": 760
    },
    {
      "epoch": 0.6186602390278196,
      "grad_norm": 0.13073422014713287,
      "learning_rate": 0.00015903614457831326,
      "loss": 0.3638,
      "step": 770
    },
    {
      "epoch": 0.6266947875866224,
      "grad_norm": 0.1339569240808487,
      "learning_rate": 0.00015850066934404284,
      "loss": 0.2989,
      "step": 780
    },
    {
      "epoch": 0.6347293361454254,
      "grad_norm": 0.1554918736219406,
      "learning_rate": 0.00015796519410977243,
      "loss": 0.4057,
      "step": 790
    },
    {
      "epoch": 0.6427638847042282,
      "grad_norm": 0.13950280845165253,
      "learning_rate": 0.000157429718875502,
      "loss": 0.3319,
      "step": 800
    },
    {
      "epoch": 0.650798433263031,
      "grad_norm": 0.11782950162887573,
      "learning_rate": 0.0001568942436412316,
      "loss": 0.3177,
      "step": 810
    },
    {
      "epoch": 0.6588329818218339,
      "grad_norm": 0.12576988339424133,
      "learning_rate": 0.00015635876840696118,
      "loss": 0.3186,
      "step": 820
    },
    {
      "epoch": 0.6668675303806367,
      "grad_norm": 0.14569640159606934,
      "learning_rate": 0.00015582329317269077,
      "loss": 0.385,
      "step": 830
    },
    {
      "epoch": 0.6749020789394395,
      "grad_norm": 0.1621841937303543,
      "learning_rate": 0.00015528781793842036,
      "loss": 0.4089,
      "step": 840
    },
    {
      "epoch": 0.6829366274982425,
      "grad_norm": 0.13134099543094635,
      "learning_rate": 0.00015475234270414994,
      "loss": 0.3466,
      "step": 850
    },
    {
      "epoch": 0.6909711760570453,
      "grad_norm": 0.11348912119865417,
      "learning_rate": 0.00015421686746987953,
      "loss": 0.3043,
      "step": 860
    },
    {
      "epoch": 0.6990057246158482,
      "grad_norm": 0.19597801566123962,
      "learning_rate": 0.0001536813922356091,
      "loss": 0.3887,
      "step": 870
    },
    {
      "epoch": 0.707040273174651,
      "grad_norm": 0.1569252610206604,
      "learning_rate": 0.0001531459170013387,
      "loss": 0.3651,
      "step": 880
    },
    {
      "epoch": 0.7150748217334538,
      "grad_norm": 0.12994404137134552,
      "learning_rate": 0.00015261044176706828,
      "loss": 0.3334,
      "step": 890
    },
    {
      "epoch": 0.7231093702922567,
      "grad_norm": 0.13774006068706512,
      "learning_rate": 0.00015207496653279787,
      "loss": 0.3561,
      "step": 900
    },
    {
      "epoch": 0.7311439188510596,
      "grad_norm": 0.14080780744552612,
      "learning_rate": 0.00015153949129852746,
      "loss": 0.331,
      "step": 910
    },
    {
      "epoch": 0.7391784674098624,
      "grad_norm": 0.11512520909309387,
      "learning_rate": 0.00015100401606425701,
      "loss": 0.3258,
      "step": 920
    },
    {
      "epoch": 0.7472130159686653,
      "grad_norm": 0.13046146929264069,
      "learning_rate": 0.00015046854082998663,
      "loss": 0.3597,
      "step": 930
    },
    {
      "epoch": 0.7552475645274681,
      "grad_norm": 0.14750921726226807,
      "learning_rate": 0.0001499330655957162,
      "loss": 0.3491,
      "step": 940
    },
    {
      "epoch": 0.7632821130862709,
      "grad_norm": 0.13117294013500214,
      "learning_rate": 0.00014939759036144577,
      "loss": 0.37,
      "step": 950
    },
    {
      "epoch": 0.7713166616450738,
      "grad_norm": 0.12348867952823639,
      "learning_rate": 0.00014886211512717538,
      "loss": 0.3567,
      "step": 960
    },
    {
      "epoch": 0.7793512102038767,
      "grad_norm": 0.11180102080106735,
      "learning_rate": 0.00014832663989290497,
      "loss": 0.3198,
      "step": 970
    },
    {
      "epoch": 0.7873857587626796,
      "grad_norm": 0.14421498775482178,
      "learning_rate": 0.00014779116465863453,
      "loss": 0.3545,
      "step": 980
    },
    {
      "epoch": 0.7954203073214824,
      "grad_norm": 0.1733960658311844,
      "learning_rate": 0.00014725568942436414,
      "loss": 0.4086,
      "step": 990
    },
    {
      "epoch": 0.8034548558802852,
      "grad_norm": 0.1372808814048767,
      "learning_rate": 0.00014672021419009373,
      "loss": 0.2998,
      "step": 1000
    },
    {
      "epoch": 0.8114894044390881,
      "grad_norm": 0.1272394061088562,
      "learning_rate": 0.00014618473895582328,
      "loss": 0.3507,
      "step": 1010
    },
    {
      "epoch": 0.8195239529978909,
      "grad_norm": 0.162174254655838,
      "learning_rate": 0.00014564926372155287,
      "loss": 0.3738,
      "step": 1020
    },
    {
      "epoch": 0.8275585015566937,
      "grad_norm": 0.16035638749599457,
      "learning_rate": 0.00014511378848728248,
      "loss": 0.3921,
      "step": 1030
    },
    {
      "epoch": 0.8355930501154967,
      "grad_norm": 0.1867516189813614,
      "learning_rate": 0.00014457831325301204,
      "loss": 0.3871,
      "step": 1040
    },
    {
      "epoch": 0.8436275986742995,
      "grad_norm": 0.13369876146316528,
      "learning_rate": 0.00014404283801874163,
      "loss": 0.3425,
      "step": 1050
    },
    {
      "epoch": 0.8516621472331023,
      "grad_norm": 0.12167710065841675,
      "learning_rate": 0.00014350736278447124,
      "loss": 0.3009,
      "step": 1060
    },
    {
      "epoch": 0.8596966957919052,
      "grad_norm": 0.12410513311624527,
      "learning_rate": 0.0001429718875502008,
      "loss": 0.3363,
      "step": 1070
    },
    {
      "epoch": 0.867731244350708,
      "grad_norm": 0.09841236472129822,
      "learning_rate": 0.00014243641231593038,
      "loss": 0.3682,
      "step": 1080
    },
    {
      "epoch": 0.8757657929095108,
      "grad_norm": 0.14756140112876892,
      "learning_rate": 0.00014190093708166,
      "loss": 0.374,
      "step": 1090
    },
    {
      "epoch": 0.8838003414683138,
      "grad_norm": 0.15321993827819824,
      "learning_rate": 0.00014136546184738956,
      "loss": 0.374,
      "step": 1100
    },
    {
      "epoch": 0.8918348900271166,
      "grad_norm": 0.17200085520744324,
      "learning_rate": 0.00014082998661311914,
      "loss": 0.3733,
      "step": 1110
    },
    {
      "epoch": 0.8998694385859195,
      "grad_norm": 0.156183660030365,
      "learning_rate": 0.00014029451137884873,
      "loss": 0.3476,
      "step": 1120
    },
    {
      "epoch": 0.9079039871447223,
      "grad_norm": 0.1381406933069229,
      "learning_rate": 0.00013975903614457834,
      "loss": 0.3429,
      "step": 1130
    },
    {
      "epoch": 0.9159385357035251,
      "grad_norm": 0.15278637409210205,
      "learning_rate": 0.0001392235609103079,
      "loss": 0.3226,
      "step": 1140
    },
    {
      "epoch": 0.923973084262328,
      "grad_norm": 0.132486492395401,
      "learning_rate": 0.00013868808567603748,
      "loss": 0.3215,
      "step": 1150
    },
    {
      "epoch": 0.9320076328211309,
      "grad_norm": 0.13444645702838898,
      "learning_rate": 0.0001381526104417671,
      "loss": 0.3593,
      "step": 1160
    },
    {
      "epoch": 0.9400421813799337,
      "grad_norm": 0.13581356406211853,
      "learning_rate": 0.00013761713520749665,
      "loss": 0.3721,
      "step": 1170
    },
    {
      "epoch": 0.9480767299387366,
      "grad_norm": 0.15123571455478668,
      "learning_rate": 0.00013708165997322624,
      "loss": 0.3785,
      "step": 1180
    },
    {
      "epoch": 0.9561112784975394,
      "grad_norm": 0.12052050977945328,
      "learning_rate": 0.00013654618473895585,
      "loss": 0.3309,
      "step": 1190
    },
    {
      "epoch": 0.9641458270563422,
      "grad_norm": 0.1255498230457306,
      "learning_rate": 0.0001360107095046854,
      "loss": 0.3858,
      "step": 1200
    },
    {
      "epoch": 0.9721803756151451,
      "grad_norm": 0.12577643990516663,
      "learning_rate": 0.000135475234270415,
      "loss": 0.3335,
      "step": 1210
    },
    {
      "epoch": 0.980214924173948,
      "grad_norm": 0.1964809000492096,
      "learning_rate": 0.00013493975903614458,
      "loss": 0.378,
      "step": 1220
    },
    {
      "epoch": 0.9882494727327509,
      "grad_norm": 0.14193300902843475,
      "learning_rate": 0.00013440428380187417,
      "loss": 0.3159,
      "step": 1230
    },
    {
      "epoch": 0.9962840212915537,
      "grad_norm": 0.12691381573677063,
      "learning_rate": 0.00013386880856760375,
      "loss": 0.3275,
      "step": 1240
    },
    {
      "epoch": 1.0040172742794014,
      "grad_norm": 0.13694779574871063,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.3866,
      "step": 1250
    },
    {
      "epoch": 1.0120518228382043,
      "grad_norm": 0.15238317847251892,
      "learning_rate": 0.00013279785809906293,
      "loss": 0.3329,
      "step": 1260
    },
    {
      "epoch": 1.0200863713970072,
      "grad_norm": 0.15172436833381653,
      "learning_rate": 0.0001322623828647925,
      "loss": 0.4294,
      "step": 1270
    },
    {
      "epoch": 1.02812091995581,
      "grad_norm": 0.16846007108688354,
      "learning_rate": 0.0001317269076305221,
      "loss": 0.3008,
      "step": 1280
    },
    {
      "epoch": 1.0361554685146128,
      "grad_norm": 0.18917331099510193,
      "learning_rate": 0.00013119143239625168,
      "loss": 0.3076,
      "step": 1290
    },
    {
      "epoch": 1.0441900170734157,
      "grad_norm": 0.176502987742424,
      "learning_rate": 0.00013065595716198127,
      "loss": 0.3642,
      "step": 1300
    },
    {
      "epoch": 1.0522245656322184,
      "grad_norm": 0.16104361414909363,
      "learning_rate": 0.00013012048192771085,
      "loss": 0.332,
      "step": 1310
    },
    {
      "epoch": 1.0602591141910214,
      "grad_norm": 0.14212384819984436,
      "learning_rate": 0.0001295850066934404,
      "loss": 0.3249,
      "step": 1320
    },
    {
      "epoch": 1.0682936627498243,
      "grad_norm": 0.16038547456264496,
      "learning_rate": 0.00012904953145917002,
      "loss": 0.3163,
      "step": 1330
    },
    {
      "epoch": 1.0763282113086272,
      "grad_norm": 0.15652818977832794,
      "learning_rate": 0.0001285140562248996,
      "loss": 0.3336,
      "step": 1340
    },
    {
      "epoch": 1.08436275986743,
      "grad_norm": 0.15337540209293365,
      "learning_rate": 0.00012797858099062917,
      "loss": 0.3375,
      "step": 1350
    },
    {
      "epoch": 1.0923973084262328,
      "grad_norm": 0.12772820889949799,
      "learning_rate": 0.00012744310575635878,
      "loss": 0.3313,
      "step": 1360
    },
    {
      "epoch": 1.1004318569850358,
      "grad_norm": 0.16377659142017365,
      "learning_rate": 0.00012690763052208837,
      "loss": 0.388,
      "step": 1370
    },
    {
      "epoch": 1.1084664055438385,
      "grad_norm": 0.1798485517501831,
      "learning_rate": 0.00012637215528781793,
      "loss": 0.4039,
      "step": 1380
    },
    {
      "epoch": 1.1165009541026414,
      "grad_norm": 0.13677653670310974,
      "learning_rate": 0.00012583668005354754,
      "loss": 0.3579,
      "step": 1390
    },
    {
      "epoch": 1.1245355026614443,
      "grad_norm": 0.14919322729110718,
      "learning_rate": 0.00012530120481927712,
      "loss": 0.337,
      "step": 1400
    },
    {
      "epoch": 1.132570051220247,
      "grad_norm": 0.14551948010921478,
      "learning_rate": 0.0001247657295850067,
      "loss": 0.3908,
      "step": 1410
    },
    {
      "epoch": 1.14060459977905,
      "grad_norm": 0.1429954171180725,
      "learning_rate": 0.00012423025435073627,
      "loss": 0.3774,
      "step": 1420
    },
    {
      "epoch": 1.1486391483378529,
      "grad_norm": 0.14960871636867523,
      "learning_rate": 0.00012369477911646588,
      "loss": 0.3394,
      "step": 1430
    },
    {
      "epoch": 1.1566736968966556,
      "grad_norm": 0.1362229585647583,
      "learning_rate": 0.00012315930388219547,
      "loss": 0.3416,
      "step": 1440
    },
    {
      "epoch": 1.1647082454554585,
      "grad_norm": 0.14940789341926575,
      "learning_rate": 0.00012262382864792503,
      "loss": 0.3444,
      "step": 1450
    },
    {
      "epoch": 1.1727427940142614,
      "grad_norm": 0.17096664011478424,
      "learning_rate": 0.00012208835341365464,
      "loss": 0.327,
      "step": 1460
    },
    {
      "epoch": 1.180777342573064,
      "grad_norm": 0.14427550137043,
      "learning_rate": 0.00012155287817938421,
      "loss": 0.3537,
      "step": 1470
    },
    {
      "epoch": 1.188811891131867,
      "grad_norm": 0.14001642167568207,
      "learning_rate": 0.0001210174029451138,
      "loss": 0.3542,
      "step": 1480
    },
    {
      "epoch": 1.19684643969067,
      "grad_norm": 0.16559037566184998,
      "learning_rate": 0.0001204819277108434,
      "loss": 0.3585,
      "step": 1490
    },
    {
      "epoch": 1.2048809882494727,
      "grad_norm": 0.15665845572948456,
      "learning_rate": 0.00011994645247657297,
      "loss": 0.3177,
      "step": 1500
    },
    {
      "epoch": 1.2129155368082756,
      "grad_norm": 0.15587951242923737,
      "learning_rate": 0.00011941097724230255,
      "loss": 0.3245,
      "step": 1510
    },
    {
      "epoch": 1.2209500853670785,
      "grad_norm": 0.19402356445789337,
      "learning_rate": 0.00011887550200803212,
      "loss": 0.3062,
      "step": 1520
    },
    {
      "epoch": 1.2289846339258812,
      "grad_norm": 0.20641301572322845,
      "learning_rate": 0.00011834002677376172,
      "loss": 0.3539,
      "step": 1530
    },
    {
      "epoch": 1.2370191824846841,
      "grad_norm": 0.19700537621974945,
      "learning_rate": 0.00011780455153949131,
      "loss": 0.3515,
      "step": 1540
    },
    {
      "epoch": 1.245053731043487,
      "grad_norm": 0.1574840545654297,
      "learning_rate": 0.00011726907630522088,
      "loss": 0.3492,
      "step": 1550
    },
    {
      "epoch": 1.2530882796022897,
      "grad_norm": 0.15300855040550232,
      "learning_rate": 0.00011673360107095048,
      "loss": 0.3857,
      "step": 1560
    },
    {
      "epoch": 1.2611228281610927,
      "grad_norm": 0.13678747415542603,
      "learning_rate": 0.00011619812583668007,
      "loss": 0.3285,
      "step": 1570
    },
    {
      "epoch": 1.2691573767198956,
      "grad_norm": 0.20398001372814178,
      "learning_rate": 0.00011566265060240964,
      "loss": 0.357,
      "step": 1580
    },
    {
      "epoch": 1.2771919252786983,
      "grad_norm": 0.17522726953029633,
      "learning_rate": 0.00011512717536813924,
      "loss": 0.3106,
      "step": 1590
    },
    {
      "epoch": 1.2852264738375012,
      "grad_norm": 0.14253441989421844,
      "learning_rate": 0.00011459170013386882,
      "loss": 0.3008,
      "step": 1600
    },
    {
      "epoch": 1.2932610223963041,
      "grad_norm": 0.16615858674049377,
      "learning_rate": 0.0001140562248995984,
      "loss": 0.3554,
      "step": 1610
    },
    {
      "epoch": 1.3012955709551068,
      "grad_norm": 0.1400468498468399,
      "learning_rate": 0.00011352074966532798,
      "loss": 0.351,
      "step": 1620
    },
    {
      "epoch": 1.3093301195139098,
      "grad_norm": 0.19078408181667328,
      "learning_rate": 0.00011298527443105758,
      "loss": 0.3374,
      "step": 1630
    },
    {
      "epoch": 1.3173646680727127,
      "grad_norm": 0.1636449694633484,
      "learning_rate": 0.00011244979919678715,
      "loss": 0.3355,
      "step": 1640
    },
    {
      "epoch": 1.3253992166315154,
      "grad_norm": 0.16405583918094635,
      "learning_rate": 0.00011191432396251674,
      "loss": 0.3201,
      "step": 1650
    },
    {
      "epoch": 1.3334337651903183,
      "grad_norm": 0.1706804633140564,
      "learning_rate": 0.00011137884872824634,
      "loss": 0.3137,
      "step": 1660
    },
    {
      "epoch": 1.3414683137491212,
      "grad_norm": 0.16107286512851715,
      "learning_rate": 0.00011084337349397591,
      "loss": 0.3227,
      "step": 1670
    },
    {
      "epoch": 1.3495028623079242,
      "grad_norm": 0.14336737990379333,
      "learning_rate": 0.0001103078982597055,
      "loss": 0.3288,
      "step": 1680
    },
    {
      "epoch": 1.3575374108667269,
      "grad_norm": 0.19990164041519165,
      "learning_rate": 0.0001097724230254351,
      "loss": 0.3519,
      "step": 1690
    },
    {
      "epoch": 1.3655719594255298,
      "grad_norm": 0.14925788342952728,
      "learning_rate": 0.00010923694779116467,
      "loss": 0.3042,
      "step": 1700
    },
    {
      "epoch": 1.3736065079843327,
      "grad_norm": 0.15937820076942444,
      "learning_rate": 0.00010870147255689425,
      "loss": 0.3077,
      "step": 1710
    },
    {
      "epoch": 1.3816410565431354,
      "grad_norm": 0.17834344506263733,
      "learning_rate": 0.00010816599732262382,
      "loss": 0.3498,
      "step": 1720
    },
    {
      "epoch": 1.3896756051019383,
      "grad_norm": 0.19108012318611145,
      "learning_rate": 0.00010763052208835342,
      "loss": 0.395,
      "step": 1730
    },
    {
      "epoch": 1.3977101536607413,
      "grad_norm": 0.16483886539936066,
      "learning_rate": 0.00010709504685408301,
      "loss": 0.2952,
      "step": 1740
    },
    {
      "epoch": 1.4057447022195442,
      "grad_norm": 0.16408847272396088,
      "learning_rate": 0.00010655957161981258,
      "loss": 0.3537,
      "step": 1750
    },
    {
      "epoch": 1.4137792507783469,
      "grad_norm": 0.14878350496292114,
      "learning_rate": 0.00010602409638554218,
      "loss": 0.3389,
      "step": 1760
    },
    {
      "epoch": 1.4218137993371498,
      "grad_norm": 0.17166608572006226,
      "learning_rate": 0.00010548862115127177,
      "loss": 0.3656,
      "step": 1770
    },
    {
      "epoch": 1.4298483478959527,
      "grad_norm": 0.2218882441520691,
      "learning_rate": 0.00010495314591700134,
      "loss": 0.3288,
      "step": 1780
    },
    {
      "epoch": 1.4378828964547554,
      "grad_norm": 0.1747017502784729,
      "learning_rate": 0.00010441767068273094,
      "loss": 0.3708,
      "step": 1790
    },
    {
      "epoch": 1.4459174450135583,
      "grad_norm": 0.1780448704957962,
      "learning_rate": 0.00010388219544846052,
      "loss": 0.3326,
      "step": 1800
    },
    {
      "epoch": 1.4539519935723613,
      "grad_norm": 0.19661261141300201,
      "learning_rate": 0.0001033467202141901,
      "loss": 0.3329,
      "step": 1810
    },
    {
      "epoch": 1.461986542131164,
      "grad_norm": 0.1957409530878067,
      "learning_rate": 0.00010281124497991968,
      "loss": 0.3162,
      "step": 1820
    },
    {
      "epoch": 1.470021090689967,
      "grad_norm": 0.15493151545524597,
      "learning_rate": 0.00010227576974564928,
      "loss": 0.3323,
      "step": 1830
    },
    {
      "epoch": 1.4780556392487698,
      "grad_norm": 0.13516178727149963,
      "learning_rate": 0.00010174029451137885,
      "loss": 0.2726,
      "step": 1840
    },
    {
      "epoch": 1.4860901878075725,
      "grad_norm": 0.16861329972743988,
      "learning_rate": 0.00010120481927710844,
      "loss": 0.3422,
      "step": 1850
    },
    {
      "epoch": 1.4941247363663754,
      "grad_norm": 0.19754251837730408,
      "learning_rate": 0.00010066934404283804,
      "loss": 0.3355,
      "step": 1860
    },
    {
      "epoch": 1.5021592849251784,
      "grad_norm": 0.1706671416759491,
      "learning_rate": 0.00010013386880856761,
      "loss": 0.3647,
      "step": 1870
    },
    {
      "epoch": 1.510193833483981,
      "grad_norm": 0.17678290605545044,
      "learning_rate": 9.95983935742972e-05,
      "loss": 0.3139,
      "step": 1880
    },
    {
      "epoch": 1.518228382042784,
      "grad_norm": 0.16498659551143646,
      "learning_rate": 9.906291834002678e-05,
      "loss": 0.3653,
      "step": 1890
    },
    {
      "epoch": 1.526262930601587,
      "grad_norm": 0.17449072003364563,
      "learning_rate": 9.852744310575637e-05,
      "loss": 0.3661,
      "step": 1900
    },
    {
      "epoch": 1.5342974791603896,
      "grad_norm": 0.1523478925228119,
      "learning_rate": 9.799196787148595e-05,
      "loss": 0.3297,
      "step": 1910
    },
    {
      "epoch": 1.5423320277191925,
      "grad_norm": 0.18997275829315186,
      "learning_rate": 9.745649263721554e-05,
      "loss": 0.3683,
      "step": 1920
    },
    {
      "epoch": 1.5503665762779955,
      "grad_norm": 0.20248588919639587,
      "learning_rate": 9.692101740294511e-05,
      "loss": 0.3456,
      "step": 1930
    },
    {
      "epoch": 1.5584011248367982,
      "grad_norm": 0.20365449786186218,
      "learning_rate": 9.638554216867471e-05,
      "loss": 0.3166,
      "step": 1940
    },
    {
      "epoch": 1.566435673395601,
      "grad_norm": 0.15396857261657715,
      "learning_rate": 9.58500669344043e-05,
      "loss": 0.319,
      "step": 1950
    },
    {
      "epoch": 1.574470221954404,
      "grad_norm": 0.1500796675682068,
      "learning_rate": 9.531459170013387e-05,
      "loss": 0.3468,
      "step": 1960
    },
    {
      "epoch": 1.5825047705132067,
      "grad_norm": 0.15949440002441406,
      "learning_rate": 9.477911646586346e-05,
      "loss": 0.3745,
      "step": 1970
    },
    {
      "epoch": 1.5905393190720096,
      "grad_norm": 0.154740110039711,
      "learning_rate": 9.424364123159304e-05,
      "loss": 0.3271,
      "step": 1980
    },
    {
      "epoch": 1.5985738676308126,
      "grad_norm": 0.16771291196346283,
      "learning_rate": 9.370816599732262e-05,
      "loss": 0.3719,
      "step": 1990
    },
    {
      "epoch": 1.6066084161896153,
      "grad_norm": 0.1865275353193283,
      "learning_rate": 9.317269076305222e-05,
      "loss": 0.3456,
      "step": 2000
    },
    {
      "epoch": 1.6146429647484182,
      "grad_norm": 0.15655753016471863,
      "learning_rate": 9.26372155287818e-05,
      "loss": 0.3712,
      "step": 2010
    },
    {
      "epoch": 1.622677513307221,
      "grad_norm": 0.1686265915632248,
      "learning_rate": 9.210174029451138e-05,
      "loss": 0.3268,
      "step": 2020
    },
    {
      "epoch": 1.6307120618660238,
      "grad_norm": 0.22577300667762756,
      "learning_rate": 9.156626506024096e-05,
      "loss": 0.3575,
      "step": 2030
    },
    {
      "epoch": 1.6387466104248267,
      "grad_norm": 0.14020811021327972,
      "learning_rate": 9.103078982597055e-05,
      "loss": 0.3102,
      "step": 2040
    },
    {
      "epoch": 1.6467811589836296,
      "grad_norm": 0.22589918971061707,
      "learning_rate": 9.049531459170014e-05,
      "loss": 0.3384,
      "step": 2050
    },
    {
      "epoch": 1.6548157075424323,
      "grad_norm": 0.18966691195964813,
      "learning_rate": 8.995983935742972e-05,
      "loss": 0.3462,
      "step": 2060
    },
    {
      "epoch": 1.6628502561012353,
      "grad_norm": 0.15841029584407806,
      "learning_rate": 8.942436412315931e-05,
      "loss": 0.3316,
      "step": 2070
    },
    {
      "epoch": 1.6708848046600382,
      "grad_norm": 0.15385453402996063,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.3172,
      "step": 2080
    },
    {
      "epoch": 1.678919353218841,
      "grad_norm": 0.14544592797756195,
      "learning_rate": 8.835341365461848e-05,
      "loss": 0.3276,
      "step": 2090
    },
    {
      "epoch": 1.6869539017776438,
      "grad_norm": 0.20856612920761108,
      "learning_rate": 8.781793842034806e-05,
      "loss": 0.2926,
      "step": 2100
    },
    {
      "epoch": 1.6949884503364467,
      "grad_norm": 0.1715317815542221,
      "learning_rate": 8.728246318607765e-05,
      "loss": 0.3469,
      "step": 2110
    },
    {
      "epoch": 1.7030229988952494,
      "grad_norm": 0.16499429941177368,
      "learning_rate": 8.674698795180724e-05,
      "loss": 0.292,
      "step": 2120
    },
    {
      "epoch": 1.7110575474540526,
      "grad_norm": 0.2532300353050232,
      "learning_rate": 8.621151271753681e-05,
      "loss": 0.3736,
      "step": 2130
    },
    {
      "epoch": 1.7190920960128553,
      "grad_norm": 0.1251787692308426,
      "learning_rate": 8.567603748326641e-05,
      "loss": 0.2852,
      "step": 2140
    },
    {
      "epoch": 1.727126644571658,
      "grad_norm": 0.18928152322769165,
      "learning_rate": 8.514056224899599e-05,
      "loss": 0.3231,
      "step": 2150
    },
    {
      "epoch": 1.7351611931304611,
      "grad_norm": 0.14734186232089996,
      "learning_rate": 8.460508701472556e-05,
      "loss": 0.363,
      "step": 2160
    },
    {
      "epoch": 1.7431957416892638,
      "grad_norm": 0.15701110661029816,
      "learning_rate": 8.406961178045516e-05,
      "loss": 0.3122,
      "step": 2170
    },
    {
      "epoch": 1.7512302902480665,
      "grad_norm": 0.18573546409606934,
      "learning_rate": 8.353413654618474e-05,
      "loss": 0.307,
      "step": 2180
    },
    {
      "epoch": 1.7592648388068697,
      "grad_norm": 0.20189446210861206,
      "learning_rate": 8.299866131191432e-05,
      "loss": 0.4122,
      "step": 2190
    },
    {
      "epoch": 1.7672993873656724,
      "grad_norm": 0.22428077459335327,
      "learning_rate": 8.246318607764392e-05,
      "loss": 0.3294,
      "step": 2200
    },
    {
      "epoch": 1.775333935924475,
      "grad_norm": 0.17604409158229828,
      "learning_rate": 8.192771084337349e-05,
      "loss": 0.3641,
      "step": 2210
    },
    {
      "epoch": 1.7833684844832782,
      "grad_norm": 0.16948018968105316,
      "learning_rate": 8.139223560910308e-05,
      "loss": 0.3272,
      "step": 2220
    },
    {
      "epoch": 1.791403033042081,
      "grad_norm": 0.21291087567806244,
      "learning_rate": 8.085676037483266e-05,
      "loss": 0.3433,
      "step": 2230
    },
    {
      "epoch": 1.7994375816008839,
      "grad_norm": 0.14422519505023956,
      "learning_rate": 8.032128514056225e-05,
      "loss": 0.3001,
      "step": 2240
    },
    {
      "epoch": 1.8074721301596868,
      "grad_norm": 0.12600508332252502,
      "learning_rate": 7.978580990629184e-05,
      "loss": 0.2859,
      "step": 2250
    },
    {
      "epoch": 1.8155066787184895,
      "grad_norm": 0.15116073191165924,
      "learning_rate": 7.925033467202142e-05,
      "loss": 0.3402,
      "step": 2260
    },
    {
      "epoch": 1.8235412272772924,
      "grad_norm": 0.19475248456001282,
      "learning_rate": 7.8714859437751e-05,
      "loss": 0.3083,
      "step": 2270
    },
    {
      "epoch": 1.8315757758360953,
      "grad_norm": 0.1495218127965927,
      "learning_rate": 7.817938420348059e-05,
      "loss": 0.3039,
      "step": 2280
    },
    {
      "epoch": 1.839610324394898,
      "grad_norm": 0.16861306130886078,
      "learning_rate": 7.764390896921018e-05,
      "loss": 0.3649,
      "step": 2290
    },
    {
      "epoch": 1.847644872953701,
      "grad_norm": 0.21987183392047882,
      "learning_rate": 7.710843373493976e-05,
      "loss": 0.387,
      "step": 2300
    },
    {
      "epoch": 1.8556794215125039,
      "grad_norm": 0.22238938510417938,
      "learning_rate": 7.657295850066935e-05,
      "loss": 0.3719,
      "step": 2310
    },
    {
      "epoch": 1.8637139700713066,
      "grad_norm": 0.15708258748054504,
      "learning_rate": 7.603748326639893e-05,
      "loss": 0.3309,
      "step": 2320
    },
    {
      "epoch": 1.8717485186301095,
      "grad_norm": 0.16936315596103668,
      "learning_rate": 7.550200803212851e-05,
      "loss": 0.3547,
      "step": 2330
    },
    {
      "epoch": 1.8797830671889124,
      "grad_norm": 0.15975479781627655,
      "learning_rate": 7.49665327978581e-05,
      "loss": 0.3383,
      "step": 2340
    },
    {
      "epoch": 1.8878176157477151,
      "grad_norm": 0.1639396846294403,
      "learning_rate": 7.443105756358769e-05,
      "loss": 0.3491,
      "step": 2350
    },
    {
      "epoch": 1.895852164306518,
      "grad_norm": 0.22418995201587677,
      "learning_rate": 7.389558232931726e-05,
      "loss": 0.3093,
      "step": 2360
    },
    {
      "epoch": 1.903886712865321,
      "grad_norm": 0.21015426516532898,
      "learning_rate": 7.336010709504686e-05,
      "loss": 0.3503,
      "step": 2370
    },
    {
      "epoch": 1.9119212614241237,
      "grad_norm": 0.20779730379581451,
      "learning_rate": 7.282463186077644e-05,
      "loss": 0.3749,
      "step": 2380
    },
    {
      "epoch": 1.9199558099829266,
      "grad_norm": 0.1784157156944275,
      "learning_rate": 7.228915662650602e-05,
      "loss": 0.2793,
      "step": 2390
    },
    {
      "epoch": 1.9279903585417295,
      "grad_norm": 0.16708694398403168,
      "learning_rate": 7.175368139223562e-05,
      "loss": 0.328,
      "step": 2400
    },
    {
      "epoch": 1.9360249071005322,
      "grad_norm": 0.14262846112251282,
      "learning_rate": 7.121820615796519e-05,
      "loss": 0.3105,
      "step": 2410
    },
    {
      "epoch": 1.9440594556593351,
      "grad_norm": 0.20004786550998688,
      "learning_rate": 7.068273092369478e-05,
      "loss": 0.3139,
      "step": 2420
    },
    {
      "epoch": 1.952094004218138,
      "grad_norm": 0.1803560107946396,
      "learning_rate": 7.014725568942436e-05,
      "loss": 0.3337,
      "step": 2430
    },
    {
      "epoch": 1.9601285527769408,
      "grad_norm": 0.22359366714954376,
      "learning_rate": 6.961178045515395e-05,
      "loss": 0.3683,
      "step": 2440
    },
    {
      "epoch": 1.9681631013357437,
      "grad_norm": 0.1992710381746292,
      "learning_rate": 6.907630522088355e-05,
      "loss": 0.2918,
      "step": 2450
    },
    {
      "epoch": 1.9761976498945466,
      "grad_norm": 0.1988743096590042,
      "learning_rate": 6.854082998661312e-05,
      "loss": 0.3662,
      "step": 2460
    },
    {
      "epoch": 1.9842321984533493,
      "grad_norm": 0.14978069067001343,
      "learning_rate": 6.80053547523427e-05,
      "loss": 0.2675,
      "step": 2470
    },
    {
      "epoch": 1.9922667470121522,
      "grad_norm": 0.20524154603481293,
      "learning_rate": 6.746987951807229e-05,
      "loss": 0.3181,
      "step": 2480
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2979680895805359,
      "learning_rate": 6.693440428380188e-05,
      "loss": 0.3473,
      "step": 2490
    },
    {
      "epoch": 2.0080345485588027,
      "grad_norm": 0.19653214514255524,
      "learning_rate": 6.639892904953146e-05,
      "loss": 0.3142,
      "step": 2500
    },
    {
      "epoch": 2.016069097117606,
      "grad_norm": 0.16944485902786255,
      "learning_rate": 6.586345381526105e-05,
      "loss": 0.2963,
      "step": 2510
    },
    {
      "epoch": 2.0241036456764085,
      "grad_norm": 0.16116508841514587,
      "learning_rate": 6.532797858099063e-05,
      "loss": 0.312,
      "step": 2520
    },
    {
      "epoch": 2.0321381942352112,
      "grad_norm": 0.1517249345779419,
      "learning_rate": 6.47925033467202e-05,
      "loss": 0.3432,
      "step": 2530
    },
    {
      "epoch": 2.0401727427940144,
      "grad_norm": 0.1536283940076828,
      "learning_rate": 6.42570281124498e-05,
      "loss": 0.3134,
      "step": 2540
    },
    {
      "epoch": 2.048207291352817,
      "grad_norm": 0.22375422716140747,
      "learning_rate": 6.372155287817939e-05,
      "loss": 0.2531,
      "step": 2550
    },
    {
      "epoch": 2.05624183991162,
      "grad_norm": 0.15607690811157227,
      "learning_rate": 6.318607764390896e-05,
      "loss": 0.2554,
      "step": 2560
    },
    {
      "epoch": 2.064276388470423,
      "grad_norm": 0.2699090242385864,
      "learning_rate": 6.265060240963856e-05,
      "loss": 0.3165,
      "step": 2570
    },
    {
      "epoch": 2.0723109370292256,
      "grad_norm": 0.21125420928001404,
      "learning_rate": 6.211512717536813e-05,
      "loss": 0.2932,
      "step": 2580
    },
    {
      "epoch": 2.0803454855880283,
      "grad_norm": 0.16638220846652985,
      "learning_rate": 6.157965194109773e-05,
      "loss": 0.2725,
      "step": 2590
    },
    {
      "epoch": 2.0883800341468315,
      "grad_norm": 0.20393967628479004,
      "learning_rate": 6.104417670682732e-05,
      "loss": 0.3036,
      "step": 2600
    },
    {
      "epoch": 2.096414582705634,
      "grad_norm": 0.21900978684425354,
      "learning_rate": 6.05087014725569e-05,
      "loss": 0.2777,
      "step": 2610
    },
    {
      "epoch": 2.104449131264437,
      "grad_norm": 0.2357661873102188,
      "learning_rate": 5.9973226238286484e-05,
      "loss": 0.2954,
      "step": 2620
    },
    {
      "epoch": 2.11248367982324,
      "grad_norm": 0.13561956584453583,
      "learning_rate": 5.943775100401606e-05,
      "loss": 0.3015,
      "step": 2630
    },
    {
      "epoch": 2.1205182283820427,
      "grad_norm": 0.209832563996315,
      "learning_rate": 5.8902275769745655e-05,
      "loss": 0.2899,
      "step": 2640
    },
    {
      "epoch": 2.1285527769408454,
      "grad_norm": 0.2223498821258545,
      "learning_rate": 5.836680053547524e-05,
      "loss": 0.3103,
      "step": 2650
    },
    {
      "epoch": 2.1365873254996486,
      "grad_norm": 0.23661530017852783,
      "learning_rate": 5.783132530120482e-05,
      "loss": 0.2767,
      "step": 2660
    },
    {
      "epoch": 2.1446218740584513,
      "grad_norm": 0.22786058485507965,
      "learning_rate": 5.729585006693441e-05,
      "loss": 0.3272,
      "step": 2670
    },
    {
      "epoch": 2.1526564226172544,
      "grad_norm": 0.2629122734069824,
      "learning_rate": 5.676037483266399e-05,
      "loss": 0.3212,
      "step": 2680
    },
    {
      "epoch": 2.160690971176057,
      "grad_norm": 0.2130257487297058,
      "learning_rate": 5.6224899598393576e-05,
      "loss": 0.328,
      "step": 2690
    },
    {
      "epoch": 2.16872551973486,
      "grad_norm": 0.20512616634368896,
      "learning_rate": 5.568942436412317e-05,
      "loss": 0.2871,
      "step": 2700
    },
    {
      "epoch": 2.176760068293663,
      "grad_norm": 0.24860727787017822,
      "learning_rate": 5.515394912985275e-05,
      "loss": 0.3465,
      "step": 2710
    },
    {
      "epoch": 2.1847946168524657,
      "grad_norm": 0.23483942449092865,
      "learning_rate": 5.461847389558233e-05,
      "loss": 0.2902,
      "step": 2720
    },
    {
      "epoch": 2.1928291654112684,
      "grad_norm": 0.2377181351184845,
      "learning_rate": 5.408299866131191e-05,
      "loss": 0.2792,
      "step": 2730
    },
    {
      "epoch": 2.2008637139700715,
      "grad_norm": 0.22871257364749908,
      "learning_rate": 5.3547523427041504e-05,
      "loss": 0.3184,
      "step": 2740
    },
    {
      "epoch": 2.2088982625288742,
      "grad_norm": 0.16989563405513763,
      "learning_rate": 5.301204819277109e-05,
      "loss": 0.3162,
      "step": 2750
    },
    {
      "epoch": 2.216932811087677,
      "grad_norm": 0.20533102750778198,
      "learning_rate": 5.247657295850067e-05,
      "loss": 0.3223,
      "step": 2760
    },
    {
      "epoch": 2.22496735964648,
      "grad_norm": 0.2595980167388916,
      "learning_rate": 5.194109772423026e-05,
      "loss": 0.3151,
      "step": 2770
    },
    {
      "epoch": 2.2330019082052828,
      "grad_norm": 0.19777728617191315,
      "learning_rate": 5.140562248995984e-05,
      "loss": 0.2855,
      "step": 2780
    },
    {
      "epoch": 2.2410364567640855,
      "grad_norm": 0.23664748668670654,
      "learning_rate": 5.0870147255689426e-05,
      "loss": 0.3219,
      "step": 2790
    },
    {
      "epoch": 2.2490710053228886,
      "grad_norm": 0.19403477013111115,
      "learning_rate": 5.033467202141902e-05,
      "loss": 0.2596,
      "step": 2800
    },
    {
      "epoch": 2.2571055538816913,
      "grad_norm": 0.1791839748620987,
      "learning_rate": 4.97991967871486e-05,
      "loss": 0.3245,
      "step": 2810
    },
    {
      "epoch": 2.265140102440494,
      "grad_norm": 0.24568317830562592,
      "learning_rate": 4.926372155287818e-05,
      "loss": 0.3309,
      "step": 2820
    },
    {
      "epoch": 2.273174650999297,
      "grad_norm": 0.2599964737892151,
      "learning_rate": 4.872824631860777e-05,
      "loss": 0.2614,
      "step": 2830
    },
    {
      "epoch": 2.2812091995581,
      "grad_norm": 0.22256726026535034,
      "learning_rate": 4.8192771084337354e-05,
      "loss": 0.2811,
      "step": 2840
    },
    {
      "epoch": 2.2892437481169026,
      "grad_norm": 0.2722933292388916,
      "learning_rate": 4.765729585006693e-05,
      "loss": 0.3111,
      "step": 2850
    },
    {
      "epoch": 2.2972782966757057,
      "grad_norm": 0.22829985618591309,
      "learning_rate": 4.712182061579652e-05,
      "loss": 0.309,
      "step": 2860
    },
    {
      "epoch": 2.3053128452345084,
      "grad_norm": 0.24798612296581268,
      "learning_rate": 4.658634538152611e-05,
      "loss": 0.321,
      "step": 2870
    },
    {
      "epoch": 2.313347393793311,
      "grad_norm": 0.2368815392255783,
      "learning_rate": 4.605087014725569e-05,
      "loss": 0.3064,
      "step": 2880
    },
    {
      "epoch": 2.3213819423521143,
      "grad_norm": 0.20773886144161224,
      "learning_rate": 4.5515394912985275e-05,
      "loss": 0.2945,
      "step": 2890
    },
    {
      "epoch": 2.329416490910917,
      "grad_norm": 0.2897711992263794,
      "learning_rate": 4.497991967871486e-05,
      "loss": 0.3588,
      "step": 2900
    },
    {
      "epoch": 2.3374510394697197,
      "grad_norm": 0.2554023861885071,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.284,
      "step": 2910
    },
    {
      "epoch": 2.345485588028523,
      "grad_norm": 0.20999246835708618,
      "learning_rate": 4.390896921017403e-05,
      "loss": 0.3383,
      "step": 2920
    },
    {
      "epoch": 2.3535201365873255,
      "grad_norm": 0.3165619373321533,
      "learning_rate": 4.337349397590362e-05,
      "loss": 0.3252,
      "step": 2930
    },
    {
      "epoch": 2.361554685146128,
      "grad_norm": 0.24506384134292603,
      "learning_rate": 4.2838018741633203e-05,
      "loss": 0.2881,
      "step": 2940
    },
    {
      "epoch": 2.3695892337049314,
      "grad_norm": 0.360919326543808,
      "learning_rate": 4.230254350736278e-05,
      "loss": 0.346,
      "step": 2950
    },
    {
      "epoch": 2.377623782263734,
      "grad_norm": 0.20371021330356598,
      "learning_rate": 4.176706827309237e-05,
      "loss": 0.3222,
      "step": 2960
    },
    {
      "epoch": 2.3856583308225368,
      "grad_norm": 0.2676144540309906,
      "learning_rate": 4.123159303882196e-05,
      "loss": 0.3199,
      "step": 2970
    },
    {
      "epoch": 2.39369287938134,
      "grad_norm": 0.20437467098236084,
      "learning_rate": 4.069611780455154e-05,
      "loss": 0.3358,
      "step": 2980
    },
    {
      "epoch": 2.4017274279401426,
      "grad_norm": 0.25325554609298706,
      "learning_rate": 4.0160642570281125e-05,
      "loss": 0.2962,
      "step": 2990
    },
    {
      "epoch": 2.4097619764989453,
      "grad_norm": 0.2916693389415741,
      "learning_rate": 3.962516733601071e-05,
      "loss": 0.292,
      "step": 3000
    },
    {
      "epoch": 2.4177965250577484,
      "grad_norm": 0.3180852234363556,
      "learning_rate": 3.9089692101740296e-05,
      "loss": 0.345,
      "step": 3010
    },
    {
      "epoch": 2.425831073616551,
      "grad_norm": 0.24021005630493164,
      "learning_rate": 3.855421686746988e-05,
      "loss": 0.3255,
      "step": 3020
    },
    {
      "epoch": 2.433865622175354,
      "grad_norm": 0.21536561846733093,
      "learning_rate": 3.801874163319947e-05,
      "loss": 0.3283,
      "step": 3030
    },
    {
      "epoch": 2.441900170734157,
      "grad_norm": 0.2525143325328827,
      "learning_rate": 3.748326639892905e-05,
      "loss": 0.2797,
      "step": 3040
    },
    {
      "epoch": 2.4499347192929597,
      "grad_norm": 0.22892332077026367,
      "learning_rate": 3.694779116465863e-05,
      "loss": 0.316,
      "step": 3050
    },
    {
      "epoch": 2.4579692678517624,
      "grad_norm": 0.2997351586818695,
      "learning_rate": 3.641231593038822e-05,
      "loss": 0.3344,
      "step": 3060
    },
    {
      "epoch": 2.4660038164105655,
      "grad_norm": 0.2716788947582245,
      "learning_rate": 3.587684069611781e-05,
      "loss": 0.3365,
      "step": 3070
    },
    {
      "epoch": 2.4740383649693682,
      "grad_norm": 0.24807234108448029,
      "learning_rate": 3.534136546184739e-05,
      "loss": 0.3199,
      "step": 3080
    },
    {
      "epoch": 2.482072913528171,
      "grad_norm": 0.2391233891248703,
      "learning_rate": 3.4805890227576974e-05,
      "loss": 0.2995,
      "step": 3090
    },
    {
      "epoch": 2.490107462086974,
      "grad_norm": 0.24326196312904358,
      "learning_rate": 3.427041499330656e-05,
      "loss": 0.3222,
      "step": 3100
    },
    {
      "epoch": 2.498142010645777,
      "grad_norm": 0.2350481152534485,
      "learning_rate": 3.3734939759036146e-05,
      "loss": 0.2873,
      "step": 3110
    },
    {
      "epoch": 2.5061765592045795,
      "grad_norm": 0.22316904366016388,
      "learning_rate": 3.319946452476573e-05,
      "loss": 0.3174,
      "step": 3120
    },
    {
      "epoch": 2.5142111077633826,
      "grad_norm": 0.23325002193450928,
      "learning_rate": 3.266398929049532e-05,
      "loss": 0.2779,
      "step": 3130
    },
    {
      "epoch": 2.5222456563221853,
      "grad_norm": 0.2876635789871216,
      "learning_rate": 3.21285140562249e-05,
      "loss": 0.3275,
      "step": 3140
    },
    {
      "epoch": 2.530280204880988,
      "grad_norm": 0.22796232998371124,
      "learning_rate": 3.159303882195448e-05,
      "loss": 0.3186,
      "step": 3150
    },
    {
      "epoch": 2.538314753439791,
      "grad_norm": 0.2703447937965393,
      "learning_rate": 3.105756358768407e-05,
      "loss": 0.3121,
      "step": 3160
    },
    {
      "epoch": 2.546349301998594,
      "grad_norm": 0.27798765897750854,
      "learning_rate": 3.052208835341366e-05,
      "loss": 0.3278,
      "step": 3170
    },
    {
      "epoch": 2.5543838505573966,
      "grad_norm": 0.3072774410247803,
      "learning_rate": 2.9986613119143242e-05,
      "loss": 0.2941,
      "step": 3180
    },
    {
      "epoch": 2.5624183991161997,
      "grad_norm": 0.22397419810295105,
      "learning_rate": 2.9451137884872827e-05,
      "loss": 0.3608,
      "step": 3190
    },
    {
      "epoch": 2.5704529476750024,
      "grad_norm": 0.22885258495807648,
      "learning_rate": 2.891566265060241e-05,
      "loss": 0.315,
      "step": 3200
    },
    {
      "epoch": 2.578487496233805,
      "grad_norm": 0.1767316609621048,
      "learning_rate": 2.8380187416331995e-05,
      "loss": 0.2874,
      "step": 3210
    },
    {
      "epoch": 2.5865220447926083,
      "grad_norm": 0.1784009039402008,
      "learning_rate": 2.7844712182061584e-05,
      "loss": 0.2897,
      "step": 3220
    },
    {
      "epoch": 2.594556593351411,
      "grad_norm": 0.20947515964508057,
      "learning_rate": 2.7309236947791167e-05,
      "loss": 0.2706,
      "step": 3230
    },
    {
      "epoch": 2.6025911419102137,
      "grad_norm": 0.22763928771018982,
      "learning_rate": 2.6773761713520752e-05,
      "loss": 0.3,
      "step": 3240
    },
    {
      "epoch": 2.610625690469017,
      "grad_norm": 0.23172025382518768,
      "learning_rate": 2.6238286479250334e-05,
      "loss": 0.2748,
      "step": 3250
    },
    {
      "epoch": 2.6186602390278195,
      "grad_norm": 0.2189406305551529,
      "learning_rate": 2.570281124497992e-05,
      "loss": 0.3078,
      "step": 3260
    },
    {
      "epoch": 2.6266947875866222,
      "grad_norm": 0.21620512008666992,
      "learning_rate": 2.516733601070951e-05,
      "loss": 0.3268,
      "step": 3270
    },
    {
      "epoch": 2.6347293361454254,
      "grad_norm": 0.2797532379627228,
      "learning_rate": 2.463186077643909e-05,
      "loss": 0.2936,
      "step": 3280
    },
    {
      "epoch": 2.642763884704228,
      "grad_norm": 0.18055541813373566,
      "learning_rate": 2.4096385542168677e-05,
      "loss": 0.3271,
      "step": 3290
    },
    {
      "epoch": 2.6507984332630308,
      "grad_norm": 0.22621893882751465,
      "learning_rate": 2.356091030789826e-05,
      "loss": 0.2906,
      "step": 3300
    },
    {
      "epoch": 2.658832981821834,
      "grad_norm": 0.23904725909233093,
      "learning_rate": 2.3025435073627845e-05,
      "loss": 0.308,
      "step": 3310
    },
    {
      "epoch": 2.6668675303806366,
      "grad_norm": 0.25926050543785095,
      "learning_rate": 2.248995983935743e-05,
      "loss": 0.2932,
      "step": 3320
    },
    {
      "epoch": 2.6749020789394393,
      "grad_norm": 0.21371226012706757,
      "learning_rate": 2.1954484605087016e-05,
      "loss": 0.3125,
      "step": 3330
    },
    {
      "epoch": 2.6829366274982425,
      "grad_norm": 0.23095668852329254,
      "learning_rate": 2.1419009370816602e-05,
      "loss": 0.3091,
      "step": 3340
    },
    {
      "epoch": 2.690971176057045,
      "grad_norm": 0.2033836990594864,
      "learning_rate": 2.0883534136546184e-05,
      "loss": 0.3072,
      "step": 3350
    },
    {
      "epoch": 2.6990057246158483,
      "grad_norm": 0.2166193574666977,
      "learning_rate": 2.034805890227577e-05,
      "loss": 0.3275,
      "step": 3360
    },
    {
      "epoch": 2.707040273174651,
      "grad_norm": 0.2593621015548706,
      "learning_rate": 1.9812583668005355e-05,
      "loss": 0.3239,
      "step": 3370
    },
    {
      "epoch": 2.7150748217334537,
      "grad_norm": 0.2744395434856415,
      "learning_rate": 1.927710843373494e-05,
      "loss": 0.336,
      "step": 3380
    },
    {
      "epoch": 2.723109370292257,
      "grad_norm": 0.22963561117649078,
      "learning_rate": 1.8741633199464527e-05,
      "loss": 0.327,
      "step": 3390
    },
    {
      "epoch": 2.7311439188510596,
      "grad_norm": 0.22546277940273285,
      "learning_rate": 1.820615796519411e-05,
      "loss": 0.284,
      "step": 3400
    },
    {
      "epoch": 2.7391784674098623,
      "grad_norm": 0.18957477807998657,
      "learning_rate": 1.7670682730923694e-05,
      "loss": 0.2726,
      "step": 3410
    },
    {
      "epoch": 2.7472130159686654,
      "grad_norm": 0.2616503834724426,
      "learning_rate": 1.713520749665328e-05,
      "loss": 0.297,
      "step": 3420
    },
    {
      "epoch": 2.755247564527468,
      "grad_norm": 0.24732011556625366,
      "learning_rate": 1.6599732262382866e-05,
      "loss": 0.3391,
      "step": 3430
    },
    {
      "epoch": 2.763282113086271,
      "grad_norm": 0.21806997060775757,
      "learning_rate": 1.606425702811245e-05,
      "loss": 0.3087,
      "step": 3440
    },
    {
      "epoch": 2.771316661645074,
      "grad_norm": 0.21304437518119812,
      "learning_rate": 1.5528781793842034e-05,
      "loss": 0.2787,
      "step": 3450
    },
    {
      "epoch": 2.7793512102038767,
      "grad_norm": 0.22365103662014008,
      "learning_rate": 1.4993306559571621e-05,
      "loss": 0.2997,
      "step": 3460
    },
    {
      "epoch": 2.78738575876268,
      "grad_norm": 0.2389494925737381,
      "learning_rate": 1.4457831325301205e-05,
      "loss": 0.2829,
      "step": 3470
    },
    {
      "epoch": 2.7954203073214825,
      "grad_norm": 0.2511368989944458,
      "learning_rate": 1.3922356091030792e-05,
      "loss": 0.3128,
      "step": 3480
    },
    {
      "epoch": 2.803454855880285,
      "grad_norm": 0.21979305148124695,
      "learning_rate": 1.3386880856760376e-05,
      "loss": 0.308,
      "step": 3490
    },
    {
      "epoch": 2.8114894044390883,
      "grad_norm": 0.25236237049102783,
      "learning_rate": 1.285140562248996e-05,
      "loss": 0.2984,
      "step": 3500
    },
    {
      "epoch": 2.819523952997891,
      "grad_norm": 0.2723413407802582,
      "learning_rate": 1.2315930388219546e-05,
      "loss": 0.3037,
      "step": 3510
    },
    {
      "epoch": 2.8275585015566937,
      "grad_norm": 0.1931089609861374,
      "learning_rate": 1.178045515394913e-05,
      "loss": 0.2927,
      "step": 3520
    },
    {
      "epoch": 2.835593050115497,
      "grad_norm": 0.20841926336288452,
      "learning_rate": 1.1244979919678715e-05,
      "loss": 0.2736,
      "step": 3530
    },
    {
      "epoch": 2.8436275986742996,
      "grad_norm": 0.24680566787719727,
      "learning_rate": 1.0709504685408301e-05,
      "loss": 0.3313,
      "step": 3540
    },
    {
      "epoch": 2.8516621472331023,
      "grad_norm": 0.1865740269422531,
      "learning_rate": 1.0174029451137885e-05,
      "loss": 0.3462,
      "step": 3550
    },
    {
      "epoch": 2.8596966957919054,
      "grad_norm": 0.18531134724617004,
      "learning_rate": 9.63855421686747e-06,
      "loss": 0.2803,
      "step": 3560
    },
    {
      "epoch": 2.867731244350708,
      "grad_norm": 0.3198171854019165,
      "learning_rate": 9.103078982597054e-06,
      "loss": 0.3572,
      "step": 3570
    },
    {
      "epoch": 2.875765792909511,
      "grad_norm": 0.2470603585243225,
      "learning_rate": 8.56760374832664e-06,
      "loss": 0.3048,
      "step": 3580
    },
    {
      "epoch": 2.883800341468314,
      "grad_norm": 0.2623049020767212,
      "learning_rate": 8.032128514056226e-06,
      "loss": 0.3203,
      "step": 3590
    },
    {
      "epoch": 2.8918348900271167,
      "grad_norm": 0.1973196566104889,
      "learning_rate": 7.4966532797858104e-06,
      "loss": 0.3584,
      "step": 3600
    },
    {
      "epoch": 2.8998694385859194,
      "grad_norm": 0.24329166114330292,
      "learning_rate": 6.961178045515396e-06,
      "loss": 0.3226,
      "step": 3610
    },
    {
      "epoch": 2.9079039871447225,
      "grad_norm": 0.19864438474178314,
      "learning_rate": 6.42570281124498e-06,
      "loss": 0.3448,
      "step": 3620
    },
    {
      "epoch": 2.9159385357035252,
      "grad_norm": 0.19697822630405426,
      "learning_rate": 5.890227576974565e-06,
      "loss": 0.3148,
      "step": 3630
    },
    {
      "epoch": 2.923973084262328,
      "grad_norm": 0.2631549537181854,
      "learning_rate": 5.3547523427041504e-06,
      "loss": 0.3228,
      "step": 3640
    },
    {
      "epoch": 2.932007632821131,
      "grad_norm": 0.23131050169467926,
      "learning_rate": 4.819277108433735e-06,
      "loss": 0.3172,
      "step": 3650
    },
    {
      "epoch": 2.940042181379934,
      "grad_norm": 0.20550468564033508,
      "learning_rate": 4.28380187416332e-06,
      "loss": 0.3191,
      "step": 3660
    },
    {
      "epoch": 2.9480767299387365,
      "grad_norm": 0.28283026814460754,
      "learning_rate": 3.7483266398929052e-06,
      "loss": 0.3547,
      "step": 3670
    },
    {
      "epoch": 2.9561112784975396,
      "grad_norm": 0.2150290161371231,
      "learning_rate": 3.21285140562249e-06,
      "loss": 0.3402,
      "step": 3680
    },
    {
      "epoch": 2.9641458270563423,
      "grad_norm": 0.24430443346500397,
      "learning_rate": 2.6773761713520752e-06,
      "loss": 0.2803,
      "step": 3690
    },
    {
      "epoch": 2.972180375615145,
      "grad_norm": 0.247059628367424,
      "learning_rate": 2.14190093708166e-06,
      "loss": 0.3124,
      "step": 3700
    },
    {
      "epoch": 2.980214924173948,
      "grad_norm": 0.3294084668159485,
      "learning_rate": 1.606425702811245e-06,
      "loss": 0.3179,
      "step": 3710
    },
    {
      "epoch": 2.988249472732751,
      "grad_norm": 0.2828091084957123,
      "learning_rate": 1.07095046854083e-06,
      "loss": 0.3062,
      "step": 3720
    },
    {
      "epoch": 2.9962840212915536,
      "grad_norm": 0.27093639969825745,
      "learning_rate": 5.35475234270415e-07,
      "loss": 0.3043,
      "step": 3730
    }
  ],
  "logging_steps": 10,
  "max_steps": 3735,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.595006596083876e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

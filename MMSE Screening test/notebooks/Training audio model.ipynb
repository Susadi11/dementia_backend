{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f8d70f-556b-432c-928d-ecafa0c6b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_audio_features(path, sr_target=16000):\n",
    "    try:\n",
    "        y, sr = librosa.load(path, sr=sr_target, mono=True)\n",
    "\n",
    "        if len(y) < sr:  # < 1 second audio → useless\n",
    "            return None\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        tonnetz = librosa.feature.tonnetz(\n",
    "            y=librosa.effects.harmonic(y), sr=sr\n",
    "        )\n",
    "\n",
    "        feat = np.hstack([\n",
    "            mfcc.mean(axis=1),\n",
    "            mfcc.std(axis=1),\n",
    "            mfcc_delta.mean(axis=1),\n",
    "            mfcc_delta2.mean(axis=1),\n",
    "            chroma.mean(axis=1),\n",
    "            contrast.mean(axis=1),\n",
    "            tonnetz.mean(axis=1),\n",
    "        ])\n",
    "\n",
    "        return feat.astype(np.float32)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping corrupted file: {path}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8298ee-265b-4ea3-b610-75c2e1ce8b48",
   "metadata": {},
   "source": [
    "## Build feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80e0ff4-6dbe-448d-a438-efbb53a0060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../dataset/talkbank\\Control\\cookie\n",
      "Reading: ../dataset/talkbank\\Control\\fluency\n",
      "Reading: ../dataset/talkbank\\Control\\recall\n",
      "Reading: ../dataset/talkbank\\Control\\sentence\n",
      "Reading: ../dataset/talkbank\\Dementia\\cookie\n",
      "Reading: ../dataset/talkbank\\Dementia\\fluency\n",
      "Reading: ../dataset/talkbank\\Dementia\\recall\n",
      "Reading: ../dataset/talkbank\\Dementia\\sentence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1361, 1361)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_ROOT = \"../dataset/talkbank\"\n",
    "TASKS = [\"cookie\", \"fluency\", \"recall\", \"sentence\"]\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "\n",
    "for label in [\"Control\", \"Dementia\"]:\n",
    "    for task in TASKS:\n",
    "        folder = os.path.join(AUDIO_ROOT, label, task)\n",
    "        print(\"Reading:\", folder)\n",
    "\n",
    "        if not os.path.exists(folder):\n",
    "            continue\n",
    "\n",
    "        for f in os.listdir(folder):\n",
    "            if f.lower().endswith((\".wav\", \".mp3\")):\n",
    "                paths.append(os.path.join(folder, f))\n",
    "                labels.append(label)\n",
    "\n",
    "len(paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4982545-2d37-4ed7-815e-690ca0bcf39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio features:  36%|█████████████████████████████████████████████████████▋                                                                                                 | 484/1361 [18:19<45:57,  3.14s/it]C:\\Users\\SASI COMPUTERS\\AppData\\Local\\Temp\\ipykernel_16236\\3053969582.py:17: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=sr_target, mono=True)\n",
      "F:\\Projects\\github projects\\dimentia ai\\env\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Extracting audio features:  36%|█████████████████████████████████████████████████████▊                                                                                                 | 485/1361 [18:19<32:57,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping corrupted file: ../dataset/talkbank\\Control\\fluency\\332-0.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio features:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 1280/1361 [6:12:29<05:36,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping corrupted file: ../dataset/talkbank\\Dementia\\sentence\\269-1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1361/1361 [6:18:45<00:00, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Finished\n",
      "✔ Used files: 1359\n",
      "⚠️ Skipped corrupted files: 2\n",
      "(1359, 77) (1359,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "valid_labels = []\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "for p, label in tqdm(zip(paths, labels), total=len(paths), desc=\"Extracting audio features\"):\n",
    "    feat = extract_audio_features(p)\n",
    "\n",
    "    if feat is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    features.append(feat)\n",
    "    valid_labels.append(label)\n",
    "\n",
    "print(f\"\\n✅ Finished\")\n",
    "print(f\"✔ Used files: {len(features)}\")\n",
    "print(f\"⚠️ Skipped corrupted files: {skipped}\")\n",
    "\n",
    "\n",
    "X_audio = np.array(features)\n",
    "y_audio_text = np.array(valid_labels)\n",
    "\n",
    "print(X_audio.shape, y_audio_text.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5834fa-b6bd-4862-87dd-9c615e01268c",
   "metadata": {},
   "source": [
    "## Encode labels + scale + train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8210029-0fc3-4f96-aa77-27d9607b79bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

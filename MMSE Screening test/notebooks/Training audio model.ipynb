{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f8d70f-556b-432c-928d-ecafa0c6b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_audio_features(path, sr_target=16000):\n",
    "    try:\n",
    "        y, sr = librosa.load(path, sr=sr_target, mono=True)\n",
    "\n",
    "        if len(y) < sr:  # < 1 second audio ‚Üí useless\n",
    "            return None\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        tonnetz = librosa.feature.tonnetz(\n",
    "            y=librosa.effects.harmonic(y), sr=sr\n",
    "        )\n",
    "\n",
    "        feat = np.hstack([\n",
    "            mfcc.mean(axis=1),\n",
    "            mfcc.std(axis=1),\n",
    "            mfcc_delta.mean(axis=1),\n",
    "            mfcc_delta2.mean(axis=1),\n",
    "            chroma.mean(axis=1),\n",
    "            contrast.mean(axis=1),\n",
    "            tonnetz.mean(axis=1),\n",
    "        ])\n",
    "\n",
    "        return feat.astype(np.float32)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipping corrupted file: {path}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8298ee-265b-4ea3-b610-75c2e1ce8b48",
   "metadata": {},
   "source": [
    "## Build feature matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80e0ff4-6dbe-448d-a438-efbb53a0060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ../dataset/talkbank\\Control\\cookie\n",
      "Reading: ../dataset/talkbank\\Control\\fluency\n",
      "Reading: ../dataset/talkbank\\Control\\recall\n",
      "Reading: ../dataset/talkbank\\Control\\sentence\n",
      "Reading: ../dataset/talkbank\\Dementia\\cookie\n",
      "Reading: ../dataset/talkbank\\Dementia\\fluency\n",
      "Reading: ../dataset/talkbank\\Dementia\\recall\n",
      "Reading: ../dataset/talkbank\\Dementia\\sentence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1361, 1361)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_ROOT = \"../dataset/talkbank\"\n",
    "TASKS = [\"cookie\", \"fluency\", \"recall\", \"sentence\"]\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "\n",
    "for label in [\"Control\", \"Dementia\"]:\n",
    "    for task in TASKS:\n",
    "        folder = os.path.join(AUDIO_ROOT, label, task)\n",
    "        print(\"Reading:\", folder)\n",
    "\n",
    "        if not os.path.exists(folder):\n",
    "            continue\n",
    "\n",
    "        for f in os.listdir(folder):\n",
    "            if f.lower().endswith((\".wav\", \".mp3\")):\n",
    "                paths.append(os.path.join(folder, f))\n",
    "                labels.append(label)\n",
    "\n",
    "len(paths), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4982545-2d37-4ed7-815e-690ca0bcf39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio features:  36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                                                 | 484/1361 [18:19<45:57,  3.14s/it]C:\\Users\\SASI COMPUTERS\\AppData\\Local\\Temp\\ipykernel_16236\\3053969582.py:17: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=sr_target, mono=True)\n",
      "F:\\Projects\\github projects\\dimentia ai\\env\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Extracting audio features:  36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                                                 | 485/1361 [18:19<32:57,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping corrupted file: ../dataset/talkbank\\Control\\fluency\\332-0.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio features:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 1280/1361 [6:12:29<05:36,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping corrupted file: ../dataset/talkbank\\Dementia\\sentence\\269-1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1361/1361 [6:18:45<00:00, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Finished\n",
      "‚úî Used files: 1359\n",
      "‚ö†Ô∏è Skipped corrupted files: 2\n",
      "(1359, 77) (1359,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "valid_labels = []\n",
    "\n",
    "skipped = 0\n",
    "\n",
    "for p, label in tqdm(zip(paths, labels), total=len(paths), desc=\"Extracting audio features\"):\n",
    "    feat = extract_audio_features(p)\n",
    "\n",
    "    if feat is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    features.append(feat)\n",
    "    valid_labels.append(label)\n",
    "\n",
    "print(f\"\\n Finished\")\n",
    "print(f\"Used files: {len(features)}\")\n",
    "print(f\" Skipped corrupted files: {skipped}\")\n",
    "\n",
    "\n",
    "X_audio = np.array(features)\n",
    "y_audio_text = np.array(valid_labels)\n",
    "\n",
    "print(X_audio.shape, y_audio_text.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5834fa-b6bd-4862-87dd-9c615e01268c",
   "metadata": {},
   "source": [
    "## Encode labels + scale + train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8210029-0fc3-4f96-aa77-27d9607b79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_audio_text)  # Control=0, Dementia=1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_audio)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43fac39-997b-4dc4-8f15-230064adf83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ecedf7-e718-428c-8fd2-3ccb3eda4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"SVM_RBF\": SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\"),\n",
    "    \n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\"\n",
    "    ),\n",
    "    \n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    \n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0869ce-7244-4e2b-849f-9b855c262d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training SVM_RBF...\n",
      "\n",
      "üìä Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.70      0.93      0.80        97\n",
      "    Dementia       0.95      0.78      0.86       175\n",
      "\n",
      "    accuracy                           0.83       272\n",
      "   macro avg       0.82      0.85      0.83       272\n",
      "weighted avg       0.86      0.83      0.83       272\n",
      "\n",
      "\n",
      "üöÄ Training LogisticRegression...\n",
      "\n",
      "üìä Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.61      0.73      0.66        97\n",
      "    Dementia       0.83      0.74      0.78       175\n",
      "\n",
      "    accuracy                           0.74       272\n",
      "   macro avg       0.72      0.73      0.72       272\n",
      "weighted avg       0.75      0.74      0.74       272\n",
      "\n",
      "\n",
      "üöÄ Training RandomForest...\n",
      "\n",
      "üìä Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.85      0.82      0.84        97\n",
      "    Dementia       0.90      0.92      0.91       175\n",
      "\n",
      "    accuracy                           0.89       272\n",
      "   macro avg       0.88      0.87      0.87       272\n",
      "weighted avg       0.89      0.89      0.89       272\n",
      "\n",
      "\n",
      "üöÄ Training XGBoost...\n",
      "\n",
      "üìä Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.82      0.87      0.84        97\n",
      "    Dementia       0.92      0.90      0.91       175\n",
      "\n",
      "    accuracy                           0.89       272\n",
      "   macro avg       0.87      0.88      0.88       272\n",
      "weighted avg       0.89      0.89      0.89       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1\": f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Training {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    train_metrics = compute_metrics(y_train, train_preds)\n",
    "    test_metrics = compute_metrics(y_test, test_preds)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \n",
    "        \"Train_Accuracy\": train_metrics[\"Accuracy\"],\n",
    "        \"Train_Precision\": train_metrics[\"Precision\"],\n",
    "        \"Train_Recall\": train_metrics[\"Recall\"],\n",
    "        \"Train_F1\": train_metrics[\"F1\"],\n",
    "        \n",
    "        \"Test_Accuracy\": test_metrics[\"Accuracy\"],\n",
    "        \"Test_Precision\": test_metrics[\"Precision\"],\n",
    "        \"Test_Recall\": test_metrics[\"Recall\"],\n",
    "        \"Test_F1\": test_metrics[\"F1\"]\n",
    "    })\n",
    "    \n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Optional: print detailed test report\n",
    "    print(\"\\n Test Classification Report:\")\n",
    "    print(classification_report(\n",
    "        y_test, test_preds,\n",
    "        target_names=le.classes_\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1bacb03-3eba-4fcb-ab66-45da12302e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Precision</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886029</td>\n",
       "      <td>0.904494</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.912181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886029</td>\n",
       "      <td>0.923529</td>\n",
       "      <td>0.897143</td>\n",
       "      <td>0.910145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>0.915363</td>\n",
       "      <td>0.988710</td>\n",
       "      <td>0.878223</td>\n",
       "      <td>0.930197</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.777143</td>\n",
       "      <td>0.855346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.801288</td>\n",
       "      <td>0.896382</td>\n",
       "      <td>0.780802</td>\n",
       "      <td>0.834609</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.781818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Train_Accuracy  Train_Precision  Train_Recall  \\\n",
       "2        RandomForest        1.000000         1.000000      1.000000   \n",
       "3             XGBoost        1.000000         1.000000      1.000000   \n",
       "0             SVM_RBF        0.915363         0.988710      0.878223   \n",
       "1  LogisticRegression        0.801288         0.896382      0.780802   \n",
       "\n",
       "   Train_F1  Test_Accuracy  Test_Precision  Test_Recall   Test_F1  \n",
       "2  1.000000       0.886029        0.904494     0.920000  0.912181  \n",
       "3  1.000000       0.886029        0.923529     0.897143  0.910145  \n",
       "0  0.930197       0.830882        0.951049     0.777143  0.855346  \n",
       "1  0.834609       0.735294        0.832258     0.737143  0.781818  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by Test F1\n",
    "results_df = results_df.sort_values(by=\"Test_F1\", ascending=False)\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c77b7-6a30-442c-9645-212770b145da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best model based on TEST F1: RandomForest\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_row = results_df.iloc[0]\n",
    "best_model_name = best_row[\"Model\"]\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(\"Best model based on TEST F1:\", best_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018f3381-3627-4394-b33c-2a4282058403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/audio_label_encoder.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, \"../models/best_audio_model.pkl\")\n",
    "joblib.dump(scaler, \"../models/audio_scaler.pkl\")\n",
    "joblib.dump(le, \"../models/audio_label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b40893a-dd28-424e-a935-05b8196a68f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_F1</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Overfitting_Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912181</td>\n",
       "      <td>0.087819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910145</td>\n",
       "      <td>0.089855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>0.930197</td>\n",
       "      <td>0.855346</td>\n",
       "      <td>0.074851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.834609</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.052791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Train_F1   Test_F1  Overfitting_Gap\n",
       "2        RandomForest  1.000000  0.912181         0.087819\n",
       "3             XGBoost  1.000000  0.910145         0.089855\n",
       "0             SVM_RBF  0.930197  0.855346         0.074851\n",
       "1  LogisticRegression  0.834609  0.781818         0.052791"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\"Overfitting_Gap\"] = results_df[\"Train_F1\"] - results_df[\"Test_F1\"]\n",
    "results_df[[\"Model\", \"Train_F1\", \"Test_F1\", \"Overfitting_Gap\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377eacf-a858-4961-900d-0b9633551479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e3bfa4-f829-4ad8-b84f-a5fbf3706c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8269956b-c25b-41eb-98c5-c51d99d960db",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_ROOT = \"../dataset/adress2020_raw/train\"\n",
    "CLEAN_ROOT = \"../dataset/adress2020\"\n",
    "\n",
    "AUDIO_RAW_CC = os.path.join(RAW_ROOT, \"Full_wave_enhanced_audio\", \"cc\")\n",
    "AUDIO_RAW_CD = os.path.join(RAW_ROOT, \"Full_wave_enhanced_audio\", \"cd\")\n",
    "\n",
    "TRANS_RAW_CC = os.path.join(RAW_ROOT, \"transcription\", \"cc\")\n",
    "TRANS_RAW_CD = os.path.join(RAW_ROOT, \"transcription\", \"cd\")\n",
    "\n",
    "AUDIO_CLEAN = os.path.join(CLEAN_ROOT, \"audio\")\n",
    "TRANS_CLEAN = os.path.join(CLEAN_ROOT, \"transcripts\")\n",
    "\n",
    "os.makedirs(AUDIO_CLEAN, exist_ok=True)\n",
    "os.makedirs(TRANS_CLEAN, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e32bb34-8fd0-4031-afea-f5ed8c6d6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio files copied: 108\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "for src_dir in [AUDIO_RAW_CC, AUDIO_RAW_CD]:\n",
    "    for f in os.listdir(src_dir):\n",
    "        if f.endswith(\".wav\"):\n",
    "            new_name = f.replace(\"_enhanced\", \"\")\n",
    "            shutil.copy(os.path.join(src_dir, f), os.path.join(AUDIO_CLEAN, new_name))\n",
    "\n",
    "print(\"Audio files copied:\", len(os.listdir(AUDIO_CLEAN)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17be1310-140e-428b-bab6-735871e22be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript files copied: 108\n"
     ]
    }
   ],
   "source": [
    "for src_dir in [TRANS_RAW_CC, TRANS_RAW_CD]:\n",
    "    for f in os.listdir(src_dir):\n",
    "        if f.endswith(\".cha\"):\n",
    "            shutil.copy(os.path.join(src_dir, f), os.path.join(TRANS_CLEAN, f))\n",
    "\n",
    "print(\"Transcript files copied:\", len(os.listdir(TRANS_CLEAN)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3119c7-a2fc-44c4-bbbc-8f4beebd3e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S001.wav</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S002.wav</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S003.wav</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S004.wav</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S005.wav</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename    label\n",
       "0  S001.wav  Control\n",
       "1  S002.wav  Control\n",
       "2  S003.wav  Control\n",
       "3  S004.wav  Control\n",
       "4  S005.wav  Control"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_meta = os.path.join(RAW_ROOT, \"cc_meta_data.txt\")\n",
    "cd_meta = os.path.join(RAW_ROOT, \"cd_meta_data.txt\")\n",
    "\n",
    "cc = pd.read_csv(cc_meta, sep=\";\", engine=\"python\",\n",
    "                 names=[\"id\", \"age\", \"gender\", \"mmse\"],\n",
    "                 skiprows=1)\n",
    "cc[\"id\"] = cc[\"id\"].str.strip()\n",
    "cc[\"label\"] = \"Control\"\n",
    "\n",
    "cd = pd.read_csv(cd_meta, sep=\";\", engine=\"python\",\n",
    "                 names=[\"id\", \"age\", \"gender\", \"mmse\"],\n",
    "                 skiprows=1)\n",
    "cd[\"id\"] = cd[\"id\"].str.strip()\n",
    "cd[\"label\"] = \"AD\"\n",
    "\n",
    "df = pd.concat([cc, cd], ignore_index=True)\n",
    "df[\"filename\"] = df[\"id\"] + \".wav\"\n",
    "\n",
    "labels = df[[\"filename\", \"label\"]]\n",
    "labels.to_csv(os.path.join(CLEAN_ROOT, \"labels.csv\"), index=False)\n",
    "\n",
    "labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895b12e0-0bb2-4431-87ce-ccf026b7683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patient_text(cha_path, speaker_tag=\"*PAR:\"):\n",
    "    text_lines = []\n",
    "    with open(cha_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(speaker_tag):\n",
    "                content = line.split(\"\\t\", 1)[-1]\n",
    "                text_lines.append(content)\n",
    "    return \" \".join(text_lines).lower()\n",
    "\n",
    "def extract_text_features(text):\n",
    "    words = text.split()\n",
    "    length = len(words)\n",
    "    avg_len = np.mean([len(w) for w in words]) if words else 0.0\n",
    "    unique_ratio = len(set(words)) / length if length else 0.0\n",
    "    return np.array([length, avg_len, unique_ratio])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb19f135-1510-44f3-a2a3-29bd76e72ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features(audio_path: str, sr_target: int = 16000) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rich acoustic feature set:\n",
    "    - MFCC (mean + std)\n",
    "    - Delta MFCC\n",
    "    - Delta-Delta MFCC\n",
    "    - Chroma\n",
    "    - Spectral contrast\n",
    "    - Tonnetz\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=sr_target)\n",
    "\n",
    "    # MFCCs and their deltas\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "    # Chroma, contrast, tonnetz\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
    "\n",
    "    # Take mean + std for stability\n",
    "    feat_vec = np.hstack([\n",
    "        mfcc.mean(axis=1),        # 13\n",
    "        mfcc.std(axis=1),         # 13\n",
    "        mfcc_delta.mean(axis=1),  # 13\n",
    "        mfcc_delta2.mean(axis=1), # 13\n",
    "        chroma.mean(axis=1),      # 12\n",
    "        contrast.mean(axis=1),    # 7\n",
    "        tonnetz.mean(axis=1),     # 6\n",
    "    ])\n",
    "\n",
    "    return feat_vec.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187fa3d2-0603-402d-8b84-07b27f5c50ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:00<00:00, 4883.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF reduced shape: (108, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(os.path.join(CLEAN_ROOT, \"labels.csv\"))\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1 — read all texts first\n",
    "all_texts = []\n",
    "\n",
    "for _, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
    "    fname = row[\"filename\"]\n",
    "    cha_path = os.path.join(TRANS_CLEAN, fname.replace(\".wav\", \".cha\"))\n",
    "\n",
    "    if os.path.exists(cha_path):\n",
    "        text = extract_patient_text(cha_path)\n",
    "    else:\n",
    "        text = \"\"\n",
    "\n",
    "    all_texts.append(text)\n",
    "\n",
    "# Step 2 — TF-IDF (300 features)\n",
    "vectorizer = TfidfVectorizer(max_features=300)\n",
    "tfidf_matrix = vectorizer.fit_transform(all_texts).toarray()\n",
    "\n",
    "# Step 3 — Reduce TF-IDF dimensions to 20\n",
    "pca = PCA(n_components=20)\n",
    "tfidf_reduced = pca.fit_transform(tfidf_matrix)\n",
    "\n",
    "print(\"TF-IDF reduced shape:\", tfidf_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485aaad-5bc9-45c7-bcff-825c44df1f03",
   "metadata": {},
   "source": [
    "## Build combined features (audio + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4326903f-99be-42e4-82cd-959a4763340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [04:35<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (108, 97) (108,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels_list = []\n",
    "\n",
    "for i, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
    "    fname = row[\"filename\"]\n",
    "    f_label = row[\"label\"]\n",
    "\n",
    "    audio_path = os.path.join(AUDIO_CLEAN, fname)\n",
    "    cha_path = os.path.join(TRANS_CLEAN, fname.replace(\".wav\", \".cha\"))\n",
    "\n",
    "    if not os.path.exists(audio_path) or not os.path.exists(cha_path):\n",
    "        continue\n",
    "\n",
    "    # Extract audio features\n",
    "    audio_feat = extract_audio_features(audio_path)\n",
    "\n",
    "    # NEW: Use TF-IDF reduced text features\n",
    "    text_feat = tfidf_reduced[i]\n",
    "\n",
    "    # Combine both\n",
    "    combined = np.hstack([audio_feat, text_feat])\n",
    "\n",
    "    features.append(combined)\n",
    "    labels_list.append(f_label)\n",
    "\n",
    "\n",
    "    # STEP 6 — Convert to numpy arrays\n",
    "# -------------------------------\n",
    "X = np.array(features)\n",
    "y_text = np.array(labels_list)\n",
    "\n",
    "print(\"Final shape:\", X.shape, y_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3922e9-84fc-4b6c-877c-697c8d507223",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fa64f7-3ba7-4c04-bce0-b8e98bc5772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034af146-b7dd-48a5-a7b3-e792155372b8",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d697dc-6bfa-4e91-94de-1bbf9adc3f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.64      0.82      0.72        11\n",
      "     Control       0.75      0.55      0.63        11\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.70      0.68      0.68        22\n",
      "weighted avg       0.70      0.68      0.68        22\n",
      "\n",
      "\n",
      "Training LogisticRegression...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.60      0.55      0.57        11\n",
      "     Control       0.58      0.64      0.61        11\n",
      "\n",
      "    accuracy                           0.59        22\n",
      "   macro avg       0.59      0.59      0.59        22\n",
      "weighted avg       0.59      0.59      0.59        22\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.71      0.91      0.80        11\n",
      "     Control       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.79      0.77      0.77        22\n",
      "weighted avg       0.79      0.77      0.77        22\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.57      0.73      0.64        11\n",
      "     Control       0.62      0.45      0.53        11\n",
      "\n",
      "    accuracy                           0.59        22\n",
      "   macro avg       0.60      0.59      0.58        22\n",
      "weighted avg       0.60      0.59      0.58        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Projects\\github projects\\dimentia ai\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\Projects\\github projects\\dimentia ai\\env\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:35:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision    Recall        F1\n",
       "0        RandomForest  0.681818   0.750000  0.545455  0.631579\n",
       "1  LogisticRegression  0.590909   0.583333  0.636364  0.608696\n",
       "2             XGBoost  0.772727   0.875000  0.636364  0.736842\n",
       "3                 SVM  0.590909   0.625000  0.454545  0.526316"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=500, class_weight=\"balanced\"),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False),\n",
    "    \"SVM\": SVC(kernel='rbf', probability=True)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds)\n",
    "    rec = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "\n",
    "    results.append([name, acc, prec, rec, f1])\n",
    "    print(classification_report(y_test, preds, target_names=encoder.classes_))\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e17b2e-bd69-487d-8702-a5101254a502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
